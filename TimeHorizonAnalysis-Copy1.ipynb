{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tcn in /opt/conda/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: keras==2.3.1 in /opt/conda/lib/python3.7/site-packages (from keras-tcn) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /opt/conda/lib/python3.7/site-packages (from keras-tcn) (1.18.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1->keras-tcn) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1->keras-tcn) (1.4.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1->keras-tcn) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1->keras-tcn) (1.1.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1->keras-tcn) (5.3.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1->keras-tcn) (1.0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = './content/coinbase_btc_usd/coinbase/btc_usd/l2_snapshots/100ms/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_data(base_path):\n",
    "    \"\"\"Concatenate all the files in basepath keeping only the\n",
    "    columns specified by features.\n",
    "    \"\"\"\n",
    "    l2_snapshot = pd.DataFrame()\n",
    "    for i, x in enumerate(tqdm(sorted(os.listdir(base_path)))):\n",
    "        if base_path is None:\n",
    "            path = x\n",
    "        else:\n",
    "            path = base_path + x\n",
    "        df_hour = pd.read_parquet(path)\n",
    "        l2_snapshot = pd.concat([l2_snapshot, df_hour.dropna()])\n",
    "        \n",
    "    return l2_snapshot\n",
    "\n",
    "def extend_matrix(A, n):\n",
    "    \"\"\"Extend a matrix A by duplicating rows as specified by the list n.\"\"\"\n",
    "    n = n[1:]  # Do not duplicate rows for the first day\n",
    "    A = A[:-1]  # Do not duplicate the last day's row\n",
    "    A = np.repeat(A, repeats=n, axis=0)\n",
    "    return A\n",
    "\n",
    "def normalise_data_per_day(df):\n",
    "    df_mean = df.resample('D').mean()\n",
    "    df_var = df.resample('D').var()\n",
    "    \n",
    "    timestamps_per_day = np.unique(df.index.date, return_counts=True)[1]\n",
    "    mean_array = extend_matrix(df_mean.to_numpy(), timestamps_per_day)\n",
    "    var_array = extend_matrix(df_var.to_numpy(), timestamps_per_day)\n",
    "    \n",
    "    # Drop the rows of the first day\n",
    "    df = df[df.index.date != df.index[0].date()]\n",
    "    \n",
    "    df = (df - mean_array) / np.sqrt(var_array)\n",
    "\n",
    "    return df\n",
    "\n",
    "def balance_classes(y):\n",
    "    unique = np.unique(y, return_counts=True)\n",
    "\n",
    "    # Take smallest number as class size\n",
    "    class_size = np.min(unique[1])\n",
    "    class_size_index = np.argmin(unique[1])\n",
    "    timestamps = np.array([], dtype=int)\n",
    "    for i, category in enumerate(unique[0]):\n",
    "        if i == class_size_index:\n",
    "            continue\n",
    "        index = np.argwhere(y==category)\n",
    "        index = index.reshape(len(index))\n",
    "        random_timestamps = np.random.choice(index, (unique[1][i] - class_size), replace=False)\n",
    "        timestamps = np.concatenate((timestamps, random_timestamps), axis=None)\n",
    "        \n",
    "    return timestamps\n",
    "\n",
    "def generate_y(df_snapshot, T=100, D=40, best_ask='a1', best_bid='b1', k=20, alpha=10e-5):\n",
    "    \"\"\"Return X, y from the snapshot dataframe and the best ask/bid columns.\"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    df['mid_price'] = (df_snapshot[best_ask].to_numpy()+df_snapshot[best_bid].to_numpy())/2\n",
    "\n",
    "    # Create columns delayed by -k to k-1\n",
    "    for i in range(-k, k):\n",
    "        df[i] = df['mid_price'].shift(periods=i)\n",
    "\n",
    "    # Drop first k-1 rows and last k rows\n",
    "    df.drop(range(0,20), axis=0, inplace=True)\n",
    "    df.drop(range(len(df_snapshot)-20,len(df_snapshot)), axis=0, inplace=True)\n",
    "    \n",
    "    # Compute mean of previous k and next k\n",
    "    df['m_b'] = df[range(0,20)].mean(axis=1)\n",
    "    df['m_a'] = df[range(-20,0)].mean(axis=1)\n",
    "    \n",
    "    # Compute label of increasing or decreasing\n",
    "    y_increase = np.where(df['m_b'] > df['m_a'] * (1+alpha), 1, 0)\n",
    "    y_decrease = np.where(df['m_b'] < df['m_a'] * (1-alpha), -1, 0)\n",
    "    y = y_increase + y_decrease\n",
    "\n",
    "    # 100 most recent limit orders used so ignore first 100 timesteps\n",
    "    y = y[T:]\n",
    "    y += 1\n",
    "\n",
    "    return y\n",
    "\n",
    "def generate_preX(df_snapshot):\n",
    "    preX = df_snapshot.to_numpy()[20:-20]\n",
    "\n",
    "    return preX\n",
    "\n",
    "def generate_X(preX, T=100, D=40):\n",
    "    # For each timestep create matrix of 100 most recent limit orders\n",
    "    X = np.array([preX[t:t+T] for t in range(len(preX)-T)], dtype='float32')\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [07:45<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# l2_snap = pd.read_csv('total.csv', index_col=0, infer_datetime_format=True)\n",
    "l2_snap = concat_data(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>...</th>\n",
       "      <th>aq41</th>\n",
       "      <th>aq42</th>\n",
       "      <th>aq43</th>\n",
       "      <th>aq44</th>\n",
       "      <th>aq45</th>\n",
       "      <th>aq46</th>\n",
       "      <th>aq47</th>\n",
       "      <th>aq48</th>\n",
       "      <th>aq49</th>\n",
       "      <th>aq50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.000</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.55</td>\n",
       "      <td>8719.50</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8717.56</td>\n",
       "      <td>8716.06</td>\n",
       "      <td>...</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>2.203</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>0.933419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.100</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.55</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8717.56</td>\n",
       "      <td>8716.06</td>\n",
       "      <td>...</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>2.203</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>0.933419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.200</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.61</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8716.06</td>\n",
       "      <td>8716.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>8.200</td>\n",
       "      <td>2.203</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.300</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.61</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8718.00</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8716.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>8.200</td>\n",
       "      <td>2.203</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.400</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.61</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.99</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8718.00</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>8.200</td>\n",
       "      <td>2.203</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              b1       b2       b3       b4      b5       b6  \\\n",
       "timestamp                                                                      \n",
       "2019-11-12 00:00:00.000  8721.53  8720.59  8719.55  8719.50  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.100  8721.53  8720.59  8719.56  8719.55  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.200  8721.53  8720.59  8719.61  8719.56  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.300  8721.53  8720.59  8719.61  8719.56  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.400  8721.53  8720.59  8719.61  8719.56  8719.0  8718.99   \n",
       "\n",
       "                              b7       b8       b9      b10  ...      aq41  \\\n",
       "timestamp                                                    ...             \n",
       "2019-11-12 00:00:00.000  8717.87  8717.85  8717.56  8716.06  ...  8.200000   \n",
       "2019-11-12 00:00:00.100  8717.87  8717.85  8717.56  8716.06  ...  8.200000   \n",
       "2019-11-12 00:00:00.200  8717.87  8717.85  8716.06  8716.00  ...  0.009135   \n",
       "2019-11-12 00:00:00.300  8718.00  8717.87  8717.85  8716.60  ...  0.009135   \n",
       "2019-11-12 00:00:00.400  8718.02  8718.00  8717.87  8717.85  ...  0.009135   \n",
       "\n",
       "                          aq42   aq43   aq44   aq45      aq46      aq47  \\\n",
       "timestamp                                                                 \n",
       "2019-11-12 00:00:00.000  2.203  2.600  0.005  2.500  0.896321  0.766000   \n",
       "2019-11-12 00:00:00.100  2.203  2.600  0.005  2.500  0.896321  0.766000   \n",
       "2019-11-12 00:00:00.200  8.200  2.203  2.600  0.005  2.500000  0.896321   \n",
       "2019-11-12 00:00:00.300  8.200  2.203  2.600  0.005  2.500000  0.896321   \n",
       "2019-11-12 00:00:00.400  8.200  2.203  2.600  0.005  2.500000  0.896321   \n",
       "\n",
       "                             aq48      aq49      aq50  \n",
       "timestamp                                              \n",
       "2019-11-12 00:00:00.000  0.001737  1.820000  0.933419  \n",
       "2019-11-12 00:00:00.100  0.001737  1.820000  0.933419  \n",
       "2019-11-12 00:00:00.200  0.766000  0.001737  1.820000  \n",
       "2019-11-12 00:00:00.300  0.766000  0.001737  1.820000  \n",
       "2019-11-12 00:00:00.400  0.766000  0.001737  1.820000  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_snap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>...</th>\n",
       "      <th>aq41</th>\n",
       "      <th>aq42</th>\n",
       "      <th>aq43</th>\n",
       "      <th>aq44</th>\n",
       "      <th>aq45</th>\n",
       "      <th>aq46</th>\n",
       "      <th>aq47</th>\n",
       "      <th>aq48</th>\n",
       "      <th>aq49</th>\n",
       "      <th>aq50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-20 23:59:57.900</th>\n",
       "      <td>8082.96</td>\n",
       "      <td>8082.23</td>\n",
       "      <td>8081.65</td>\n",
       "      <td>8080.17</td>\n",
       "      <td>8079.74</td>\n",
       "      <td>8079.69</td>\n",
       "      <td>8079.19</td>\n",
       "      <td>8077.75</td>\n",
       "      <td>8077.6</td>\n",
       "      <td>8076.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.151276</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>1.137</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.907671</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.74149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 23:59:58.400</th>\n",
       "      <td>8082.96</td>\n",
       "      <td>8082.23</td>\n",
       "      <td>8081.65</td>\n",
       "      <td>8080.17</td>\n",
       "      <td>8079.74</td>\n",
       "      <td>8079.69</td>\n",
       "      <td>8079.19</td>\n",
       "      <td>8077.75</td>\n",
       "      <td>8077.6</td>\n",
       "      <td>8076.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.151276</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>1.137</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.907671</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.74149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 23:59:58.500</th>\n",
       "      <td>8082.96</td>\n",
       "      <td>8082.23</td>\n",
       "      <td>8081.65</td>\n",
       "      <td>8080.17</td>\n",
       "      <td>8079.74</td>\n",
       "      <td>8079.69</td>\n",
       "      <td>8079.19</td>\n",
       "      <td>8077.75</td>\n",
       "      <td>8077.6</td>\n",
       "      <td>8076.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.151276</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>1.137</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.907671</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.74149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 23:59:58.800</th>\n",
       "      <td>8082.96</td>\n",
       "      <td>8082.23</td>\n",
       "      <td>8081.65</td>\n",
       "      <td>8080.17</td>\n",
       "      <td>8079.74</td>\n",
       "      <td>8079.69</td>\n",
       "      <td>8079.19</td>\n",
       "      <td>8077.75</td>\n",
       "      <td>8077.6</td>\n",
       "      <td>8076.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.151276</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>1.137</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.907671</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.74149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 23:59:59.600</th>\n",
       "      <td>8082.96</td>\n",
       "      <td>8082.23</td>\n",
       "      <td>8081.65</td>\n",
       "      <td>8080.17</td>\n",
       "      <td>8079.74</td>\n",
       "      <td>8079.69</td>\n",
       "      <td>8079.19</td>\n",
       "      <td>8077.75</td>\n",
       "      <td>8077.6</td>\n",
       "      <td>8076.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.151276</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>1.137</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.907671</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.74149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              b1       b2       b3       b4       b5       b6  \\\n",
       "timestamp                                                                       \n",
       "2019-11-20 23:59:57.900  8082.96  8082.23  8081.65  8080.17  8079.74  8079.69   \n",
       "2019-11-20 23:59:58.400  8082.96  8082.23  8081.65  8080.17  8079.74  8079.69   \n",
       "2019-11-20 23:59:58.500  8082.96  8082.23  8081.65  8080.17  8079.74  8079.69   \n",
       "2019-11-20 23:59:58.800  8082.96  8082.23  8081.65  8080.17  8079.74  8079.69   \n",
       "2019-11-20 23:59:59.600  8082.96  8082.23  8081.65  8080.17  8079.74  8079.69   \n",
       "\n",
       "                              b7       b8      b9      b10  ...   aq41  \\\n",
       "timestamp                                                   ...          \n",
       "2019-11-20 23:59:57.900  8079.19  8077.75  8077.6  8076.88  ...  0.005   \n",
       "2019-11-20 23:59:58.400  8079.19  8077.75  8077.6  8076.88  ...  0.005   \n",
       "2019-11-20 23:59:58.500  8079.19  8077.75  8077.6  8076.88  ...  0.005   \n",
       "2019-11-20 23:59:58.800  8079.19  8077.75  8077.6  8076.88  ...  0.005   \n",
       "2019-11-20 23:59:59.600  8079.19  8077.75  8077.6  8076.88  ...  0.005   \n",
       "\n",
       "                             aq42    aq43   aq44  aq45      aq46   aq47  \\\n",
       "timestamp                                                                 \n",
       "2019-11-20 23:59:57.900  0.151276  0.0058  1.137   0.6  0.907671  0.001   \n",
       "2019-11-20 23:59:58.400  0.151276  0.0058  1.137   0.6  0.907671  0.001   \n",
       "2019-11-20 23:59:58.500  0.151276  0.0058  1.137   0.6  0.907671  0.001   \n",
       "2019-11-20 23:59:58.800  0.151276  0.0058  1.137   0.6  0.907671  0.001   \n",
       "2019-11-20 23:59:59.600  0.151276  0.0058  1.137   0.6  0.907671  0.001   \n",
       "\n",
       "                          aq48  aq49     aq50  \n",
       "timestamp                                      \n",
       "2019-11-20 23:59:57.900  0.001   2.4  0.74149  \n",
       "2019-11-20 23:59:58.400  0.001   2.4  0.74149  \n",
       "2019-11-20 23:59:58.500  0.001   2.4  0.74149  \n",
       "2019-11-20 23:59:58.800  0.001   2.4  0.74149  \n",
       "2019-11-20 23:59:59.600  0.001   2.4  0.74149  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_snap.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Model and Depth Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input, Model\n",
    "from tcn import TCN, tcn_full_summary\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(depth):\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "\n",
    "        i = Input(batch_shape=(None, 100, depth))\n",
    "        o = TCN(return_sequences=False, use_skip_connections=True, dropout_rate=0.4, dilations=[1, 2, 4, 8, 16, 32, 64], use_batch_norm=True)(i)\n",
    "        o = Dense(3, activation='softmax')(o)\n",
    "        m = Model(inputs=[i], outputs=[o])\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "        m.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(l2_snap, depth, columns, days_training):\n",
    "    l2_snap.index = pd.to_datetime(l2_snap.index)\n",
    "    l2_snap_dep2 = l2_snap.loc[:,columns]\n",
    "    l2_norm = normalise_data_per_day(l2_snap_dep2)\n",
    "    T = 100\n",
    "    D = depth\n",
    "    y = generate_y(l2_norm, T=T, D=D, best_ask='a1', best_bid = 'b1', alpha=0.002)\n",
    "    preX = generate_preX(l2_norm)\n",
    "    print(\"preX Shape: \", preX.shape)\n",
    "    X = generate_X(preX)\n",
    "    print(\"X shape, y shape: \", X.shape, y.shape)\n",
    "    print(\"Unique y's: \", np.unique(y))\n",
    "\n",
    "    del preX\n",
    "    gc.collect()\n",
    "\n",
    "    # First and last 20 are removed to create labels and then last 100 as previous 100 is required for input matrix\n",
    "    X_index = l2_norm[20:-120].index\n",
    "\n",
    "    # Number of data points for the last day\n",
    "    num_test = np.unique(X_index.day, return_counts=True)[1][-1]\n",
    "\n",
    "    # Days back to\n",
    "    num_start = np.unique(X_index.day, return_counts=True)[1][-1 - days_training:].sum()\n",
    "\n",
    "    # Split the data into the first days and the last day\n",
    "    X_train_val = X[-num_start:-num_test]\n",
    "    y_train_val = y[-num_start:-num_test]\n",
    "    X_test = X[-num_test:]\n",
    "    y_test = y[-num_test:]\n",
    "    return X_train_val, y_train_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth:10\n",
    "\n",
    "\n",
    "#### Days 1, 2, 4, 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days Training now  1\n",
      "preX Shape:  (4220032, 40)\n",
      "X shape, y shape:  (4219932, 100, 40) (4219932,)\n",
      "Unique y's:  [0 1 2]\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1 2], y=[1 1 1 ... 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "INFO:tensorflow:batch_all_reduce: 60 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 60 all-reduces with algorithm = nccl, num_packs = 1\n",
      "4128/4128 [==============================] - ETA: 0s - loss: 0.7559 - accuracy: 0.4845\n",
      "Epoch 00001: val_loss improved from inf to 1.79466, saving model to model_resnet_walkforward_tcn_depth10.h5\n",
      "4128/4128 [==============================] - 142s 34ms/step - loss: 0.7559 - accuracy: 0.4845 - val_loss: 1.7947 - val_accuracy: 0.2879 - lr: 0.0100\n",
      "Epoch 2/20\n",
      "4127/4128 [============================>.] - ETA: 0s - loss: 0.6829 - accuracy: 0.5566\n",
      "Epoch 00002: val_loss improved from 1.79466 to 1.38233, saving model to model_resnet_walkforward_tcn_depth10.h5\n",
      "4128/4128 [==============================] - 135s 33ms/step - loss: 0.6829 - accuracy: 0.5566 - val_loss: 1.3823 - val_accuracy: 0.4053 - lr: 0.0100\n",
      "Epoch 3/20\n",
      "4128/4128 [==============================] - ETA: 0s - loss: 0.6673 - accuracy: 0.5692\n",
      "Epoch 00003: val_loss did not improve from 1.38233\n",
      "4128/4128 [==============================] - 134s 32ms/step - loss: 0.6673 - accuracy: 0.5692 - val_loss: 1.6325 - val_accuracy: 0.5596 - lr: 0.0100\n",
      "Epoch 4/20\n",
      "4127/4128 [============================>.] - ETA: 0s - loss: 0.6538 - accuracy: 0.5819\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.38233\n",
      "4128/4128 [==============================] - 134s 32ms/step - loss: 0.6538 - accuracy: 0.5819 - val_loss: 2.6609 - val_accuracy: 0.3687 - lr: 0.0100\n",
      "Epoch 5/20\n",
      "4128/4128 [==============================] - ETA: 0s - loss: 0.6274 - accuracy: 0.5939\n",
      "Epoch 00005: val_loss did not improve from 1.38233\n",
      "4128/4128 [==============================] - 135s 33ms/step - loss: 0.6274 - accuracy: 0.5939 - val_loss: 3.0526 - val_accuracy: 0.5935 - lr: 0.0050\n",
      "Epoch 6/20\n",
      "4128/4128 [==============================] - ETA: 0s - loss: 0.6184 - accuracy: 0.5983\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.38233\n",
      "4128/4128 [==============================] - 136s 33ms/step - loss: 0.6184 - accuracy: 0.5983 - val_loss: 2.8368 - val_accuracy: 0.5656 - lr: 0.0050\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.28      0.41      0.33     61142\n",
      "      Stable       0.78      0.62      0.69    350499\n",
      "          Up       0.22      0.41      0.29     53759\n",
      "\n",
      "    accuracy                           0.57    465400\n",
      "   macro avg       0.43      0.48      0.44    465400\n",
      "weighted avg       0.65      0.57      0.59    465400\n",
      "\n",
      "Days Training now  2\n",
      "preX Shape:  (4220032, 40)\n",
      "X shape, y shape:  (4219932, 100, 40) (4219932,)\n",
      "Unique y's:  [0 1 2]\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1 2], y=[1 1 1 ... 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "INFO:tensorflow:batch_all_reduce: 60 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 60 all-reduces with algorithm = nccl, num_packs = 1\n",
      "8082/8082 [==============================] - ETA: 0s - loss: 0.7667 - accuracy: 0.5351\n",
      "Epoch 00001: val_loss improved from inf to 1.29134, saving model to model_resnet_walkforward_tcn_depth10.h5\n",
      "8082/8082 [==============================] - 231s 29ms/step - loss: 0.7667 - accuracy: 0.5351 - val_loss: 1.2913 - val_accuracy: 0.3809 - lr: 0.0100\n",
      "Epoch 2/20\n",
      "8080/8082 [============================>.] - ETA: 0s - loss: 0.7002 - accuracy: 0.6055\n",
      "Epoch 00002: val_loss did not improve from 1.29134\n",
      "8082/8082 [==============================] - 222s 27ms/step - loss: 0.7001 - accuracy: 0.6055 - val_loss: 1.4297 - val_accuracy: 0.4679 - lr: 0.0100\n",
      "Epoch 3/20\n",
      "8082/8082 [==============================] - ETA: 0s - loss: 0.6824 - accuracy: 0.6171\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.29134\n",
      "8082/8082 [==============================] - 222s 27ms/step - loss: 0.6824 - accuracy: 0.6171 - val_loss: 1.6929 - val_accuracy: 0.4324 - lr: 0.0100\n",
      "Epoch 4/20\n",
      "8080/8082 [============================>.] - ETA: 0s - loss: 0.6533 - accuracy: 0.6331\n",
      "Epoch 00004: val_loss did not improve from 1.29134\n",
      "8082/8082 [==============================] - 227s 28ms/step - loss: 0.6533 - accuracy: 0.6331 - val_loss: 1.7265 - val_accuracy: 0.4449 - lr: 0.0050\n",
      "Epoch 5/20\n",
      "8082/8082 [==============================] - ETA: 0s - loss: 0.6432 - accuracy: 0.6364\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.29134\n",
      "8082/8082 [==============================] - 223s 28ms/step - loss: 0.6432 - accuracy: 0.6364 - val_loss: 2.3254 - val_accuracy: 0.4336 - lr: 0.0050\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.27      0.57      0.37     61142\n",
      "      Stable       0.83      0.37      0.51    350499\n",
      "          Up       0.21      0.70      0.32     53759\n",
      "\n",
      "    accuracy                           0.43    465400\n",
      "   macro avg       0.44      0.55      0.40    465400\n",
      "weighted avg       0.68      0.43      0.47    465400\n",
      "\n",
      "Days Training now  4\n",
      "preX Shape:  (4220032, 40)\n",
      "X shape, y shape:  (4219932, 100, 40) (4219932,)\n",
      "Unique y's:  [0 1 2]\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1 2], y=[0 0 0 ... 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "INFO:tensorflow:batch_all_reduce: 60 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 60 all-reduces with algorithm = nccl, num_packs = 1\n",
      "15479/15479 [==============================] - ETA: 0s - loss: 0.7702 - accuracy: 0.6733\n",
      "Epoch 00001: val_loss improved from inf to 0.76948, saving model to model_resnet_walkforward_tcn_depth10.h5\n",
      "15479/15479 [==============================] - 396s 26ms/step - loss: 0.7702 - accuracy: 0.6733 - val_loss: 0.7695 - val_accuracy: 0.6631 - lr: 0.0100\n",
      "Epoch 2/20\n",
      "15478/15479 [============================>.] - ETA: 0s - loss: 0.7170 - accuracy: 0.7120\n",
      "Epoch 00002: val_loss did not improve from 0.76948\n",
      "15479/15479 [==============================] - 387s 25ms/step - loss: 0.7170 - accuracy: 0.7120 - val_loss: 0.7804 - val_accuracy: 0.6346 - lr: 0.0100\n",
      "Epoch 3/20\n",
      "15478/15479 [============================>.] - ETA: 0s - loss: 0.7007 - accuracy: 0.7202\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.76948\n",
      "15479/15479 [==============================] - 384s 25ms/step - loss: 0.7007 - accuracy: 0.7202 - val_loss: 0.7947 - val_accuracy: 0.6283 - lr: 0.0100\n",
      "Epoch 4/20\n",
      "15477/15479 [============================>.] - ETA: 0s - loss: 0.6741 - accuracy: 0.7306\n",
      "Epoch 00004: val_loss did not improve from 0.76948\n",
      "15479/15479 [==============================] - 391s 25ms/step - loss: 0.6741 - accuracy: 0.7306 - val_loss: 0.7861 - val_accuracy: 0.5839 - lr: 0.0050\n",
      "Epoch 5/20\n",
      "15478/15479 [============================>.] - ETA: 0s - loss: 0.6662 - accuracy: 0.7321\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.76948\n",
      "15479/15479 [==============================] - 384s 25ms/step - loss: 0.6662 - accuracy: 0.7321 - val_loss: 0.7835 - val_accuracy: 0.5722 - lr: 0.0050\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.42      0.54      0.47     61142\n",
      "      Stable       0.90      0.54      0.67    350499\n",
      "          Up       0.26      0.85      0.40     53759\n",
      "\n",
      "    accuracy                           0.57    465400\n",
      "   macro avg       0.52      0.64      0.51    465400\n",
      "weighted avg       0.76      0.57      0.61    465400\n",
      "\n",
      "Days Training now  7\n",
      "preX Shape:  (4220032, 40)\n",
      "X shape, y shape:  (4219932, 100, 40) (4219932,)\n",
      "Unique y's:  [0 1 2]\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/20\n",
      "INFO:tensorflow:batch_all_reduce: 60 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 60 all-reduces with algorithm = nccl, num_packs = 1\n",
      "29333/29333 [==============================] - ETA: 0s - loss: 0.7621 - accuracy: 0.6823\n",
      "Epoch 00001: val_loss improved from inf to 0.70070, saving model to model_resnet_walkforward_tcn_depth10.h5\n",
      "29333/29333 [==============================] - 700s 24ms/step - loss: 0.7621 - accuracy: 0.6823 - val_loss: 0.7007 - val_accuracy: 0.7023 - lr: 0.0100\n",
      "Epoch 2/20\n",
      "29332/29333 [============================>.] - ETA: 0s - loss: 0.7202 - accuracy: 0.7152\n",
      "Epoch 00002: val_loss did not improve from 0.70070\n",
      "29333/29333 [==============================] - 693s 24ms/step - loss: 0.7202 - accuracy: 0.7152 - val_loss: 0.7237 - val_accuracy: 0.6819 - lr: 0.0100\n",
      "Epoch 3/20\n",
      "29333/29333 [==============================] - ETA: 0s - loss: 0.7087 - accuracy: 0.7209\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.70070\n",
      "29333/29333 [==============================] - 691s 24ms/step - loss: 0.7087 - accuracy: 0.7209 - val_loss: 0.7671 - val_accuracy: 0.6254 - lr: 0.0100\n",
      "Epoch 4/20\n",
      "29331/29333 [============================>.] - ETA: 0s - loss: 0.6867 - accuracy: 0.7293\n",
      "Epoch 00004: val_loss improved from 0.70070 to 0.65795, saving model to model_resnet_walkforward_tcn_depth10.h5\n",
      "29333/29333 [==============================] - 728s 25ms/step - loss: 0.6867 - accuracy: 0.7293 - val_loss: 0.6580 - val_accuracy: 0.7299 - lr: 0.0050\n",
      "Epoch 5/20\n",
      "29331/29333 [============================>.] - ETA: 0s - loss: 0.6811 - accuracy: 0.7312\n",
      "Epoch 00005: val_loss did not improve from 0.65795\n",
      "29333/29333 [==============================] - 712s 24ms/step - loss: 0.6811 - accuracy: 0.7312 - val_loss: 0.7101 - val_accuracy: 0.6737 - lr: 0.0050\n",
      "Epoch 6/20\n",
      "29333/29333 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.7321\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.65795\n",
      "29333/29333 [==============================] - 711s 24ms/step - loss: 0.6772 - accuracy: 0.7321 - val_loss: 0.6618 - val_accuracy: 0.7132 - lr: 0.0050\n",
      "Epoch 7/20\n",
      "29332/29333 [============================>.] - ETA: 0s - loss: 0.6661 - accuracy: 0.7356\n",
      "Epoch 00007: val_loss did not improve from 0.65795\n",
      "29333/29333 [==============================] - 708s 24ms/step - loss: 0.6661 - accuracy: 0.7356 - val_loss: 0.7038 - val_accuracy: 0.6709 - lr: 0.0025\n",
      "Epoch 8/20\n",
      "29333/29333 [==============================] - ETA: 0s - loss: 0.6636 - accuracy: 0.7365\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.65795\n",
      "29333/29333 [==============================] - 694s 24ms/step - loss: 0.6636 - accuracy: 0.7365 - val_loss: 0.7088 - val_accuracy: 0.6683 - lr: 0.0025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.41      0.59      0.49     61142\n",
      "      Stable       0.90      0.67      0.77    350499\n",
      "          Up       0.34      0.74      0.47     53759\n",
      "\n",
      "    accuracy                           0.67    465400\n",
      "   macro avg       0.55      0.67      0.57    465400\n",
      "weighted avg       0.77      0.67      0.70    465400\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for days_training in [1,2,4,7]:\n",
    "    print('Days Training now ', days_training)\n",
    "    X_train_val, y_train_val, X_test, y_test = generate_data(l2_snap, 40, columns = ['b1','b2','b3','b4','b5','b6','b7','b8', 'b9', 'b10', 'a1','a2','a3','a4','a5','a6','a7','a8', 'a9', 'a10', 'bq1','bq2','bq3','bq4','bq5','bq6','bq7','bq8', 'bq9', 'bq10', 'aq1','aq2','aq3','aq4','aq5','aq6','aq7','aq8', 'aq9', 'aq10'], days_training=days_training)\n",
    "    m = generate_model(40)\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    class_weights = compute_class_weight('balanced', np.unique(y_train_val), y_train_val)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    EPOCHS = 20\n",
    "    model_filename = \"model_resnet_walkforward_tcn_depth10.h5\"\n",
    "    hist_filename = \"hist_model_walkforward_tcn_depth10.csv\"\n",
    "    early_stop = keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=4)\n",
    "    model_save_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "                                filepath= model_filename,\n",
    "                                save_best_only=True,\n",
    "                                monitor='val_loss',\n",
    "                                verbose=1)\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor='val_loss',\n",
    "                    factor=0.5,\n",
    "                    patience=2,\n",
    "                    verbose=1,\n",
    "                    min_lr=0.0001)\n",
    "    callbacks = [reduce_lr, model_save_checkpoint, early_stop]\n",
    "    history = m.fit(\n",
    "                X_train_val, y_train_val,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=128,\n",
    "                callbacks=callbacks,\n",
    "                class_weight = d_class_weights,\n",
    "                validation_data = (X_test, y_test),\n",
    "    )\n",
    "\n",
    "    y_pred = m.predict(X_test).argmax(axis=1)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set()\n",
    "    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    ax=sns.heatmap(cm, annot=True, xticklabels=['Down','Stable','Up'], yticklabels=['Down','Stable','Up'], cmap='Blues')\n",
    "    ax.set_ylim(3.0, 0)\n",
    "    plt.savefig('image_depth_10_{}_days_training'.format(days_training))\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_true = y_test,y_pred = y_pred,  target_names=['Down', 'Stable', 'Up']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Days used for training')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEPCAYAAAC3NDh4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de1hUdcIH8C8zXMQAkWmAIW9JprOrKYqYb6irYEgO4iXFMM1MtIe8Zd4i4+YtLCtFXDdsMZYuLusFHXFxTdF0U8EseQWsV0FUhkFBA8wUh3n/8GkeCQ4caG7g9/M8+zxz+c38vjN74us5Z845Nnq9Xg8iIqJGSCwdgIiIrBdLgoiIBLEkiIhIEEuCiIgEsSSIiEgQS4KIiATZmmuioqIirFixArdu3YKrqysSEhLQo0ePemOWLVuGCxcuGO5fuHABSUlJCAgIMFdMIiJ6iI25jpOYMWMGJk2ahNDQUGRkZGDnzp1ITU0VHF9YWIhXXnkF33zzDezt7c0RkYiIfscsm5sqKiqQn58PlUoFAFCpVMjPz0dlZaXga/71r38hJCSEBUFEZEFmKQmNRgMPDw9IpVIAgFQqhbu7OzQaTaPj7927h3379mHSpEnmiEdERAKscsf1oUOH4OXlBaVSaekoRESPNLPsuFYoFNBqtdDpdJBKpdDpdCgvL4dCoWh0/M6dO1u9FlFRUYO6Osudjkoud8b169UWm781mNn02lpegJnNxdKZJRIbyGROws+bI4RMJoNSqYRarQYAqNVqKJVKuLm5NRhbVlaGM2fOGPZfEBGR5Zhtc1NsbCzS0tIQFBSEtLQ0xMXFAQAiIiKQl5dnGLd7926MHDkSrq6u5opGREQCzPYTWHPh5qaWY2bTa2t5AWY2F0tntorNTURE1DaxJIiISBBLgoiIBLEkiIhIkNlO8EdE1J44uziig4Nx/oTK5c5/+D1+vXsf1VV3jJCmPpYEEVErdHCwRchbGZaOYbBvQyhM8Rspbm4iIiJBLAkiIhLEkiAiIkEsCSIiEsSSICIiQSwJIiISxJIgIiJBLAkiIhLEkiAiIkEsCSIiEsSSICIiQSwJIiISxJIgIiJBLAkiIhLEkiAiIkEsCSIiEmS2kigqKkJYWBiCgoIQFhaG4uLiRsdlZmYiJCQEKpUKISEhuHHjhrkiEhHR75jtynQxMTEIDw9HaGgoMjIyEB0djdTU1Hpj8vLysHnzZnz22WeQy+Worq6Gvb29uSISEdHvmGVNoqKiAvn5+VCpVAAAlUqF/Px8VFZW1hu3fft2zJo1C3K5HADg7OwMBwcHc0QkIqJGmKUkNBoNPDw8IJVKAQBSqRTu7u7QaDT1xl28eBFXrlzBtGnTMGHCBGzZsgV6vd4cEYmIqBFm29wkhk6nw4ULF5CSkoJ79+5h9uzZ8PLywvjx40W/h0zmZMKE4sjlzpaO0GLMbHptLS/AzG2NKT67WUpCoVBAq9VCp9NBKpVCp9OhvLwcCoWi3jgvLy+MGTMG9vb2sLe3R0BAAM6dO9eikqioqEFdneXWPuRyZ1y/Xm2x+VuDmU2vreUFmFnMXNamNZ9dIrFp8h/XZtncJJPJoFQqoVarAQBqtRpKpRJubm71xqlUKhw/fhx6vR61tbU4efIk+vTpY46IRETUCLP9BDY2NhZpaWkICgpCWloa4uLiAAARERHIy8sDAIwdOxYymQwvvPACxo8fj6eeegovvviiuSISEdHvmG2fhLe3N9LT0xs8npycbLgtkUjw9ttv4+233zZXLCIiagKPuCYiIkEsCSIiEsSSICIiQSwJIiISJGrHdWFhYbv/KaqziyM6OBhnP74xfj/96937qK66Y4Q09EcZa9ngckFtkaglf+bMmXB3d0doaChCQkLg7u5u6lxm18HBFiFvZVg6hsG+DaFoW4cxtV/WtGxwuSBzE7W56fjx41iwYAF++OEHBAUFYdasWcjIyMCdO/wXDRFReyaqJGxtbREYGIhNmzbh2LFjCA4OxrZt2/A///M/WLZsGc6cOWPqnEREZAEt2nF9+/ZtHDp0CPv374dWq8XYsWPRvXt3LF261HAENRERtR+i9klkZ2cjIyMDx44dw8CBAzF58mQEBgYarvUwbdo0jBw5EjExMSYNS0RE5iWqJDZs2IDQ0FC8/fbbje60dnV1RVRUlNHDERGRZYkqiX379jU7ZvLkyX84DBERWRdR+yTmzZuH3Nzceo/l5uZiwYIFJglFRETWQVRJ5OTkwMfHp95jAwYMwKlTp0wSioiIrIOokrC3t29wTMQvv/wCW1uruvopEREZmaiS8Pf3R3R0NGpqagAANTU1iI+Px7Bhw0wajoiILEtUSaxYsQI1NTXw8/PD0KFD4efnh5qaGv6iiYionRO1vahTp0745JNPUF5ejrKyMigUCsjlclNnIyIiC2vRTgV3d3fI5XLo9XrU1dUBeHDJUSIiap9ElYRWq0V8fDxyc3NRVVVV77mCggKTBCMiIssTtRoQExMDOzs7bN++HR07dsTu3bsxatQonq+JiKidE7UmcfbsWRw5cgQdO3aEjY0N+vTpgzVr1mDq1KmYMmWKqTMSEZGFiCoJiURiOCbCxcUFlZWVcHJyglarFT1RUVERVqxYgVu3bsHV1RUJCQno0aNHvTGJiYn44osvDOeHGjhwIE8aSERkQaJKon///jh69ChGjx4Nf39/LFq0CB06dEDfvn1FTxQTE4Pw8HCEhoYiIyMD0dHRSE1NbTBu/PjxWL58ufhPQEREJiNqn8T69esxePBgAEBUVBSeffZZ9OrVCxs2bBA1SUVFBfLz86FSqQAAKpUK+fn5qKysbGVsIiIyh2ZLQqfTYc2aNejYsSMAoEOHDoiMjMTSpUtFX+tao9HAw8MDUqkUACCVSuHu7g6NRtNg7P79+xESEoJZs2bh7NmzLfksRERkZM1ubpJKpThx4gRsbGxMHmbq1Kl4/fXXYWdnhxMnTiAyMhKZmZno3Lmz6PeQyZxMmNC85HLndjmXsbTFzMbA5aJpbTGzsZjis4vaJ/HKK68gMTER8+fPh52dXYsnUSgU0Gq10Ol0kEql0Ol0KC8vh0KhqDfu4aO4n3vuOSgUCvz000/w8/MTPVdFRQ3q6vQtzmiNC9b169VmmUcudzbbXMZizszWtmxwuRD2KC8XQOuWDYnEpsl/XIsqibS0NNy4cQMpKSlwc3Ort1aRnZ3d7OtlMhmUSiXUajVCQ0OhVquhVCrh5uZWb5xWq4WHhweABwfpXbt2DU8++aSYiEREZAKiSuL999//wxPFxsZixYoV2LJlC1xcXJCQkAAAiIiIwIIFC9CvXz98+OGHOH/+PCQSCezs7LB+/XqeI4qIyIJElURLNvcI8fb2Rnp6eoPHk5OTDbd/Kw4iIrIOokpi48aNgs8tXLjQaGGIiMi6iCqJsrKyevevX7+OnJwcBAYGmiQUERFZB1ElsW7dugaPHTt2DPv37zd6ICIish6tvhiEv78/Dh06ZMwsRERkZUStSVy5cqXe/Tt37kCtVjc4zoGIiNoXUSUxevRo2NjYQK9/cJCao6MjlEol3nvvPZOGIyIiyxJVEoWFhabOQUREVkjUPomCgoIGJ+PTaDQsDyKidk5USSxduhT379+v91htbS2WLl1qklBERGQdRJVEaWkpunbtWu+xbt264dq1ayYJRURE1kFUSXh6euL8+fP1Hjt//rzo60kQEVHbJGrH9cyZMxEZGYnZs2ejW7duKCkpwd///ne8/vrrps5HREQWJKokpkyZAmdnZ/zrX/9CWVkZPD09sXz5cowZM8bU+YiIyIJElQQABAcHIzg42JRZiIjIyojaJ7F69Wp899139R777rvvsGbNGpOEIiIi6yCqJNRqNfr27Vvvsb59+0KtVpskFBERWQdRm5sePiXHb3Q6Herq6kwSisRxdnFEBwfRWwybZIzr9f569z6qq+4YIQ0RWQtRf2F8fX3x8ccfY+nSpZBIJKirq0NiYiJ8fX1NnY+a0MHBFiFvZVg6hsG+DaEwzyXoichcRJXEO++8g7lz58Lf3x9eXl7QaDSQy+XYunWrqfMREZEFiSoJT09P7N69Gz/88APKysqgUCjwzDPPQCJp9eUoiIioDRC9QVsikcDHx8eUWYiIyMqIKomamhokJiYiJycHN2/erLcTOzs721TZiIjIwkRtL4qNjUV+fj4iIyNx69YtrFy5EgqFAjNnzhQ9UVFREcLCwhAUFISwsDAUFxcLjr106RL69++PhIQE0e9PRETGJ6okTpw4gU2bNiEwMBBSqRSBgYH4+OOPkZEh/pc1MTExCA8PR1ZWFsLDwxEdHd3oOJ1Oh5iYGAQGBop+byIiMg1RJVFXVwdn5we/o+/YsSOqqqogl8tx+fJlUZNUVFQgPz8fKpUKAKBSqZCfn4/KysoGYz/55BP85S9/QY8ePUR+BCIiMhVRJdGnTx/k5OQAeHDMRFxcHGJjY0X/IddoNPDw8IBUKgUASKVSuLu7N7jaXWFhIY4fP96izVhERGQ6onZcr1692rCzeuXKldiwYQOqqqqwfv16owWpra3Fu+++i3Xr1hnKpDVkMiejZbI0YxwFbW7mzNwWvx9j4HfctLaY2VhM8dlFlcTDV6Vzc3Nr8Yn9FAoFtFotdDodpFIpdDodysvLoVAoDGOuX7+OkpISzJkzBwBQVVUFvV6PmpoarFq1SvRcFRU1qKvTNz/wd6xxwbp+venjl9tiZmORy53NOpc1aY/fsbE8yssF0LplQyKxafIf18Y58U8zZDIZlEol1Go1QkNDoVaroVQq4ebmZhjj5eWFU6dOGe4nJibil19+wfLly80RkYiIGmG2Q6ZjY2ORlpaGoKAgpKWlIS4uDgAQERGBvLw8c8UgIqIWMMuaBAB4e3sjPT29wePJycmNjp8/f76pIxERUTN48iUiIhIkuCaxceNGUW+wcOFCo4UhIiLrIlgSZWVlhtt3797FwYMH0bdvXzzxxBMoLS1FXl4enn/+ebOEJCIiyxAsiXXr1hluv/nmm9iwYQOCgoIMjx08eBD//ve/TZuOiIgsStQ+iWPHjjU4l1JAQACOHj1qklBERGQdRJVE9+7d8fnnn9d77IsvvkC3bt1MEoqIiKyDqJ/ArlmzBm+88Qa2bdsGDw8PaLVa2NraIjEx0dT5iIjIgpotibq6Oty6dQt79+5FYWEhysvLIZfLMWDAANjZ2ZkjIxERWUizJSGRSBAZGYmzZ8/C19fXHJmIiMhKiNonMXjwYHz//femzkJERFZG1D4JLy8vREREICAgAJ6enrCxsTE8x4PpiIjaL1ElcffuXcNPYLVarUkDERGR9RBVEg8fWEdERI+OFp0FtqamBjdv3qz32MMXJCIiovZFVEn83//9H5YsWYLCwkLY2NhAr9cb9ksUFBSYNCAREVmOqF83xcXFYciQITh9+jScnJyQk5ODsLAwvPfee6bOR0REFiSqJAoLC7FkyRK4uLhAr9fD2dkZy5YtE306cSIiaptElYSDgwPu378PAOjcuTNKS0sNR2ITEVH7JWqfxKBBg3DgwAFMnDgRQUFBiIiIgL29PZ599llT5yMiIgsSVRIPb1ZavHgxevXqhdu3b2P8+PEmC0ZERJYnqiSqq6vh7OwM4MG5nEJDQ00aioiIrIOoknjuuefQs2dPDB48GH5+fvD19UXnzp1NnY2IiCxM1I7rnJwcLF++HC4uLkhNTcWoUaMQEhKC+Ph40RMVFRUhLCwMQUFBCAsLQ3FxcYMxO3fuREhICEJDQxESEoLU1FTR709ERMYn+tdNQ4cOxezZszF37lyEhYWhtLQUWVlZoieKiYlBeHg4srKyEB4ejujo6AZjgoKCsHfvXmRkZODLL79ESkoKCgsLxX8aIiIyKlEl8cEHHyAsLAzBwcHYuXMnunbtih07duDEiROiJqmoqEB+fj5UKhUAQKVSIT8/H5WVlfXGOTk5GY7k/vXXX1FbW1vvjLNERGReovZJfP7553j88cfx0ksvwc/PD/369YOtrfjTPmk0Gnh4eEAqlQIApFIp3N3dodFo4ObmVm/s119/jQ8//BAlJSV466230Lt37xZ8HCIiMiZRf+lzcnKQl5eHnJwc/PWvf0VBQQGeeuopDB48GJGRkUYNFBAQgICAAJSWluKNN97A8OHD0bNnT9Gvl8mcjJrHkuRyZ0tHaDFzZm6L348x8DtuWlvMbCym+OyiSsLW1hY+Pj7o2bMnnnzySZw8eRJ79uxBTk6OqJJQKBTQarXQ6XSQSqXQ6XQoLy+HQqEQfI2Xlxf69euH7OzsFpVERUUN6ur0osf/xhoXrOvXq5t8vi1mNha53Nmsc1mT9vgdG8ujvFwArVs2JBKbJv9xLWqfxOrVqzFu3DgMHz4c27dvh5OTEzZt2oTTp0+LCiGTyaBUKqFWqwEAarUaSqWywaamixcvGm5XVlbi1KlTePrpp0XNQURExidqTaJTp06IioqCj48PHBwcWjVRbGwsVqxYgS1btsDFxQUJCQkAgIiICCxYsAD9+vUz7Ay3tbWFXq/Hyy+/DH9//1bNR0REf1yzJaHT6ZCRkYG5c+fC3t6+1RN5e3sjPT29wePJycmG21FRUa1+fyIiMr5mNzdJpVJIpVLcvXvXHHmIiMiKiNrcNGPGDCxatAhz586Fp6dnvWMXePlSIqL2S1RJrFq1CgAaHDxnY2PDy5cSEbVjokqCp8YgIno0iT9sGkBpaSm0Wi08PT2bPMaBiIjaB1ElUV5ejsWLF+P777+Hq6srbt26hf79++PDDz+Eh4eHqTMSEZGFiDqYLjY2Fn369MHp06dx/PhxnD59GkqlEjExMabOR0REFiRqTeLMmTPYuHEj7OzsAAAdO3bEsmXLMGzYMJOGIyIiyxK1JtGpU6d6p8wAgEuXLsHFxcUkoYiIyDqIWpOYPXs2Zs6ciRdffBFeXl4oLS3Frl27sHDhQlPnIyIiCxJVElOmTEHXrl2hVqtx4cIFuLu7Y8OGDRg6dKip8xERkQUJlsSUKVPwz3/+EwCwefNmzJs3j6VARPSIEdwnUVxcbDhf09///nezBSIiIushuCYREBCAoKAgPPHEE7h79y6mTZvW6LjPP//cZOGIiMiyBEti3bp1yM3NxbVr15CXl4cXX3zRnLmIiMgKNLnj2tfXF76+vqitrcWECRPMlYmIiKyEqOMkHl6LmDNnjsnCEBGRdRFVEg/Lzc01RQ4iIrJCLS4JvV5vihxERGSFWlwS8fHxpshBRERWSFRJZGZmGm6HhIQYbm/atMn4iYiIyGqIKokNGzbg6NGjDR47fPiwSUIREZF1EFUSn3zyCWJjY5GTkwPgwTEUJ06cwGeffSZ6oqKiIoSFhSEoKAhhYWEoLi5uMCYpKQljx47FuHHjMHHiRHzzzTei35+IiIxP1An+vL29sXnzZkRGRmLgwIHQaDRITU2Fk5OT6IliYmIQHh6O0NBQZGRkIDo6GqmpqfXGPPPMM5g1axYcHR1RWFiIl19+GcePH0eHDh1a9qmIiMgoBNckvv3223r/q6qqwosvvoicnBzMnj0beXl5+Pbbb0VNUlFRgfz8fKhUKgCASqVCfn4+Kisr640bNmwYHB0dAQC9e/eGXq/HrVu3WvvZiIjoDxJck3jnnXcafdze3h5r164FANjY2ODrr79udhKNRgMPDw9IpVIAgFQqhbu7OzQaDdzc3Bp9zZ49e9CtWzd4eno2+/4Pk8nEr91YO7nc2dIRWsycmdvi92MM/I6b1hYzG4spPrtgSVhyp/Tp06excePGVp19tqKiBnV1LT+WwxoXrOvXq5t8vi1mNha53Nmsc1mT9vgdG8ujvFwArVs2JBKbJv9x3eLjJFpDoVBAq9VCp9MBAHQ6HcrLy6FQKBqMPXv2LJYuXYqkpCT07NnTHPGIiEiA4JrEiBEjYGNj0+wbZGdnNztGJpNBqVRCrVYjNDQUarUaSqWywaamc+fO4c0338SmTZvw5z//ufn0RERkUoIl8f777xt1otjYWKxYsQJbtmyBi4sLEhISAAARERFYsGAB+vXrh7i4OPz666+Ijo42vG79+vXo3bu3UbMQEZE4giXh5+dn1Im8vb2Rnp7e4PHk5GTD7Z07dxp1TiIi+mNEHScBAAUFBcjNzcXNmzfrneRv4cKFJglGRESWJ2rH9Y4dO/DSSy/h5MmTSE5Oxo8//oiUlBSUlJSYOh8REVmQqJLYtm0btm3bhqSkJHTo0AFJSUnYuHEjbG1Fr4gQEVEbJKokKioq4Ovr++AFEgnq6uowYsQIHDlyxKThiIjIskStCnh6euLq1avo0qULevToga+//hqdO3eGnZ2dqfMREZEFiSqJ2bNn4+LFi+jSpQsiIyOxcOFC1NbWCp66g4iI2ocmSyIzMxODBw/GxIkTDY+NGDECp0+fRm1tLR577DGTByQiIstpsiQ2btyIkpISdOvWDb6+vhg8eDAGDx6MJ554Avb29ubKSEREFtJkSWRlZeHGjRvIyclBbm4uUlJSEBUVBQ8PD/j6+sLPzw+TJ082V1YiIjKzZvdJPP744wgODkZwcDAAoKqqCjt27MD27duhVqtZEkRE7VizJaHX61FQUGBYmzh79izc3d0RHByMQYMGmSMjERFZSJMlMXfuXJw/fx5PPvkkBg0ahClTpmDdunUtumwpERG1XU0eTFdUVAR7e3t06dIF3bp1Q/fu3VkQRESPkCbXJA4ePFhvx/Vnn32GmzdvYuDAgfD19cWgQYOgVCrNlZWIiMys1Tuu//rXv6KyshIFBQUmD0lERJbR4h3XZ86cQVVVFfr27YtJkyaZIyMREVlIkyUxZ84cnD17FrW1tXjmmWfg5+eHadOmwcfHBw4ODubKSEREFtJkSfj6+uL1119Hv379eDI/IqJHULNrEkRE9OgSdT0JIiJ6NLEkiIhIEEuCiIgEma0kioqKEBYWhqCgIISFhaG4uLjBmOPHj2PixIno27cvEhISzBWNiIgEmK0kYmJiEB4ejqysLISHhyM6OrrBmK5du2L16tV47bXXzBWLiIiaYJaSqKioQH5+PlQqFQBApVIhPz8flZWV9cZ1794df/rTn2BrK+qqqkREZGJm+Wus0Wjg4eEBqVQKAJBKpXB3d4dGo4Gbm5tR55LJ2s8JCOVyZ0tHaDFzZm6L348x8DtuWlvMbCym+Ozt7p/sFRU1qKvTt/h11rhgXb9e3eTzbTGzscjlzmady5q0x+/YWB7l5QJo3bIhkdg0+Y9rs2xuUigU0Gq10Ol0AACdTofy8nIoFApzTE9ERK1klpKQyWRQKpVQq9UAALVaDaVSafRNTUREZFxm+3VTbGws0tLSEBQUhLS0NMTFxQEAIiIikJeXBwDIzc3F8OHDkZKSgq+++grDhw/HN998Y66IRET0O2bbJ+Ht7Y309PQGjycnJxtu+/r64tixY+aKREREzeAR10REJIglQUREglgSREQkiCVBRESCWBJERCSIJUFERIJYEkREJIglQUREglgSREQkiCVBRESCWBJERCSIJUFERIJYEkREJIglQUREglgSREQkiCVBRESCWBJERCSIJUFERIJYEkREJIglQUREglgSREQkiCVBRESCzFYSRUVFCAsLQ1BQEMLCwlBcXNxgjE6nQ1xcHAIDAzF69Gikp6ebKx4RETXCbCURExOD8PBwZGVlITw8HNHR0Q3G7Nu3DyUlJTh48CB27NiBxMREXL161VwRiYjod2zNMUlFRQXy8/ORkpICAFCpVFi1ahUqKyvh5uZmGJeZmYnJkydDIpHAzc0NgYGB+Pe//43Zs2eLnksisWl1TvfOjq1+rSmI+SxtMXNbnMuavuf2+h0by6O6XACt++zNvcYsJaHRaODh4QGpVAoAkEqlcHd3h0ajqVcSGo0GXl5ehvsKhQJlZWUtmqtz58danfPTlc+3+rWmIJM5NTumLWZui3NZ0/fcXr9jY3lUlwvANJ+dO66JiEiQWUpCoVBAq9VCp9MBeLCDury8HAqFosG40tJSw32NRgNPT09zRCQiokaYpSRkMhmUSiXUajUAQK1WQ6lU1tvUBABjxoxBeno66urqUFlZiUOHDiEoKMgcEYmIqBE2er1eb46JLl68iBUrVqCqqgouLi5ISEhAz549ERERgQULFqBfv37Q6XSIj4/HiRMnAAAREREICwszRzwiImqE2UqCiIjaHu64JiIiQSwJIiISxJIgIiJBLAkiIhJkliOuHwUJCQnIysrCtWvXsG/fPjz99NOWjtSkmzdvYtmyZSgpKYG9vT26d++O+Pj4Bj9LtjaRkZG4evUqJBIJOnbsiHfffRdKpdLSsZq1efNmJCYmtollAwBGjRoFe3t7ODg4AACWLFmCYcOGWTiVsLt372Lt2rX49ttv4eDggAEDBmDVqlWWjiXo6tWreOONNwz3q6urUVNTg9OnT1swVeNYEkYSEBCAGTNmYNq0aZaOIoqNjQ1mz56NIUOGAHhQch988AHWrl1r4WRNS0hIgLOzMwDg0KFDiIqKwu7duy2cqmnnz5/H999/X++UM23Bpk2b2kShAcD7778PBwcHZGVlwcbGBjdu3LB0pCZ16dIFGRkZhvtr1qwxHGxsbbi5yUh8fX0bHEFuzVxdXQ0FAQADBgyod7S7tfqtIACgpqYGNjbWfQK6e/fuIT4+HjExMVafta26ffs29uzZg4ULFxq+48cff9zCqcS7d+8e9u3bh0mTJlk6SqO4JkGoq6vDl19+iVGjRlk6iijvvPMOTpw4Ab1ej23btlk6TpM2btyIcePGoWvXrpaO0mJLliyBXq/HoEGDsHjxYri4uFg6UqOuXLkCV1dXbN68GadOncJjjz2GhQsXwtfX19LRRDl8+DA8PDzw5z//2dJRGsU1CcKqVavQsWNHvPzyy5aOIsqaNWuQnZ2NN998E+vXr7d0HEFnz55FXl4ewsPDLR2lxT7//HPs3bsXO3fuhF6vR3x8vKUjCbp//z6uXLmCP/3pT9i1axeWLFmC+fPno6amxtLRRNm5c6fVrkUALIlHXkJCAi5fvoyPP/4YEknbWhzGjx+PU6dO4ebNm5aO0qicnBxcuhVFwK0AAAnuSURBVHQJAQEBGDVqFMrKyvDaa6/h+PHjlo7WrN82ndrb2yM8PBzfffedhRMJ8/Lygq2tLVQqFQCgf//+6Ny5M4qKiiycrHlarRY5OTkICQmxdBRBbeuvAhnVRx99hP/93/9FUlIS7O3tLR2nWbdv34ZGozHcP3z4MDp16gRXV1cLphI2Z84cHD9+HIcPH8bhw4fh6emJTz/9FP7+/paO1qRffvkF1dXVAAC9Xo/MzEyr/gWZm5sbhgwZYjjnW1FRESoqKtC9e3cLJ2ve7t27MWLECHTu3NnSUQRxn4SRrF69GgcPHsSNGzfw6quvwtXVFfv377d0LEE//fQTtm7dih49emDq1KkAHvziIikpycLJhN25cwcLFy7EnTt3IJFI0KlTJ2zdupU7hI2soqIC8+fPh06nQ11dHby9vRETE2PpWE2Ki4tDVFQUEhISYGtri/Xr11vtPpSH7d69G++8846lYzSJJ/gjIiJB3NxERESCWBJERCSIJUFERIJYEkREJIglQUREglgSREZy9epV9O7dG/fv32/0+UuXLmH8+PHw8fFBamqqmdM1Ljc3F0FBQUYfS+0HfwJLJjVq1CjcuHEDUqkUUqkUTz31FEJDQxEWFtbmjvBuztWrVxEQEIDz58/D1rbhIUhRUVFwcnJCVFSUUeZLTEzE5cuX8cEHHxjl/Yga077+KyWrtHXrVpw9exZHjhxBREQEkpOTrf4AIlMoLS1Fr169WvVaobWTpuj1etTV1bVqPqLfsCTIbJydnREQEICPP/4Yu3fvxo8//ggAyM7Oxvjx4zFw4ECMGDECiYmJhtfMmTMH//jHP+q9T0hICA4dOgS9Xo+1a9di6NChGDRoEEJCQgzv+XujRo3Cf//7X8P9xMRELFmyBMCDC9YsWbIEQ4YMga+vLyZNmmS4HkF1dTWioqLg7++PYcOG4aOPPjKc91+n0yEhIQFDhgxBQEAAjh49KvjZZ8yYgVOnTiE+Ph4+Pj4oKipCdXU1li1bhmeffRYjR47Eli1bDH/Ud+3ahalTp2Lt2rXw8/Or950AwLFjx/C3v/0NBw4cgI+PD8aNGwcAmD59Oj766CNMnToV/fv3x5UrV7Bz504EBwfDx8cHAQEB+Oqrrwzvc+rUKQwfPrze9/Tpp58iJCQEgwYNwqJFi3D37t0WjwWA5ORk+Pv7w9/fH+np6ejduzcuX74s+B2RdeJpOcjsnnnmGXh6eiI3NxdPP/00HB0dkZCQgF69euHHH3/ErFmzoFQqERgYiPHjxyMlJQXTp08HABQWFqK8vBzDhw/H8ePHkZubi6ysLDg7O+PSpUv1rjch1u7du1FTU4Ps7GzY29ujoKAAHTp0AAAsX74cjz/+OA4ePIg7d+5g7ty5UCgUmDp1Kv75z3/iyJEj2LNnDxwdHTF//nzBOVJTUzF9+nSMGzcOkydPBgAsW7YM1dXVOHToEG7duoXXXnsNcrnc8Py5c+cwduxY/Pe//22wJjF8+HDMnTu30c1NGRkZSE5OxpNPPgm9Xg+ZTIa//e1v6Nq1K3JychAREYF+/foJnpr6wIED2LZtGxwcHPDSSy9h165deOmll1o09tixY9i+fTu2b9+OLl26IDo6Wtz/GWR1uCZBFuHu7o6ff/4ZADBkyBD07t0bEokEffr0wdixYw2XcQwMDMTly5dRXFwM4MEfwODgYNjb28PW1ha3b9/GpUuXoNfr4e3tDXd39xZnsbW1xa1bt3D58mVIpVL07dsXTk5OuHHjBo4dO4aoqCh07NgRMpkMM2fONJyT68CBA3jllVegUCjg6uqKuXPnip5Tp9MhMzMTb731FpycnNClSxe8+uqr2Lt3b73vaPr06bC1tTWUlhgTJkxAr169YGtrCzs7O/zlL39Bt27dYGNjAz8/Pzz33HPIzc0VfP306dPh4eEBV1dXjBw5EgUFBS0ee+DAAUycOBG9evWCo6Mj5s2bJzo/WReuSZBFaLVadOrUCQDwww8/4IMPPsBPP/2E2tpa3Lt3D2PGjAHw4FTVY8aMwd69ezFv3jyo1Wps2rQJADB06FBMmzYN8fHxKC0txejRo7F8+XI4OTm1KEtoaCjKysqwePFiVFVVYdy4cXjzzTdRWlqK+/fv1ztra11dneE02uXl5fWuRtiSy5PevHkTtbW19V7j5eUFrVZruO/p6dmiz/Gb318h8ejRo0hKSkJxcTHq6urw66+/NnlZUrlcbrjt6OiI8vLyFo8tLy9H3759BTNR28E1CTK7c+fOQavVYtCgQQCAt956y7BN/8yZM5g6dSoe/tHdhAkTsG/fPnz77bdwdHSEj4+P4bkZM2Zg165d2L9/P4qLiwWvVOfo6Ig7d+4Y7l+/ft1w287ODvPmzUNmZia++uorZGdnY8+ePfD09IS9vT1OnjyJ3Nxc5Obm4rvvvjOsScjl8nqnLn/4dnM6d+4MOzu7epeM1Wg08PDwMNxv7uy2Qs8//Pi9e/ewYMECzJo1CydOnEBubi6GDx8OU/+o0d3dvV7hteS7IevCkiCzqampwZEjR7B48WKMGzcOvXv3BvDgOhGdOnWCg4MDzp07B7VaXe91Pj4+kEgkeO+99ww7aIEHZfPDDz+gtrYWjo6OsLe3h1QqbXTuPn36IDMzE7W1tcjLy0NWVpbhuZMnT+LChQvQ6XRwcnKCra0tpFIp3N3d8dxzz+G9995DTU0N6urqUFJSYtgUFhwcjH/84x8oKyvDzz//jE8++UT0dyGVSjFmzBh89NFHqKmpwbVr15CSklLv8zVHJpPh2rVrTf6C6d69e7h37x7c3Nxga2uLo0ePGq67YEpjxozBrl27cPHiRdy5c8eqT0FPTWNJkMm9/vrr8PHxwYgRI7B161a8+uqrWLduneH5mJgYbNq0CT4+PkhKSkJwcHCD9wgNDcWPP/6I0NBQw2O3b9/GypUr4efnh5EjR8LV1RWzZs1qNMOiRYtQUlJi+KXQw1cCu3HjBhYsWIBBgwbhhRdegJ+fn+GP9fr161FbW4sXXngBgwcPxoIFCwxrIVOmTIG/vz9CQ0MxYcIEPP/88y36Xt599104OjoiMDAQ4eHhUKlULbqM5W+b5IYMGYIJEyY0OsbJyQkrV67EokWLMHjwYKjVarNcy3zEiBGYPn06ZsyYgdGjR2PAgAEA0CYubkX18WA6ahP27NmDHTt24Msvv7R0FGqFixcvQqVSIS8vr9EDDcl6cU2CrN6dO3fwxRdfICwszNJRqAX+85//4N69e/j555/x/vvvY+TIkSyINoglQVbtm2++wdChQyGTyQwXuqe24auvvsLQoUMxevRoSKVSxMbGWjoStQI3NxERkSCuSRARkSCWBBERCWJJEBGRIJYEEREJYkkQEZEglgQREQn6f5uIO8XZaI4eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([1,2,4,7], [0.57, 0.43, 0.57, 0.67])\n",
    "plt.ylabel('Walk-forward accuracy')\n",
    "plt.xlabel('Days used for training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_val, y_train_val, X_test, y_test = generate_data(l2_snap, 20, columns = ['b1','b2','b3','b4','b5', 'a1','a2','a3','a4','a5', 'bq1','bq2','bq3','bq4','bq5', 'aq1','aq2','aq3','aq4','aq5'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = generate_model(20)\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# class_weights = compute_class_weight('balanced', np.unique(y_train_val), y_train_val)\n",
    "# d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 20\n",
    "# model_filename = \"model_resnet_walkforward_tcn_depth5.h5\"\n",
    "# hist_filename = \"hist_model_walkforward_tcn_depth5.csv\"\n",
    "# early_stop = keras.callbacks.EarlyStopping(\n",
    "#                 monitor='val_loss',\n",
    "#                 patience=4)\n",
    "# model_save_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "#                             filepath= model_filename,\n",
    "#                             save_best_only=True,\n",
    "#                             monitor='val_loss',\n",
    "#                             verbose=1)\n",
    "# reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "#                 monitor='val_loss',\n",
    "#                 factor=0.5,\n",
    "#                 patience=2,\n",
    "#                 verbose=1,\n",
    "#                 min_lr=0.0001)\n",
    "# callbacks = [reduce_lr, model_save_checkpoint, early_stop]\n",
    "# history = m.fit(\n",
    "#             X_train_val, y_train_val,\n",
    "#             epochs=EPOCHS,\n",
    "#             batch_size=128,\n",
    "#             callbacks=callbacks,\n",
    "#             class_weight = d_class_weights,\n",
    "#             validation_data = (X_test, y_test),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = m.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set()\n",
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    \n",
    "# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# ax=sns.heatmap(cm, annot=True, xticklabels=['Down','Stable','Up'], yticklabels=['Down','Stable','Up'], cmap='Blues')\n",
    "# ax.set_ylim(3.0, 0)\n",
    "# plt.savefig('image_depth_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_true = y_test,y_pred = y_pred,  target_names=['Down', 'Stable', 'Up']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEPTH 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_val, y_train_val, X_test, y_test = generate_data(l2_snap, 4, columns=['b1','a1','bq1','aq1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = generate_model(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# class_weights = compute_class_weight('balanced', np.unique(y_train_val), y_train_val)\n",
    "# d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 20\n",
    "# model_filename = \"model_resnet_walkforward_tcn.h5\"\n",
    "# hist_filename = \"hist_model_walkforward_tcn.csv\"\n",
    "# early_stop = keras.callbacks.EarlyStopping(\n",
    "#                 monitor='val_loss',\n",
    "#                 patience=4)\n",
    "# model_save_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "#                             filepath= model_filename,\n",
    "#                             save_best_only=True,\n",
    "#                             monitor='val_loss',\n",
    "#                             verbose=1)\n",
    "# reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "#                 monitor='val_loss',\n",
    "#                 factor=0.5,\n",
    "#                 patience=2,\n",
    "#                 verbose=1,\n",
    "#                 min_lr=0.0001)\n",
    "# callbacks = [reduce_lr, model_save_checkpoint, early_stop]\n",
    "# history = m.fit(\n",
    "#             X_train_val, y_train_val,\n",
    "#             epochs=EPOCHS,\n",
    "#             batch_size=128,\n",
    "#             callbacks=callbacks,\n",
    "#             class_weight = d_class_weights,\n",
    "#             validation_data = (X_test, y_test),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = m.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set()\n",
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    \n",
    "# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# ax=sns.heatmap(cm, annot=True, xticklabels=['Down','Stable','Up'], yticklabels=['Down','Stable','Up'], cmap='Blues')\n",
    "# ax.set_ylim(3.0, 0)\n",
    "# plt.savefig('image_depth_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_true = y_test,y_pred = y_pred,  target_names=['Down', 'Stable', 'Up']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

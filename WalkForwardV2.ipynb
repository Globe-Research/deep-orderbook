{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from google.cloud import storage\n",
    "from io import StringIO\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client()\n",
    "bucket = client.get_bucket('bucket_l2_snapshot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob('l2_snapshot_100ms.csv')\n",
    "bt = blob.download_as_string()\n",
    "s = str(bt, 'utf-8')\n",
    "s = StringIO(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(s, index_col=0, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>...</th>\n",
       "      <th>aq1</th>\n",
       "      <th>aq2</th>\n",
       "      <th>aq3</th>\n",
       "      <th>aq4</th>\n",
       "      <th>aq5</th>\n",
       "      <th>aq6</th>\n",
       "      <th>aq7</th>\n",
       "      <th>aq8</th>\n",
       "      <th>aq9</th>\n",
       "      <th>aq10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.000</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.55</td>\n",
       "      <td>8719.50</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8717.56</td>\n",
       "      <td>8716.06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.802204</td>\n",
       "      <td>2.859</td>\n",
       "      <td>0.12189</td>\n",
       "      <td>0.142575</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.038468</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.100</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.55</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8717.56</td>\n",
       "      <td>8716.06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.802204</td>\n",
       "      <td>2.859</td>\n",
       "      <td>0.12189</td>\n",
       "      <td>0.142575</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.038468</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.200</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.61</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8716.06</td>\n",
       "      <td>8716.00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.802204</td>\n",
       "      <td>2.859</td>\n",
       "      <td>0.12189</td>\n",
       "      <td>0.142575</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.038468</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.086016</td>\n",
       "      <td>0.00189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.300</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.61</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8718.00</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8716.60</td>\n",
       "      <td>...</td>\n",
       "      <td>7.802204</td>\n",
       "      <td>2.859</td>\n",
       "      <td>0.12189</td>\n",
       "      <td>0.142575</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.038468</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.086016</td>\n",
       "      <td>0.00189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.400</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.61</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.99</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8718.00</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>...</td>\n",
       "      <td>7.802204</td>\n",
       "      <td>2.859</td>\n",
       "      <td>0.12189</td>\n",
       "      <td>0.142575</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.038468</td>\n",
       "      <td>1.086016</td>\n",
       "      <td>0.00189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              b1       b2       b3       b4      b5       b6  \\\n",
       "timestamp                                                                      \n",
       "2019-11-12 00:00:00.000  8721.53  8720.59  8719.55  8719.50  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.100  8721.53  8720.59  8719.56  8719.55  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.200  8721.53  8720.59  8719.61  8719.56  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.300  8721.53  8720.59  8719.61  8719.56  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.400  8721.53  8720.59  8719.61  8719.56  8719.0  8718.99   \n",
       "\n",
       "                              b7       b8       b9      b10  ...       aq1  \\\n",
       "timestamp                                                    ...             \n",
       "2019-11-12 00:00:00.000  8717.87  8717.85  8717.56  8716.06  ...  5.802204   \n",
       "2019-11-12 00:00:00.100  8717.87  8717.85  8717.56  8716.06  ...  5.802204   \n",
       "2019-11-12 00:00:00.200  8717.87  8717.85  8716.06  8716.00  ...  5.802204   \n",
       "2019-11-12 00:00:00.300  8718.00  8717.87  8717.85  8716.60  ...  7.802204   \n",
       "2019-11-12 00:00:00.400  8718.02  8718.00  8717.87  8717.85  ...  7.802204   \n",
       "\n",
       "                           aq2      aq3       aq4       aq5   aq6       aq7  \\\n",
       "timestamp                                                                     \n",
       "2019-11-12 00:00:00.000  2.859  0.12189  0.142575  0.002692  0.46  0.038468   \n",
       "2019-11-12 00:00:00.100  2.859  0.12189  0.142575  0.002692  0.46  0.038468   \n",
       "2019-11-12 00:00:00.200  2.859  0.12189  0.142575  0.002692  0.46  0.038468   \n",
       "2019-11-12 00:00:00.300  2.859  0.12189  0.142575  0.002692  0.46  0.038468   \n",
       "2019-11-12 00:00:00.400  2.859  0.12189  0.142575  0.002692  0.46  0.200000   \n",
       "\n",
       "                              aq8       aq9     aq10  \n",
       "timestamp                                             \n",
       "2019-11-12 00:00:00.000  0.200000  0.001890  1.00000  \n",
       "2019-11-12 00:00:00.100  0.200000  0.001890  1.00000  \n",
       "2019-11-12 00:00:00.200  0.200000  1.086016  0.00189  \n",
       "2019-11-12 00:00:00.300  0.200000  1.086016  0.00189  \n",
       "2019-11-12 00:00:00.400  0.038468  1.086016  0.00189  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_data(base_path, features):\n",
    "    \"\"\"Concatenate all the files in basepath keeping only the\n",
    "    columns specified by features.\n",
    "    \"\"\"\n",
    "    l2_snapshot = pd.DataFrame()\n",
    "    for i, x in enumerate(tqdm(sorted(os.listdir(base_path)))):\n",
    "        if base_path is None:\n",
    "            path = x\n",
    "        else:\n",
    "            path = base_path + x\n",
    "        df_hour = pd.read_parquet(path, columns=features)\n",
    "        l2_snapshot = pd.concat([l2_snapshot, df_hour.dropna()])\n",
    "        \n",
    "    return l2_snapshot\n",
    "\n",
    "def extend_matrix(A, n):\n",
    "    \"\"\"Extend a matrix A by duplicating rows as specified by the list n.\"\"\"\n",
    "    n = n[1:]  # Do not duplicate rows for the first day\n",
    "    A = A[:-1]  # Do not duplicate the last day's row\n",
    "    A = np.repeat(A, repeats=n, axis=0)\n",
    "    return A\n",
    "\n",
    "def normalise_data_per_day(df):\n",
    "    df_mean = df.resample('D').mean()\n",
    "    df_var = df.resample('D').var()\n",
    "    \n",
    "    timestamps_per_day = np.unique(df.index.date, return_counts=True)[1]\n",
    "    mean_array = extend_matrix(df_mean.to_numpy(), timestamps_per_day)\n",
    "    var_array = extend_matrix(df_var.to_numpy(), timestamps_per_day)\n",
    "    \n",
    "    # Drop the rows of the first day\n",
    "    df = df[df.index.date != df.index[0].date()]\n",
    "    \n",
    "    df = (df - mean_array) / np.sqrt(var_array)\n",
    "\n",
    "    return df\n",
    "\n",
    "def balance_classes(y):\n",
    "    unique = np.unique(y, return_counts=True)\n",
    "\n",
    "    # Take smallest number as class size\n",
    "    class_size = np.min(unique[1])\n",
    "    class_size_index = np.argmin(unique[1])\n",
    "    timestamps = np.array([], dtype=int)\n",
    "    for i, category in enumerate(unique[0]):\n",
    "        if i == class_size_index:\n",
    "            continue\n",
    "        index = np.argwhere(y==category)\n",
    "        index = index.reshape(len(index))\n",
    "        random_timestamps = np.random.choice(index, (unique[1][i] - class_size), replace=False)\n",
    "        timestamps = np.concatenate((timestamps, random_timestamps), axis=None)\n",
    "        \n",
    "    return timestamps\n",
    "\n",
    "def generate_y(df_snapshot, T=100, D=40, best_ask='a1', best_bid='b1', k=20, alpha=10e-5):\n",
    "    \"\"\"Return X, y from the snapshot dataframe and the best ask/bid columns.\"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    df['mid_price'] = (df_snapshot[best_ask].to_numpy()+df_snapshot[best_bid].to_numpy())/2\n",
    "\n",
    "    # Create columns delayed by -k to k-1\n",
    "    for i in range(-k, k):\n",
    "        df[i] = df['mid_price'].shift(periods=i)\n",
    "\n",
    "    # Drop first k-1 rows and last k rows\n",
    "    df.drop(range(0,20), axis=0, inplace=True)\n",
    "    df.drop(range(len(df_snapshot)-20,len(df_snapshot)), axis=0, inplace=True)\n",
    "    \n",
    "    # Compute mean of previous k and next k\n",
    "    df['m_b'] = df[range(0,20)].mean(axis=1)\n",
    "    df['m_a'] = df[range(-20,0)].mean(axis=1)\n",
    "    \n",
    "    # Compute label of increasing or decreasing\n",
    "    y_increase = np.where(df['m_b'] > df['m_a'] * (1+alpha), 1, 0)\n",
    "    y_decrease = np.where(df['m_b'] < df['m_a'] * (1-alpha), -1, 0)\n",
    "    y = y_increase + y_decrease\n",
    "\n",
    "    # 100 most recent limit orders used so ignore first 100 timesteps\n",
    "    y = y[T:]\n",
    "    y += 1\n",
    "\n",
    "    return y\n",
    "\n",
    "def generate_preX(df_snapshot):\n",
    "    # First and last 20 can't create labels for as previous and next k=20 needed\n",
    "    preX = df_snapshot.to_numpy()[20:-20]\n",
    "\n",
    "    return preX\n",
    "\n",
    "def generate_X(preX, T=100, D=40):\n",
    "    # For each timestep create matrix of 100 most recent limit orders\n",
    "    X = np.array([preX[t:t+T] for t in range(len(preX)-T)], dtype='float32')\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_norm = normalise_data_per_day(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>...</th>\n",
       "      <th>aq1</th>\n",
       "      <th>aq2</th>\n",
       "      <th>aq3</th>\n",
       "      <th>aq4</th>\n",
       "      <th>aq5</th>\n",
       "      <th>aq6</th>\n",
       "      <th>aq7</th>\n",
       "      <th>aq8</th>\n",
       "      <th>aq9</th>\n",
       "      <th>aq10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-13 00:00:00.000</th>\n",
       "      <td>2.069669</td>\n",
       "      <td>2.066221</td>\n",
       "      <td>2.049359</td>\n",
       "      <td>2.032164</td>\n",
       "      <td>2.045755</td>\n",
       "      <td>2.056132</td>\n",
       "      <td>2.062144</td>\n",
       "      <td>2.072841</td>\n",
       "      <td>2.064472</td>\n",
       "      <td>2.076723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630327</td>\n",
       "      <td>-0.585376</td>\n",
       "      <td>-0.603213</td>\n",
       "      <td>-0.584939</td>\n",
       "      <td>-0.568453</td>\n",
       "      <td>-0.547841</td>\n",
       "      <td>-0.503235</td>\n",
       "      <td>-0.459792</td>\n",
       "      <td>-0.545609</td>\n",
       "      <td>-0.581027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 00:00:00.100</th>\n",
       "      <td>2.096553</td>\n",
       "      <td>2.099017</td>\n",
       "      <td>2.099095</td>\n",
       "      <td>2.093216</td>\n",
       "      <td>2.076695</td>\n",
       "      <td>2.060169</td>\n",
       "      <td>2.073992</td>\n",
       "      <td>2.084426</td>\n",
       "      <td>2.090621</td>\n",
       "      <td>2.101545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630484</td>\n",
       "      <td>-0.585376</td>\n",
       "      <td>-0.603213</td>\n",
       "      <td>-0.584939</td>\n",
       "      <td>-0.568453</td>\n",
       "      <td>-0.547841</td>\n",
       "      <td>-0.559809</td>\n",
       "      <td>-0.556070</td>\n",
       "      <td>-0.552547</td>\n",
       "      <td>-0.576830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 00:00:00.200</th>\n",
       "      <td>2.096553</td>\n",
       "      <td>2.099017</td>\n",
       "      <td>2.099095</td>\n",
       "      <td>2.093216</td>\n",
       "      <td>2.076695</td>\n",
       "      <td>2.060169</td>\n",
       "      <td>2.073992</td>\n",
       "      <td>2.084426</td>\n",
       "      <td>2.090621</td>\n",
       "      <td>2.101545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630484</td>\n",
       "      <td>-0.585376</td>\n",
       "      <td>-0.603213</td>\n",
       "      <td>-0.584939</td>\n",
       "      <td>-0.568453</td>\n",
       "      <td>-0.547841</td>\n",
       "      <td>-0.559809</td>\n",
       "      <td>-0.556070</td>\n",
       "      <td>-0.552547</td>\n",
       "      <td>-0.576830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 00:00:00.300</th>\n",
       "      <td>2.096553</td>\n",
       "      <td>2.085576</td>\n",
       "      <td>2.096676</td>\n",
       "      <td>2.062824</td>\n",
       "      <td>2.046024</td>\n",
       "      <td>2.059900</td>\n",
       "      <td>2.070222</td>\n",
       "      <td>2.076344</td>\n",
       "      <td>2.087117</td>\n",
       "      <td>2.078882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630484</td>\n",
       "      <td>-0.585376</td>\n",
       "      <td>-0.603213</td>\n",
       "      <td>-0.584939</td>\n",
       "      <td>-0.568453</td>\n",
       "      <td>-0.547841</td>\n",
       "      <td>-0.559809</td>\n",
       "      <td>-0.556070</td>\n",
       "      <td>-0.552547</td>\n",
       "      <td>-0.576830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 00:00:00.400</th>\n",
       "      <td>2.096553</td>\n",
       "      <td>2.085576</td>\n",
       "      <td>2.096676</td>\n",
       "      <td>2.062824</td>\n",
       "      <td>2.046024</td>\n",
       "      <td>2.059900</td>\n",
       "      <td>2.070222</td>\n",
       "      <td>2.076344</td>\n",
       "      <td>2.064472</td>\n",
       "      <td>2.076723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630484</td>\n",
       "      <td>-0.585376</td>\n",
       "      <td>-0.603213</td>\n",
       "      <td>-0.584939</td>\n",
       "      <td>-0.568453</td>\n",
       "      <td>-0.547841</td>\n",
       "      <td>-0.559809</td>\n",
       "      <td>-0.556070</td>\n",
       "      <td>-0.552547</td>\n",
       "      <td>-0.576830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               b1        b2        b3        b4        b5  \\\n",
       "timestamp                                                                   \n",
       "2019-11-13 00:00:00.000  2.069669  2.066221  2.049359  2.032164  2.045755   \n",
       "2019-11-13 00:00:00.100  2.096553  2.099017  2.099095  2.093216  2.076695   \n",
       "2019-11-13 00:00:00.200  2.096553  2.099017  2.099095  2.093216  2.076695   \n",
       "2019-11-13 00:00:00.300  2.096553  2.085576  2.096676  2.062824  2.046024   \n",
       "2019-11-13 00:00:00.400  2.096553  2.085576  2.096676  2.062824  2.046024   \n",
       "\n",
       "                               b6        b7        b8        b9       b10  \\\n",
       "timestamp                                                                   \n",
       "2019-11-13 00:00:00.000  2.056132  2.062144  2.072841  2.064472  2.076723   \n",
       "2019-11-13 00:00:00.100  2.060169  2.073992  2.084426  2.090621  2.101545   \n",
       "2019-11-13 00:00:00.200  2.060169  2.073992  2.084426  2.090621  2.101545   \n",
       "2019-11-13 00:00:00.300  2.059900  2.070222  2.076344  2.087117  2.078882   \n",
       "2019-11-13 00:00:00.400  2.059900  2.070222  2.076344  2.064472  2.076723   \n",
       "\n",
       "                         ...       aq1       aq2       aq3       aq4  \\\n",
       "timestamp                ...                                           \n",
       "2019-11-13 00:00:00.000  ... -0.630327 -0.585376 -0.603213 -0.584939   \n",
       "2019-11-13 00:00:00.100  ... -0.630484 -0.585376 -0.603213 -0.584939   \n",
       "2019-11-13 00:00:00.200  ... -0.630484 -0.585376 -0.603213 -0.584939   \n",
       "2019-11-13 00:00:00.300  ... -0.630484 -0.585376 -0.603213 -0.584939   \n",
       "2019-11-13 00:00:00.400  ... -0.630484 -0.585376 -0.603213 -0.584939   \n",
       "\n",
       "                              aq5       aq6       aq7       aq8       aq9  \\\n",
       "timestamp                                                                   \n",
       "2019-11-13 00:00:00.000 -0.568453 -0.547841 -0.503235 -0.459792 -0.545609   \n",
       "2019-11-13 00:00:00.100 -0.568453 -0.547841 -0.559809 -0.556070 -0.552547   \n",
       "2019-11-13 00:00:00.200 -0.568453 -0.547841 -0.559809 -0.556070 -0.552547   \n",
       "2019-11-13 00:00:00.300 -0.568453 -0.547841 -0.559809 -0.556070 -0.552547   \n",
       "2019-11-13 00:00:00.400 -0.568453 -0.547841 -0.559809 -0.556070 -0.552547   \n",
       "\n",
       "                             aq10  \n",
       "timestamp                          \n",
       "2019-11-13 00:00:00.000 -0.581027  \n",
       "2019-11-13 00:00:00.100 -0.576830  \n",
       "2019-11-13 00:00:00.200 -0.576830  \n",
       "2019-11-13 00:00:00.300 -0.576830  \n",
       "2019-11-13 00:00:00.400 -0.576830  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preX Shape:  (4220032, 40)\n",
      "X shape, y shape:  (4219932, 100, 40) (4219932,)\n",
      "Unique y's:  [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "T = 100\n",
    "D = 40\n",
    "y = generate_y(l2_norm, T=T, D=D, best_ask='a1', best_bid = 'b1', alpha=0.002)\n",
    "preX = generate_preX(l2_norm)\n",
    "print(\"preX Shape: \", preX.shape)\n",
    "X = generate_X(preX)\n",
    "print(\"X shape, y shape: \", X.shape, y.shape)\n",
    "print(\"Unique y's: \", np.unique(y))\n",
    "\n",
    "del preX\n",
    "gc.collect()\n",
    "\n",
    "# First and last 20 are removed to create labels and then last 100 as previous 100 is required for input matrix\n",
    "X_index = l2_norm[20:-120].index\n",
    "\n",
    "# Number of data points for the last day\n",
    "num_test = np.unique(X_index.day, return_counts=True)[1][-1]\n",
    "\n",
    "# Split the data into the first seven days and the last day\n",
    "X_train_val = X[:-num_test]\n",
    "y_train_val = y[:-num_test]\n",
    "X_test = X[-num_test:]\n",
    "y_test = y[-num_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input, Model\n",
    "from tcn import TCN, tcn_full_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    i = Input(batch_shape=(None, 100, 40))\n",
    "    o = TCN(return_sequences=False, use_skip_connections=True, dropout_rate=0.4, dilations=[1, 2, 4, 8, 16, 32, 64], use_batch_norm=True)(i)\n",
    "    o = Dense(3, activation='softmax')(o)\n",
    "    m = Model(inputs=[i], outputs=[o])\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    m.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_train_val), y_train_val)\n",
    "d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 3754532 samples, validate on 465400 samples\n",
      "Epoch 1/1000\n",
      "INFO:tensorflow:batch_all_reduce: 60 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 60 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "3754496/3754532 [============================>.] - ETA: 0s - loss: 0.7631 - accuracy: 0.6850\n",
      "Epoch 00001: val_loss improved from inf to 0.66100, saving model to model_resnet_walkforward_tcn_actual.h5\n",
      "3754532/3754532 [==============================] - 934s 249us/sample - loss: 0.7631 - accuracy: 0.6850 - val_loss: 0.6610 - val_accuracy: 0.6530\n",
      "Epoch 2/1000\n",
      "3754368/3754532 [============================>.] - ETA: 0s - loss: 0.7186 - accuracy: 0.7191\n",
      "Epoch 00002: val_loss improved from 0.66100 to 0.65249, saving model to model_resnet_walkforward_tcn_actual.h5\n",
      "3754532/3754532 [==============================] - 831s 221us/sample - loss: 0.7186 - accuracy: 0.7191 - val_loss: 0.6525 - val_accuracy: 0.6863\n",
      "Epoch 3/1000\n",
      "3754368/3754532 [============================>.] - ETA: 0s - loss: 0.7061 - accuracy: 0.7253\n",
      "Epoch 00003: val_loss improved from 0.65249 to 0.64854, saving model to model_resnet_walkforward_tcn_actual.h5\n",
      "3754532/3754532 [==============================] - 831s 221us/sample - loss: 0.7061 - accuracy: 0.7253 - val_loss: 0.6485 - val_accuracy: 0.7433\n",
      "Epoch 4/1000\n",
      "3754496/3754532 [============================>.] - ETA: 0s - loss: 0.6982 - accuracy: 0.7281\n",
      "Epoch 00004: val_loss did not improve from 0.64854\n",
      "3754532/3754532 [==============================] - 829s 221us/sample - loss: 0.6982 - accuracy: 0.7281 - val_loss: 0.6519 - val_accuracy: 0.6770\n",
      "Epoch 5/1000\n",
      "3754368/3754532 [============================>.] - ETA: 0s - loss: 0.6922 - accuracy: 0.7299\n",
      "Epoch 00005: val_loss improved from 0.64854 to 0.64811, saving model to model_resnet_walkforward_tcn_actual.h5\n",
      "3754532/3754532 [==============================] - 829s 221us/sample - loss: 0.6922 - accuracy: 0.7299 - val_loss: 0.6481 - val_accuracy: 0.6421\n",
      "Epoch 6/1000\n",
      "3754368/3754532 [============================>.] - ETA: 0s - loss: 0.6876 - accuracy: 0.7312\n",
      "Epoch 00006: val_loss improved from 0.64811 to 0.64290, saving model to model_resnet_walkforward_tcn_actual.h5\n",
      "3754532/3754532 [==============================] - 830s 221us/sample - loss: 0.6876 - accuracy: 0.7312 - val_loss: 0.6429 - val_accuracy: 0.6118\n",
      "Epoch 7/1000\n",
      "3754496/3754532 [============================>.] - ETA: 0s - loss: 0.6840 - accuracy: 0.7317\n",
      "Epoch 00007: val_loss did not improve from 0.64290\n",
      "3754532/3754532 [==============================] - 831s 221us/sample - loss: 0.6840 - accuracy: 0.7317 - val_loss: 0.6484 - val_accuracy: 0.7022\n",
      "Epoch 8/1000\n",
      "3754496/3754532 [============================>.] - ETA: 0s - loss: 0.6812 - accuracy: 0.7331\n",
      "Epoch 00008: val_loss improved from 0.64290 to 0.63999, saving model to model_resnet_walkforward_tcn_actual.h5\n",
      "3754532/3754532 [==============================] - 831s 221us/sample - loss: 0.6812 - accuracy: 0.7331 - val_loss: 0.6400 - val_accuracy: 0.6446\n",
      "Epoch 9/1000\n",
      "3754496/3754532 [============================>.] - ETA: 0s - loss: 0.6784 - accuracy: 0.7341\n",
      "Epoch 00009: val_loss improved from 0.63999 to 0.63913, saving model to model_resnet_walkforward_tcn_actual.h5\n",
      "3754532/3754532 [==============================] - 832s 222us/sample - loss: 0.6784 - accuracy: 0.7341 - val_loss: 0.6391 - val_accuracy: 0.6525\n",
      "Epoch 10/1000\n",
      "3754496/3754532 [============================>.] - ETA: 0s - loss: 0.6759 - accuracy: 0.7348\n",
      "Epoch 00010: val_loss improved from 0.63913 to 0.63433, saving model to model_resnet_walkforward_tcn_actual.h5\n",
      "3754532/3754532 [==============================] - 830s 221us/sample - loss: 0.6759 - accuracy: 0.7348 - val_loss: 0.6343 - val_accuracy: 0.7053\n",
      "Epoch 11/1000\n",
      "3754368/3754532 [============================>.] - ETA: 0s - loss: 0.6736 - accuracy: 0.7358\n",
      "Epoch 00011: val_loss did not improve from 0.63433\n",
      "3754532/3754532 [==============================] - 830s 221us/sample - loss: 0.6737 - accuracy: 0.7358 - val_loss: 0.6431 - val_accuracy: 0.6656\n",
      "Epoch 12/1000\n",
      "3754496/3754532 [============================>.] - ETA: 0s - loss: 0.6717 - accuracy: 0.7367\n",
      "Epoch 00012: val_loss improved from 0.63433 to 0.62916, saving model to model_resnet_walkforward_tcn_actual.h5\n",
      "3754532/3754532 [==============================] - 831s 221us/sample - loss: 0.6717 - accuracy: 0.7367 - val_loss: 0.6292 - val_accuracy: 0.7084\n",
      "Epoch 13/1000\n",
      "3754496/3754532 [============================>.] - ETA: 0s - loss: 0.6704 - accuracy: 0.7368\n",
      "Epoch 00013: val_loss did not improve from 0.62916\n",
      "3754532/3754532 [==============================] - 831s 221us/sample - loss: 0.6704 - accuracy: 0.7368 - val_loss: 0.6409 - val_accuracy: 0.7432\n",
      "Epoch 14/1000\n",
      "3754496/3754532 [============================>.] - ETA: 0s - loss: 0.6688 - accuracy: 0.7373\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.62916\n",
      "3754532/3754532 [==============================] - 832s 222us/sample - loss: 0.6688 - accuracy: 0.7373 - val_loss: 0.6355 - val_accuracy: 0.6914\n",
      "Epoch 15/1000\n",
      "3754240/3754532 [============================>.] - ETA: 0s - loss: 0.6536 - accuracy: 0.7419\n",
      "Epoch 00015: val_loss did not improve from 0.62916\n",
      "3754532/3754532 [==============================] - 832s 221us/sample - loss: 0.6536 - accuracy: 0.7419 - val_loss: 0.6311 - val_accuracy: 0.6917\n",
      "Epoch 16/1000\n",
      "3754368/3754532 [============================>.] - ETA: 0s - loss: 0.6521 - accuracy: 0.7426\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.62916\n",
      "3754532/3754532 [==============================] - 829s 221us/sample - loss: 0.6521 - accuracy: 0.7426 - val_loss: 0.6410 - val_accuracy: 0.7048\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "model_filename = \"model_resnet_walkforward_tcn_actual.h5\"\n",
    "hist_filename = \"hist_model_walkforward_tcn_actual.csv\"\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=4)\n",
    "model_save_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "                            filepath= model_filename,\n",
    "                            save_best_only=True,\n",
    "                            monitor='val_loss',\n",
    "                            verbose=1)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=2,\n",
    "                verbose=1,\n",
    "                min_lr=0.0001)\n",
    "callbacks = [reduce_lr, model_save_checkpoint, early_stop]\n",
    "history = m.fit(\n",
    "            X_train_val, y_train_val,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=128,\n",
    "            callbacks=callbacks,\n",
    "            class_weight = d_class_weights,\n",
    "            validation_data = (X_test, y_test),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = m.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    \n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "ax=sns.heatmap(cm, annot=True, xticklabels=['Down','Stable','Up'], yticklabels=['Down','Stable','Up'], cmap='Blues')\n",
    "ax.set_ylim(3.0, 0)\n",
    "plt.savefig('image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down       0.45      0.55      0.50     61142\n",
      "     Stable       0.89      0.73      0.80    350499\n",
      "         Up       0.37      0.71      0.49     53759\n",
      "\n",
      "avg / total       0.77      0.70      0.73    465400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true = y_test,y_pred = y_pred,  target_names=['Down', 'Stable', 'Up']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

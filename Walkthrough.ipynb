{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from google.cloud import storage\n",
    "from io import StringIO\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client()\n",
    "bucket = client.get_bucket('bucket_l2_snapshot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob('l2_snapshot_100ms.csv')\n",
    "bt = blob.download_as_string()\n",
    "s = str(bt, 'utf-8')\n",
    "s = StringIO(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(s, index_col=0, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>...</th>\n",
       "      <th>aq1</th>\n",
       "      <th>aq2</th>\n",
       "      <th>aq3</th>\n",
       "      <th>aq4</th>\n",
       "      <th>aq5</th>\n",
       "      <th>aq6</th>\n",
       "      <th>aq7</th>\n",
       "      <th>aq8</th>\n",
       "      <th>aq9</th>\n",
       "      <th>aq10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.000</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.55</td>\n",
       "      <td>8719.50</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8717.56</td>\n",
       "      <td>8716.06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.802204</td>\n",
       "      <td>2.859</td>\n",
       "      <td>0.12189</td>\n",
       "      <td>0.142575</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.038468</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.100</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.55</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8717.56</td>\n",
       "      <td>8716.06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.802204</td>\n",
       "      <td>2.859</td>\n",
       "      <td>0.12189</td>\n",
       "      <td>0.142575</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.038468</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.200</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.61</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8716.06</td>\n",
       "      <td>8716.00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.802204</td>\n",
       "      <td>2.859</td>\n",
       "      <td>0.12189</td>\n",
       "      <td>0.142575</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.038468</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.086016</td>\n",
       "      <td>0.00189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.300</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.61</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8718.00</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8716.60</td>\n",
       "      <td>...</td>\n",
       "      <td>7.802204</td>\n",
       "      <td>2.859</td>\n",
       "      <td>0.12189</td>\n",
       "      <td>0.142575</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.038468</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.086016</td>\n",
       "      <td>0.00189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.400</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.61</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.99</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8718.00</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>...</td>\n",
       "      <td>7.802204</td>\n",
       "      <td>2.859</td>\n",
       "      <td>0.12189</td>\n",
       "      <td>0.142575</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.038468</td>\n",
       "      <td>1.086016</td>\n",
       "      <td>0.00189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              b1       b2       b3       b4      b5       b6  \\\n",
       "timestamp                                                                      \n",
       "2019-11-12 00:00:00.000  8721.53  8720.59  8719.55  8719.50  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.100  8721.53  8720.59  8719.56  8719.55  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.200  8721.53  8720.59  8719.61  8719.56  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.300  8721.53  8720.59  8719.61  8719.56  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.400  8721.53  8720.59  8719.61  8719.56  8719.0  8718.99   \n",
       "\n",
       "                              b7       b8       b9      b10  ...       aq1  \\\n",
       "timestamp                                                    ...             \n",
       "2019-11-12 00:00:00.000  8717.87  8717.85  8717.56  8716.06  ...  5.802204   \n",
       "2019-11-12 00:00:00.100  8717.87  8717.85  8717.56  8716.06  ...  5.802204   \n",
       "2019-11-12 00:00:00.200  8717.87  8717.85  8716.06  8716.00  ...  5.802204   \n",
       "2019-11-12 00:00:00.300  8718.00  8717.87  8717.85  8716.60  ...  7.802204   \n",
       "2019-11-12 00:00:00.400  8718.02  8718.00  8717.87  8717.85  ...  7.802204   \n",
       "\n",
       "                           aq2      aq3       aq4       aq5   aq6       aq7  \\\n",
       "timestamp                                                                     \n",
       "2019-11-12 00:00:00.000  2.859  0.12189  0.142575  0.002692  0.46  0.038468   \n",
       "2019-11-12 00:00:00.100  2.859  0.12189  0.142575  0.002692  0.46  0.038468   \n",
       "2019-11-12 00:00:00.200  2.859  0.12189  0.142575  0.002692  0.46  0.038468   \n",
       "2019-11-12 00:00:00.300  2.859  0.12189  0.142575  0.002692  0.46  0.038468   \n",
       "2019-11-12 00:00:00.400  2.859  0.12189  0.142575  0.002692  0.46  0.200000   \n",
       "\n",
       "                              aq8       aq9     aq10  \n",
       "timestamp                                             \n",
       "2019-11-12 00:00:00.000  0.200000  0.001890  1.00000  \n",
       "2019-11-12 00:00:00.100  0.200000  0.001890  1.00000  \n",
       "2019-11-12 00:00:00.200  0.200000  1.086016  0.00189  \n",
       "2019-11-12 00:00:00.300  0.200000  1.086016  0.00189  \n",
       "2019-11-12 00:00:00.400  0.038468  1.086016  0.00189  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_data(base_path, features):\n",
    "    \"\"\"Concatenate all the files in basepath keeping only the\n",
    "    columns specified by features.\n",
    "    \"\"\"\n",
    "    l2_snapshot = pd.DataFrame()\n",
    "    for i, x in enumerate(tqdm(sorted(os.listdir(base_path)))):\n",
    "        if base_path is None:\n",
    "            path = x\n",
    "        else:\n",
    "            path = base_path + x\n",
    "        df_hour = pd.read_parquet(path, columns=features)\n",
    "        l2_snapshot = pd.concat([l2_snapshot, df_hour.dropna()])\n",
    "        \n",
    "    return l2_snapshot\n",
    "\n",
    "def extend_matrix(A, n):\n",
    "    \"\"\"Extend a matrix A by duplicating rows as specified by the list n.\"\"\"\n",
    "    n = n[1:]  # Do not duplicate rows for the first day\n",
    "    A = A[:-1]  # Do not duplicate the last day's row\n",
    "    A = np.repeat(A, repeats=n, axis=0)\n",
    "    return A\n",
    "\n",
    "def normalise_data_per_day(df):\n",
    "    df_mean = df.resample('D').mean()\n",
    "    df_var = df.resample('D').var()\n",
    "    \n",
    "    timestamps_per_day = np.unique(df.index.date, return_counts=True)[1]\n",
    "    mean_array = extend_matrix(df_mean.to_numpy(), timestamps_per_day)\n",
    "    var_array = extend_matrix(df_var.to_numpy(), timestamps_per_day)\n",
    "    \n",
    "    # Drop the rows of the first day\n",
    "    df = df[df.index.date != df.index[0].date()]\n",
    "    \n",
    "    df = (df - mean_array) / np.sqrt(var_array)\n",
    "\n",
    "    return df\n",
    "\n",
    "def balance_classes(y):\n",
    "    unique = np.unique(y, return_counts=True)\n",
    "\n",
    "    # Take smallest number as class size\n",
    "    class_size = np.min(unique[1])\n",
    "    class_size_index = np.argmin(unique[1])\n",
    "    timestamps = np.array([], dtype=int)\n",
    "    for i, category in enumerate(unique[0]):\n",
    "        if i == class_size_index:\n",
    "            continue\n",
    "        index = np.argwhere(y==category)\n",
    "        index = index.reshape(len(index))\n",
    "        random_timestamps = np.random.choice(index, (unique[1][i] - class_size), replace=False)\n",
    "        timestamps = np.concatenate((timestamps, random_timestamps), axis=None)\n",
    "        \n",
    "    return timestamps\n",
    "\n",
    "def generate_y(df_snapshot, T=100, D=40, best_ask='a1', best_bid='b1', k=20, alpha=10e-5):\n",
    "    \"\"\"Return X, y from the snapshot dataframe and the best ask/bid columns.\"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    df['mid_price'] = (df_snapshot[best_ask].to_numpy()+df_snapshot[best_bid].to_numpy())/2\n",
    "\n",
    "    # Create columns delayed by -k to k-1\n",
    "    for i in range(-k, k):\n",
    "        df[i] = df['mid_price'].shift(periods=i)\n",
    "\n",
    "    # Drop first k-1 rows and last k rows\n",
    "    df.drop(range(0,20), axis=0, inplace=True)\n",
    "    df.drop(range(len(df_snapshot)-20,len(df_snapshot)), axis=0, inplace=True)\n",
    "    \n",
    "    # Compute mean of previous k and next k\n",
    "    df['m_b'] = df[range(0,20)].mean(axis=1)\n",
    "    df['m_a'] = df[range(-20,0)].mean(axis=1)\n",
    "    \n",
    "    # Compute label of increasing or decreasing\n",
    "    y_increase = np.where(df['m_b'] > df['m_a'] * (1+alpha), 1, 0)\n",
    "    y_decrease = np.where(df['m_b'] < df['m_a'] * (1-alpha), -1, 0)\n",
    "    y = y_increase + y_decrease\n",
    "\n",
    "    # 100 most recent limit orders used so ignore first 100 timesteps\n",
    "    y = y[T:]\n",
    "    y += 1\n",
    "\n",
    "    return y\n",
    "\n",
    "def generate_preX(df_snapshot):\n",
    "    # First and last 20 can't create labels for as previous and next k=20 needed\n",
    "    preX = df_snapshot.to_numpy()[20:-20]\n",
    "\n",
    "    return preX\n",
    "\n",
    "def generate_X(preX, T=100, D=40):\n",
    "    # For each timestep create matrix of 100 most recent limit orders\n",
    "    X = np.array([preX[t:t+T] for t in range(len(preX)-T)], dtype='float32')\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_norm = normalise_data_per_day(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>...</th>\n",
       "      <th>aq1</th>\n",
       "      <th>aq2</th>\n",
       "      <th>aq3</th>\n",
       "      <th>aq4</th>\n",
       "      <th>aq5</th>\n",
       "      <th>aq6</th>\n",
       "      <th>aq7</th>\n",
       "      <th>aq8</th>\n",
       "      <th>aq9</th>\n",
       "      <th>aq10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-13 00:00:00.000</th>\n",
       "      <td>2.069669</td>\n",
       "      <td>2.066221</td>\n",
       "      <td>2.049359</td>\n",
       "      <td>2.032164</td>\n",
       "      <td>2.045755</td>\n",
       "      <td>2.056132</td>\n",
       "      <td>2.062144</td>\n",
       "      <td>2.072841</td>\n",
       "      <td>2.064472</td>\n",
       "      <td>2.076723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630327</td>\n",
       "      <td>-0.585376</td>\n",
       "      <td>-0.603213</td>\n",
       "      <td>-0.584939</td>\n",
       "      <td>-0.568453</td>\n",
       "      <td>-0.547841</td>\n",
       "      <td>-0.503235</td>\n",
       "      <td>-0.459792</td>\n",
       "      <td>-0.545609</td>\n",
       "      <td>-0.581027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 00:00:00.100</th>\n",
       "      <td>2.096553</td>\n",
       "      <td>2.099017</td>\n",
       "      <td>2.099095</td>\n",
       "      <td>2.093216</td>\n",
       "      <td>2.076695</td>\n",
       "      <td>2.060169</td>\n",
       "      <td>2.073992</td>\n",
       "      <td>2.084426</td>\n",
       "      <td>2.090621</td>\n",
       "      <td>2.101545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630484</td>\n",
       "      <td>-0.585376</td>\n",
       "      <td>-0.603213</td>\n",
       "      <td>-0.584939</td>\n",
       "      <td>-0.568453</td>\n",
       "      <td>-0.547841</td>\n",
       "      <td>-0.559809</td>\n",
       "      <td>-0.556070</td>\n",
       "      <td>-0.552547</td>\n",
       "      <td>-0.576830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 00:00:00.200</th>\n",
       "      <td>2.096553</td>\n",
       "      <td>2.099017</td>\n",
       "      <td>2.099095</td>\n",
       "      <td>2.093216</td>\n",
       "      <td>2.076695</td>\n",
       "      <td>2.060169</td>\n",
       "      <td>2.073992</td>\n",
       "      <td>2.084426</td>\n",
       "      <td>2.090621</td>\n",
       "      <td>2.101545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630484</td>\n",
       "      <td>-0.585376</td>\n",
       "      <td>-0.603213</td>\n",
       "      <td>-0.584939</td>\n",
       "      <td>-0.568453</td>\n",
       "      <td>-0.547841</td>\n",
       "      <td>-0.559809</td>\n",
       "      <td>-0.556070</td>\n",
       "      <td>-0.552547</td>\n",
       "      <td>-0.576830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 00:00:00.300</th>\n",
       "      <td>2.096553</td>\n",
       "      <td>2.085576</td>\n",
       "      <td>2.096676</td>\n",
       "      <td>2.062824</td>\n",
       "      <td>2.046024</td>\n",
       "      <td>2.059900</td>\n",
       "      <td>2.070222</td>\n",
       "      <td>2.076344</td>\n",
       "      <td>2.087117</td>\n",
       "      <td>2.078882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630484</td>\n",
       "      <td>-0.585376</td>\n",
       "      <td>-0.603213</td>\n",
       "      <td>-0.584939</td>\n",
       "      <td>-0.568453</td>\n",
       "      <td>-0.547841</td>\n",
       "      <td>-0.559809</td>\n",
       "      <td>-0.556070</td>\n",
       "      <td>-0.552547</td>\n",
       "      <td>-0.576830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 00:00:00.400</th>\n",
       "      <td>2.096553</td>\n",
       "      <td>2.085576</td>\n",
       "      <td>2.096676</td>\n",
       "      <td>2.062824</td>\n",
       "      <td>2.046024</td>\n",
       "      <td>2.059900</td>\n",
       "      <td>2.070222</td>\n",
       "      <td>2.076344</td>\n",
       "      <td>2.064472</td>\n",
       "      <td>2.076723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630484</td>\n",
       "      <td>-0.585376</td>\n",
       "      <td>-0.603213</td>\n",
       "      <td>-0.584939</td>\n",
       "      <td>-0.568453</td>\n",
       "      <td>-0.547841</td>\n",
       "      <td>-0.559809</td>\n",
       "      <td>-0.556070</td>\n",
       "      <td>-0.552547</td>\n",
       "      <td>-0.576830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               b1        b2        b3        b4        b5  \\\n",
       "timestamp                                                                   \n",
       "2019-11-13 00:00:00.000  2.069669  2.066221  2.049359  2.032164  2.045755   \n",
       "2019-11-13 00:00:00.100  2.096553  2.099017  2.099095  2.093216  2.076695   \n",
       "2019-11-13 00:00:00.200  2.096553  2.099017  2.099095  2.093216  2.076695   \n",
       "2019-11-13 00:00:00.300  2.096553  2.085576  2.096676  2.062824  2.046024   \n",
       "2019-11-13 00:00:00.400  2.096553  2.085576  2.096676  2.062824  2.046024   \n",
       "\n",
       "                               b6        b7        b8        b9       b10  \\\n",
       "timestamp                                                                   \n",
       "2019-11-13 00:00:00.000  2.056132  2.062144  2.072841  2.064472  2.076723   \n",
       "2019-11-13 00:00:00.100  2.060169  2.073992  2.084426  2.090621  2.101545   \n",
       "2019-11-13 00:00:00.200  2.060169  2.073992  2.084426  2.090621  2.101545   \n",
       "2019-11-13 00:00:00.300  2.059900  2.070222  2.076344  2.087117  2.078882   \n",
       "2019-11-13 00:00:00.400  2.059900  2.070222  2.076344  2.064472  2.076723   \n",
       "\n",
       "                         ...       aq1       aq2       aq3       aq4  \\\n",
       "timestamp                ...                                           \n",
       "2019-11-13 00:00:00.000  ... -0.630327 -0.585376 -0.603213 -0.584939   \n",
       "2019-11-13 00:00:00.100  ... -0.630484 -0.585376 -0.603213 -0.584939   \n",
       "2019-11-13 00:00:00.200  ... -0.630484 -0.585376 -0.603213 -0.584939   \n",
       "2019-11-13 00:00:00.300  ... -0.630484 -0.585376 -0.603213 -0.584939   \n",
       "2019-11-13 00:00:00.400  ... -0.630484 -0.585376 -0.603213 -0.584939   \n",
       "\n",
       "                              aq5       aq6       aq7       aq8       aq9  \\\n",
       "timestamp                                                                   \n",
       "2019-11-13 00:00:00.000 -0.568453 -0.547841 -0.503235 -0.459792 -0.545609   \n",
       "2019-11-13 00:00:00.100 -0.568453 -0.547841 -0.559809 -0.556070 -0.552547   \n",
       "2019-11-13 00:00:00.200 -0.568453 -0.547841 -0.559809 -0.556070 -0.552547   \n",
       "2019-11-13 00:00:00.300 -0.568453 -0.547841 -0.559809 -0.556070 -0.552547   \n",
       "2019-11-13 00:00:00.400 -0.568453 -0.547841 -0.559809 -0.556070 -0.552547   \n",
       "\n",
       "                             aq10  \n",
       "timestamp                          \n",
       "2019-11-13 00:00:00.000 -0.581027  \n",
       "2019-11-13 00:00:00.100 -0.576830  \n",
       "2019-11-13 00:00:00.200 -0.576830  \n",
       "2019-11-13 00:00:00.300 -0.576830  \n",
       "2019-11-13 00:00:00.400 -0.576830  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preX Shape:  (4220032, 40)\n",
      "X shape, y shape:  (4219932, 100, 40) (4219932,)\n",
      "Unique y's:  [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "T = 100\n",
    "D = 40\n",
    "y = generate_y(l2_norm, T=T, D=D, best_ask='a1', best_bid = 'b1', alpha=0.002)\n",
    "preX = generate_preX(l2_norm)\n",
    "print(\"preX Shape: \", preX.shape)\n",
    "X = generate_X(preX)\n",
    "print(\"X shape, y shape: \", X.shape, y.shape)\n",
    "print(\"Unique y's: \", np.unique(y))\n",
    "\n",
    "del preX\n",
    "gc.collect()\n",
    "\n",
    "# First and last 20 are removed to create labels and then last 100 as previous 100 is required for input matrix\n",
    "X_index = l2_norm[20:-120].index\n",
    "\n",
    "# Number of data points for the last day\n",
    "num_test = np.unique(X_index.day, return_counts=True)[1][-1]\n",
    "\n",
    "# Split the data into the first seven days and the last day\n",
    "X_train_val = X[:-num_test]\n",
    "y_train_val = y[:-num_test]\n",
    "X_test = X[-num_test:]\n",
    "y_test = y[-num_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input, Model\n",
    "from tcn import TCN, tcn_full_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    i = Input(batch_shape=(None, 100, 40))\n",
    "    o = TCN(return_sequences=False, use_skip_connections=True, dropout_rate=0.2)(i)\n",
    "    o = Dense(3, activation='softmax')(o)\n",
    "    m = Model(inputs=[i], outputs=[o])\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    m.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_train_val), y_train_val)\n",
    "d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 3754532 samples, validate on 465400 samples\n",
      "Epoch 1/1000\n",
      "INFO:tensorflow:batch_all_reduce: 28 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 28 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "3754240/3754532 [============================>.] - ETA: 0s - loss: 0.7837 - accuracy: 0.6785\n",
      "Epoch 00001: val_loss improved from inf to 0.64774, saving model to model_resnet_walkforward_tcn.h5\n",
      "3754532/3754532 [==============================] - 506s 135us/sample - loss: 0.7837 - accuracy: 0.6785 - val_loss: 0.6477 - val_accuracy: 0.7247\n",
      "Epoch 2/1000\n",
      "3754496/3754532 [============================>.] - ETA: 0s - loss: 0.6901 - accuracy: 0.7326\n",
      "Epoch 00002: val_loss improved from 0.64774 to 0.63731, saving model to model_resnet_walkforward_tcn.h5\n",
      "3754532/3754532 [==============================] - 433s 115us/sample - loss: 0.6901 - accuracy: 0.7326 - val_loss: 0.6373 - val_accuracy: 0.7113\n",
      "Epoch 3/1000\n",
      "3754112/3754532 [============================>.] - ETA: 0s - loss: 0.6794 - accuracy: 0.7365\n",
      "Epoch 00003: val_loss did not improve from 0.63731\n",
      "3754532/3754532 [==============================] - 434s 116us/sample - loss: 0.6794 - accuracy: 0.7365 - val_loss: 0.6388 - val_accuracy: 0.7474\n",
      "Epoch 4/1000\n",
      "3754496/3754532 [============================>.] - ETA: 0s - loss: 0.6734 - accuracy: 0.7384\n",
      "Epoch 00004: val_loss improved from 0.63731 to 0.63683, saving model to model_resnet_walkforward_tcn.h5\n",
      "3754532/3754532 [==============================] - 434s 116us/sample - loss: 0.6734 - accuracy: 0.7384 - val_loss: 0.6368 - val_accuracy: 0.7244\n",
      "Epoch 5/1000\n",
      "3754112/3754532 [============================>.] - ETA: 0s - loss: 0.6691 - accuracy: 0.7396\n",
      "Epoch 00005: val_loss improved from 0.63683 to 0.62580, saving model to model_resnet_walkforward_tcn.h5\n",
      "3754532/3754532 [==============================] - 433s 115us/sample - loss: 0.6691 - accuracy: 0.7396 - val_loss: 0.6258 - val_accuracy: 0.7162\n",
      "Epoch 6/1000\n",
      "3754496/3754532 [============================>.] - ETA: 0s - loss: 0.6663 - accuracy: 0.7403\n",
      "Epoch 00006: val_loss did not improve from 0.62580\n",
      "3754532/3754532 [==============================] - 434s 116us/sample - loss: 0.6663 - accuracy: 0.7403 - val_loss: 0.6288 - val_accuracy: 0.7256\n",
      "Epoch 7/1000\n",
      "3754112/3754532 [============================>.] - ETA: 0s - loss: 0.6634 - accuracy: 0.7409\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.62580\n",
      "3754532/3754532 [==============================] - 434s 115us/sample - loss: 0.6634 - accuracy: 0.7409 - val_loss: 0.6315 - val_accuracy: 0.7172\n",
      "Epoch 8/1000\n",
      "3754112/3754532 [============================>.] - ETA: 0s - loss: 0.6404 - accuracy: 0.7496\n",
      "Epoch 00008: val_loss did not improve from 0.62580\n",
      "3754532/3754532 [==============================] - 436s 116us/sample - loss: 0.6404 - accuracy: 0.7496 - val_loss: 0.6264 - val_accuracy: 0.7098\n",
      "Epoch 9/1000\n",
      "3754496/3754532 [============================>.] - ETA: 0s - loss: 0.6339 - accuracy: 0.7503\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.62580\n",
      "3754532/3754532 [==============================] - 435s 116us/sample - loss: 0.6339 - accuracy: 0.7503 - val_loss: 0.6287 - val_accuracy: 0.6852\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "model_filename = \"model_resnet_walkforward_tcn.h5\"\n",
    "hist_filename = \"hist_model_walkforward_tcn.csv\"\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=4)\n",
    "model_save_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "                            filepath= model_filename,\n",
    "                            save_best_only=True,\n",
    "                            monitor='val_loss',\n",
    "                            verbose=1)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.2,\n",
    "                patience=2,\n",
    "                verbose=1,\n",
    "                min_lr=0.0001)\n",
    "callbacks = [reduce_lr, model_save_checkpoint, early_stop]\n",
    "history = m.fit(\n",
    "            X_train_val, y_train_val,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=128,\n",
    "            callbacks=callbacks,\n",
    "            class_weight = d_class_weights,\n",
    "            validation_data = (X_test, y_test),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = m.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD8CAYAAABAWd66AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VOX1x/HPmQRElJ0k7LKjogiyurILrf6wVFzrz62VatG2WvSn0rpgqXVHBRXclypuVVFQRAUEV4Ki7IKIQhDCDiICSc7vjxliEpZMIMncO/m++7ov59773LnnDvRw5rnPfcbcHRERSbxIogMQEZEoJWQRkYBQQhYRCQglZBGRgFBCFhEJCCVkEZGAUEIWEQkIJWQRkYBQQhYRCYjUsj5B1TMe16OAZeyNEQMSHULS69a8TqJDqBAOqWx2oO9xcIcr4s45274YdcDnK02qkEVEAqLMK2QRkXJl4a0zlZBFJLlEUhIdwX5TQhaR5HLg3dAJo4QsIslFXRYiIgGhCllEJCBUIYuIBIQqZBGRgNAoCxGRgFCXhYhIQKjLQkQkIFQhi4gEhBKyiEhApOimnohIMKgPWUQkINRlISISEKqQRUQCQhWyiEhAqEIWEQkIPTotIhIQ6rIQEQkIdVmIiASEKmQRkYBQQhYRCQjd1BMRCQj1IYuIBIS6LEREAkIVsohIMJgSsohIMCghi4gEhEWUkEOhb/uG3HlJN1IixpPvfc3dr361W5vfHt+MYWe1x4E5y9Zz8chpNE47hBeu7U3EjNTUCA9PnM+j7ywq/wsIiXmff8JLj4zE8/I4vu//0G/Q/xba/97r4/jwnTeIpKRQrUZNzr/yBuqk12PRV7N45fH789utWvE9lwy9hfbdTi7vSwi8D2dM567bR5Cbm8fA3w7i4j8MLrR/VuZM7r7jNhZ/vYjb7ribPqf0z9835LI/MOerL2nf4VjuHz2mvEMvc6qQQyASMe699DhOGz6JrHVbmX77ACbM/J6FKzbmt2lRvzrXDGxH72ET2Lh1B2nVqwCwasM2elz/Jjty8jikSiqZ9w5kwszv+WHDtkRdTmDl5ebywpi7+fMtI6lZJ53bh/6Bdl1OpH6TZvltGjVrxXX3PEblg6rwwVuv8uqTo/nDtbfSpl1Hbhj5FABbt2zmpsvO4sgOXRJ1KYGVm5vL7SOG8+DYx8mol8H555xJ9569aN6iZX6b+vXrc/Ott/HMU4/vdvwFF/2en3/exisvvVCeYZebMCfk8I4PKaFOLevyzarNLFu9hZ05ebw8YymndW5SqM3FfVoz5u0FbNy6A4A1m38GYGdOHjty8gA4KDWFSIj/wMvassULSKvXiLr1GpJaqRIdT+rNl59NL9SmTbuOVD4o+o9dszZt2bhuzW7v88VHU2h7bLf8dvKLuXO+olGTJjRq3JhKlSrT71e/ZuqU9wq1adCwEa3btNnj39Wu3Y7jkEMOKa9wy52Zxb3E8V79zWyRmS0xs+v20uYsM5tvZvPM7LkC2y80s8Wx5cJ4Yo+7Qjaz44GmBY9x96fjPT7RGtQ+hKy1W/PXs9ZvpXOrtEJtWjWoAcB7I04lJWKMeOELJs/OAqBhnUP477C+tKhXnWFPz1R1vBcb162hVt30/PVaddJZ9vW8vbb/aPIbtO3YbbftmdPfpffp55RJjGG3Jns19erVz19Pz6jH3K++TGBEAVNK9ZKZpQCjgb7ACmCmmY139/kF2rQCrgdOcPcNZpYe214buAnoBDgwK3bshn2dM64K2cyeAe4CTgQ6x5ZOJby+wEuNGC3r16DfjRO58N6pjL78BGpUrQxA1rqtdL36NY4e8hK/69GS9Bqq3A7Up1Mn8d2ShfQZeF6h7ZvWr2Xld0s5skPXBEUmYVaKFXIXYIm7L3X3HcA44PQibS4FRu9KtO6eHdveD5js7utj+yYD/SlGvBVyJ+BId/d4GpvZYGAwQKUOF5DarHucpyk7K9dvpWHdX76mNax9CCvX/VSoTda6n5i5eA05uc532T+yeOVmWtavzqxv1ua3+WHDNuZ/v4Hjj6jHa58sK6/wQ6NmnTQ2rM3OX9+wLpsaddJ2a7dw9kzefukprh4xmkqVKhfaN+vD9zmm28mkpFaYWxwlkpaewapVP+SvZ69eRXpGRgIjCpZIpNR6YhsCywusrwCKVgmtAczsQyAFuNnd397LsQ2LO2G8kc8F6sXZFncf6+6d3L1TEJIxwKwla2lZvwaHpR9KpdQIg05szoTM7wu1eeOz7zipbfQy61Q7iFYNqvPt6i00rF2VKpWjE5bUPKQyxx2RweKVm8r9GsLgsFaHk/3DCtauXknOzp3Mmv4e7bqcWKjN8qVf89xDd3D5sNupVrPWbu+R+cFkOp3Up7xCDp22Rx3N8u++I2vFCnbu3MGktybSvUevRIcVGCWpkM1ssJllFlgGF3+GQlKBVkAP4FzgETOrub+xx1uC1AXmm9lnwPZdG919wP6euLzl5jlXP/ox4//Rj5SI8fT7i1mwfCP/OKcDny9Zy4TM5UyenUXv9g2ZNXIguXnODU/PZP2P2+nVrgG3XdQF9+hTmfeNn8u87/fZFVRhpaSkcvbgqxh189Xk5eVyXO/TaNCkOW/85xEOa3k47bqexH+fGM32bdt49I6/A1CrbgaX//0OANat/oENa7NpdVSHRF5GoKWmpvJ/N/yDIZf9nrzcPAYMPIMWLVvx0Kj7ObLtUXTv2Yt5c+fwt79cweYtm/lg2hQefnAUL7/2JgCXXPg7ln27lG0//UT/3t25cfg/Of6EkxJ8VaWoBH3I7j4WGLuX3VlA4wLrjWLbCloBfOruO4Fvzexrogk6i2iSLnjs1OLisXh6Icxsj2Wuu08r7tiqZzweVzeH7L83RoTm38XQ6ta8TqJDqBAOqXzgQ5jqXjQu7pyz9slz9no+M0sFvgZ6E02wM4Hz3H1egTb9gXPd/UIzqwt8AbQndiMPODbW9HOgo7uv31c88VbILYEP3H1xnO1FRBKitMYhu3uOmV0BTCLaP/y4u88zs+FApruPj+07xczmA7nANe6+LhbHrUSTOMDw4pIxxJ+QmwBjzKwp0az/ATDd3WfHfXUiIuWgNB+ddveJwMQi224s8NqBq2NL0WMfB3Z/Mmcf4krI7n4TgJkdTHSYxzXASKL/aoiIBEaYn9SLKyGb2d+BE4BDifaRDAWm7/MgEZEESPqEDPwWyAEmANOAj919+74PEREpf2FOyHGNQ3b3Y4E+wGdEHyOcY2YzyjIwEZH9UZpzWZS3eLssjgJOAroTfWpvOeqyEJEgCl6ejVu8XRb/JpqA7wdmxgZBi4gETik+Ol3u4h1lcZqZVSb63HYbM1ukpCwiQRTEroh4xdtl0R14GlhG9AtBYzO70N0/KMPYRERKLrz5OO4ui3uAU9x9EYCZtQaeBzqWVWAiIvsj6StkoNKuZAzg7l+bWaUyiklEZL9VhIScaWaPAs/G1n8HZJZNSCIi+68iJOTLgSHAn2Pr04EHyyQiEZEDUJpzWZS3eEdZbI/9jNMz7r77L1KKiAREmCvkfQ7Ys6ibzWwtsAhYZGZrzOzGfR0nIpIoYX5Sr7gR1FcRnVSos7vXdvfaRH9T6gQzu6rMoxMRKSGz+JegKS4h/y/R2fC/3bXB3ZcC5wMXlGVgIiL7I8wVcnF9yJXcfW3Rje6+RsPeRCSIIkl8U2/Hfu4TEUmIABa+cSsuIR9jZpv3sN2AKmUQj4jIAUnaCtnd9RNNIhIqyVwhi4iEShBv1sVLCVlEkkqI87ESsogkl6SfoF5EJCxUIYuIBIT6kEVEAiLE+VgJWUSSiypkEZGACHE+VkIWkeSStE/qlYbvntSkcGWtSe/rEh1C0lsw8Z+JDqFCOKTugc/IoC4LEZGACHE+VkIWkeSiCllEJCBCnI+VkEUkueimnohIQKjLQkQkIJSQRUQCIsT5WAlZRJKLKmQRkYAIcT5WQhaR5KJRFiIiAREJcYmshCwiSSXE+VgJWUSSi27qiYgERIi7kJWQRSS5hPmmXnh/L1tEZA+sBP8r9r3M+pvZIjNbYmZ7nXjczM4wMzezTrH1pma2zcxmx5aH44ldFbKIJJXSKpDNLAUYDfQFVgAzzWy8u88v0q4a8Bfg0yJv8Y27ty/JOVUhi0hSMbO4l2J0AZa4+1J33wGMA07fQ7tbgduBnw80diVkEUkqZiVZbLCZZRZYBhd4q4bA8gLrK2LbCpzLjgUau/uEPYTSzMy+MLNpZnZSPLGry0JEkkpJHgxx97HA2P05j5lFgHuAi/aw+wegibuvM7OOwGtm1tbdN+/rPZWQRSSplOIoiyygcYH1RrFtu1QDjgKmxro/6gHjzWyAu2cC2wHcfZaZfQO0BjL3GXtpRS4iEgQl6bIoxkyglZk1M7PKwDnA+F073X2Tu9d196bu3hT4BBjg7plmlha7KYiZNQdaAUuLO6EqZBFJKqU1l4W755jZFcAkIAV43N3nmdlwINPdx+/j8JOB4Wa2E8gDLnP39cWdUwlZRJJKaT4W4u4TgYlFtt24l7Y9Crx+BXilpOdTQhaRpKK5LEREAiLET04rIYtIcgnzXBZKyCKSVNRlISISECEukJWQRSS5qEIWEQmI8KbjCvak3icfTefc357K2b/pzzNPPrLb/tmfZ3LJ7wbRvWs7prw7abf9W3/8kYG/7sU9t/+zPMINrb7d2vDlS9cy95XrGHpBzz22OaPPMXw+7hpmjRvKk7eel7/9n1ecSubzQ8l8fiiD+hxTXiGHzsxPPuT35wzgorNO44VnHttt/5zZsxhy8dn86uRjmT5lcv722bM+4/ILz8pfTuvZmY8+eL88Qy9zKRGLewmaClMh5+bmcs/tI7h39COkZ2TwhwvO5sSTe9Ksecv8Nhn16nPDzSN4/pkn9/gejzz8AMd06FhOEYdTJGKMvHYgp14xlqzsTcx46i+8OX0+C79dnd+mReO6DL2wF70uHcXGLdtIq3UoAP1POIL2bRrS9fx7OKhSKu88fDmTPl7Ilq3bE3U5gZSbm8vou//FbSPHUDc9gyv/cB7dTuzBYc1a5LdJy6jH34bdysvPP1Xo2PYdu/DQUy8CsHnzJi4+6zSO7XJcucZf1sLcZVFhKuQF8+bQqHFjGjZqTKVKlelzyq+ZMW1KoTb1GzSkZas2exw2s3DBPDasW0eXbseXV8ih1LltE75ZsY5lK9ezMyeXl96ZzWknty3U5pLfdGXMyx+yccs2ANZs+BGAI5plMOOLpeTm5vHTzzuYs2Qlpxx3eLlfQ9AtWjCXBo0aU79hIypVqkSP3v35ePrUQm3q1W9I85atidje/y8+Y8pkOnc7kSpVDi7jiMtXKc5lUe4qTEJek72a9Iz6+etp6RmsyV69jyN+kZeXx6h772TIX4eWVXhJo0FaDVas3pi/npW9kYZpNQq1adUkjVZN0nj/kSFMe+xK+nZrA8BXi1dyynFtOPigStSpUZXuHVvSKL1mucYfBuvWZJOWXi9/vW56OmvXxPd3uaCp775Nj779SzO0QIiYxb0ETVxdFmbWGngIyHD3o8ysHdFZjSpEZ+qrLz3PcSecRHpGveIbS7FSUiK0bFyXUy57iIYZNXl3zJ/odO5dvPfp13Q8sjFTHruCtRu28umc78jNy0t0uElp3do1LFu6hE5dk+8bXwDzbNzirZAfAa4HdgK4+1dEp6Lbo4Kz8D/9xO43zxIhLT2D7NU/5K+vyV5NWnpGXMfOnfMlr7z4HIP+py+jR97F2xPH89AD95RVqKG2cs0mGmX8UtU2TK9J1ppNhdpkZW/izQ/mk5Obx3cr17P4+zW0bJwGwB1PvEe38+/ltCvHYgaLv19TrvGHQZ20dNZkr8pfX5udTd20+P4u7/LB++9w/Mm9SE2tVNrhJVwp/oRTuYs3IVd198+KbMvZW2N3H+vundy90wUXX7r/0ZWiw488iuXLv2dl1gp27tzBu+9M5IST9zwCoKib/nkH/53wHi+/MZkhfx1K/18P4PIrry7jiMMpc/5yWjauy2ENalMpNYUzT2nPhOnzCrV5Y+pcTu4YvQFVp0ZVWjVJ49uV64hEjNo1qgJwVMv6HNWyAe9++nW5X0PQtTm8LVkrvmfVyhXs3LmTqe+9TbcTu5foPaZOfosefZKvuwIgxSzuJWjiHWWx1sxaAA5gZoOI/kRJaKSmpnL1NcO4+srB5OXmceqAgTRv0ZJHH36Aw49oy4nde7Fg3hxuuOYvbNm8mQ+nT+WxsaN59sV9TXkqReXm5nHVna/yxv2XkhIxnnpjJguWruYfg/vx+YLlTJg+n8mfLKJPt9Z8Pu4acvPyuOH+N1m/6ScOqpzKu2OGALBl689ccuNz5Oaqy6KolNRUhlx1PTdcfTl5uXmcctpvaNq8JU89MprWh7fluJN6sGjBXIZffxVbtmzmkw+n8fSjD/LIf14FYNUPWazJXkW7Dp0SfCVlI4Cj2eJm7l58o+iM92OB44ENwLfA+e6+rLhj12zJKf4EckCa9L4u0SEkvQUTK8TtkoRrWrfKAafTq8cvjDvn3DPg8ECl77gqZHdfCvQxs0OAiLtvKduwRET2TxD7huO1z4RsZnvsKN11we6uO1siEihh7rIorkKuVi5RiIiUkhAXyPtOyO5+S3kFIiJSGlJDnJHjGvZmZs3N7A0zW2Nm2Wb2euxGn4hIoFSER6efA14E6gMNgJeA58sqKBGR/RXmR6dL8mDIM+6eE1ueBaqUZWAiIvsjzBVycaMsasdevmVm1wHjiD4ccjYwsYxjExEpsWQeZTGLaALedYl/LLDPic5vISISGEGceD5exY2yaFZegYiIlIYQ5+P4fzHEzI4CjqRA37G7P10WQYmI7C8L8a/qxTsf8k1AD6IJeSLwK2AGoIQsIoES5go53lEWg4DewCp3vxg4Bqix70NERMpfxOJfgibeLott7p5nZjlmVh3IBhqXYVwiIvslaScXKiDTzGoS/eWQWcCPwMdlFpWIyH5KCfEvhcY7/eafYi8fNrO3geqxn3ESEQmUID6BF69457J4b9drd1/m7l8V3CYiEhRJ24dsZlWAqkBdM6vFLw+IVAcalnFsIiIlFuICudguiz8CfyU6odCsAtu3AKPKKigRkf0VCfE45OK6LD4i+jt6Q929OXALMBeYRnQGOBGRQAnz5ELFJeQxwHZ3f8DMTgZuA54CNhH90VMRkUBJjVjcS9AU12WR4u7rY6/PBsa6+yvAK2Y2u2xDExEpuSBWvvEqrkJOMbNdSbs38H6BfXHPgyEiUl7CPEF9cUn1eWCama0FtgHTAcysJdFuCxGRQAlgno1bcdNvjoiNN64PvOPuHtsVAa4s6+BEREoqxA/qFd/t4O6f7GHb12UTjojIgQliV0S81A8sIklFCVlEJCDCm47D3d0iIrKb0nwwxMz6m9kiM1sS+6HnovsvM7M5ZjbbzGaY2ZEF9l0fO26RmfWLJ3ZVyCKSVEprPmQzSwFGA32BFcBMMxvv7vMLNHvO3R+OtR8A3AP0jyXmc4C2RKeeeNfMWrt77r7OqQpZRJJKpARLMboAS9x9qbvvAMYBpxds4O6bC6weAuwaiXY6MM7dt7v7t8CS2PvtkypkEUkqpXhTryGwvMD6CqBr0UZmNgS4GqgM9CpwbMERaiuIY4bMMk/I1Q5Wzi9rn792S6JDSHpH9B2a6BAqhG1fHPgkkiXpsjCzwcDgApvGunuJ5ulx99HAaDM7D/g7cGFJji9I2VJEkkpJ+mFjyXdvCTiLwr8d2ii2bW/GAQ/t57GA+pBFJMmYWdxLMWYCrcysmZlVJnqTbnyRc7UqsHoqsDj2ejxwjpkdZGbNgFbAZ8WdUBWyiCSV0upBdvccM7sCmASkAI+7+zwzGw5kuvt44Aoz6wPsBDYQ666ItXsRmA/kAEOKG2EBSsgikmRSSvFJPXefCEwssu3GAq//so9jRwAjSnI+JWQRSSohfnJaCVlEkouF+OFpJWQRSSqqkEVEAiLMvzqthCwiSUUVsohIQGg+ZBGRgIiENx8rIYtIctEoCxGRgAhxj4USsogkF1XIIiIBoT5kEZGA0CgLEZGACG86VkIWkSSjCllEJCDCm46VkEUk2YQ4Iyshi0hSUZeFiEhAhDcdKyGLSLIJcUZWQhaRpKIn9UREAiLEXchKyCKSXEKcj5WQRSS5WIhLZCVkEUkqIc7HSsgiklxCnI+VkEUkyYQ4Iyshi0hS0bC3APtw+gfc/u8R5OXmMfCMM/n9pYML7d+xYwfDrr+WBfPmUaNmTe64+14aNmzEzh07GH7LTcyfN5eIGddeP4zOXboCsHPHDm4bcSszZ35GJGJc+eer6HNKv0RcXuB9/tmHPDrqLvJyc+l76kDOOO/iQvtff/FZJk98lZSUFKrXqMWV195Eer0GCYo2PPoefwR3XTOIlEiEJ1/7iLuemFxo/x1/+y0nd24NQNUqlUmrfSj1T74WgNdH/Yku7Zry0RdLOeMvD5d77GVNfcgBlZuby79GDGfMI0+QkZHBeWcPokfPXrRo2TK/zauvvET16tV58+3JvDVxAiPvuYs77x7JKy+/BMArr73BunXrGHLZpTz3wstEIhEeGfswtWvX5o2Jk8jLy2PTpo2JusRAy83NZcx9t3PLnQ9SJy2Day47ny7Hd6dx0+b5bZq3asPdDz/LQVUO5q3XX+KpMfdxzU23JzDq4ItEjJHXncWpl48ia/VGZvznGt6cNoeFS1flt7n27v/mv778nO4c06ZR/vq9T79L1SqV+f0ZJ5Zr3OUlzAk5kugAytLcOV/RuPFhNGrcmEqVK9P/16cydcp7hdpMef99Bpw+EIC+p/Tjs08+xt1Z+s0SunSNVsR16tShWrVqzJs7F4DXXn2FSy79IwCRSIRatWqX41WFx+KFc6nfoBH1GjSiUqVKnNirH59+OLVQm6M7dOagKgcD0ObIo1m3JjsBkYZL56Oa8s3ytSzLWsfOnFxemvQ5p/Vot9f2Z/XvyItvz8pfn/rZ12zZur08Qk0IK8H/gqZECdnMqptZtbIKprRlr15Nvfr18tfTMzJYvXp14TbZq6lXrz4AqampHFqtGhs3bqB1m8OZNuV9cnJyWLFiOQvmz2P1qh/YvHkzAKMfuI+zBw1k6FV/Zt3ateV3USGyfu0a6qb/8vnXSUtn/dq9J9x3J77GsV1PKI/QQq1Beg1WrN6Qv561egMN02rssW2T+rU4rEEdps5cVF7hJZxZ/EvQxJWQzayzmc0BvgLmmtmXZtaxbENLrN/89gwyMupx3llncOe//8Ux7TsQSUkhNzeH1atW0b59B154+VXaHdOBu+/SV+wDNXXyBJYsms/Asy9IdChJ5cx+HXntvdnk5XmiQyk3VoIlaOKtkB8D/uTuTd39MGAI8MTeGpvZYDPLNLPMxx4ZWxpx7pf0jAxW/fBLv1r26tVkZGQUbpOewapVPwCQk5PDj1u2ULNmLVJTU7nmuht48b+vc9+oh9iyZQuHHdaUmjVrUeXgg+nd9xQATunXnwXz55ffRYVI7bpprM3+5fNftyab2nXTd2v35axPefnZx7hhxEgqVa5cniGG0srsTTTKqJW/3jCjFllrNu2x7aB+HXnx7czyCi0YQpyR403Iue4+fdeKu88AcvbW2N3Hunsnd+9UdFRDeWp71NF8//0yVqxYzs4dO3h74gS69+xVqE2Pnr0Y//qrAEx+ZxJdunbDzNi2bRs//fQTAB9/9CEpKSm0aNkSM6N7j57M/OxTAD795GNatGhRvhcWEq0Ob8sPWctZ/UMWO3fuZMb7k+hyfPdCbZYuXsiD94zghhEjqam++LhkzvuOlk3SOKxBHSqlpnBmv2OZMPWr3dq1bppBrepV+eTLbxMQZeJEzOJegsbci/8qY2YjgYOB5wEHzgZ+Bp4FcPfP93bszzkk9LvS9A+mcce//0VeXi6/GXgGl/7xckY/cB9t2x5Fj1692b59O8Ouu4aFCxZQvUYN7rjrXho1bkxW1gouH/x7IpEI6ekZ3HzrCBo0aAjAypVZDLvuWrZs2UytWrUZ/s/bqN8gcUO1vs3emrBzFyfzkxk8PvoucvPy6POrAZx5/h947vGHaNnmSLqc0J0b/3YZ3327hFq16wKQllGPYSNGJjjq3R176v8lOoRC+p14JHcOHURKxHjq9U+447FJ/OPyU/l8/vdMmDYHgGF//DVVDkrlH/ePL3Tsu4/9ldbNMjj04INYv2krl93yHO9+vCARl7GbbV+MOuAs+fWqn+LOOa3rVQ1UVo43IU+JvdzVuOBFuLv3Yi8SnZArgiAn5GQRtIScrEolIa8uQULOCFZC3uc4ZDO7Ovbyzdh/HVgDzHD3ivU9SERCIYjD2eJVXB9ytdhyaGypBnQC3jKzc8o4NhGREgvzsLd9VsjufsuetptZbeBdYFxZBCUisr8CmGfjtl+PTrv7egvzLNAikrTCnJr2KyGbWU9gQ7ENRUTKWYjzcbE39ebAbqMkagMrAT1SJSKBE+J8XGyFfFqRdQfWubvGWYlIMIU4Ixd3U++78gpERKQ0hHnYW1LPhywiFU+Y+5CTej5kEal4Ihb/Uhwz629mi8xsiZldt4f9J5vZ52aWY2aDiuzLNbPZsWV80WP3RBWyiCSZ0imRzSwFGA30BVYAM81svLsXnN7xe+AiYOge3mKbu7cvyTmVkEUkqZRil0UXYIm7L42+r40DTgfyE7K7L4vtyyuNE6rLQkSSSkmmQy44d3tsKThfcENgeYH1FbFt8aoSe89PzOw38RygCllEkkpJKmR3HwuU1a9oHObuWWbWHHjfzOa4+zf7OkAVsogkFTOLeylGFtC4wHqj2La4uHtW7L9LgalAh+KOUUIWkaRSir/gNBNoZWbNzKwycA4Q12gJM6tlZgfFXtcFTqBA3/PeKCGLSFIprek33T0HuAKYBCwAXnT3eWY23MwGRM9lnc1sBXAmMMbM5sUOPwLINLMvgSnAv4uMztgj9SGLSFIpzSf13H0iMLHIthsLvJ5JtCuj6HEfAUeX9HxKyCKSXEL8pJ4SsogklRDnYyVkEUkukRBPZqGELCJJJcT5WKMsRESCQhWyiCSVMFdkrKY2AAAEEElEQVTISsgiklQ0Qb2ISECoQhYRCQglZBGRgFCXhYhIQKhCFhEJiBDnYyVkEUkyIc7ISsgiklTC/Oi0uXuiYwgcMxsc+2kXKSP6jMuePuPw0aPTeza4+CZygPQZlz19xiGjhCwiEhBKyCIiAaGEvGfqdyt7+ozLnj7jkNFNPRGRgFCFLCISEEmfkM0s18xmm9k8M/vSzP5mZkl/3eXFzIbFPtuvYp9zVzP7q5lVjePYZWZWdw/bbzazoWUTcfIxs6ZmNrfINn2GIVQRHgzZ5u7tAcwsHXgOqA7clNCokoCZHQecBhzr7ttjybUy8ALwLPBTIuMTCZsKVSm6ezbRsZlXWFQVM3vCzOaY2Rdm1hPAzCaYWbvY6y/M7MbY6+FmdqmZ9TCzqWb2spktNLP/mIX48aD9Vx9Y6+7bAdx9LTAIaABMMbMpAGb2kJllxirpW4q8x7Wxz/8zM2tZ9ARm1sLM3jazWWY23cwOL+NrSiqxv6f3xb69zDWzLomOSfauQiVkAHdfCqQA6cCQ6CY/GjgXeMrMqgDTgZPMrAaQA5wQO/wk4IPY6w7AX4EjgeYF2lQk7wCNzexrM3vQzLq7+/3ASqCnu/eMtRvm7p2AdkD3Xf/YxWyKff6jgJF7OMdY4Ep37wgMBR4ss6tJXlVj3xL/BDye6GBk7ypcQi7iRKJfrXH3hcB3QGuiCflkokl2AnBorE+0mbsvih37mbuvcPc8YDbQtJxjTzh3/xHoSPRbxxrgBTO7aA9NzzKzz4EvgLZE/xHb5fkC/z2u4EFmdihwPPCSmc0GxhCtyqWwvQ2V2rX9eQB3/wCobmY1yyUqKbGK0IdciJk1B3KB7H00mwl0ApYCk4G6wKXArAJtthd4nUsF/CwB3D0XmApMNbM5wIUF95tZM6KVbWd332BmTwJVCr7FXl5DtGDYuOsegOzVOqBWkW21gW9jr4t+rhrrGlAVqkI2szTgYWCURwdgTwd+F9vXGmgCLHL3HcBy4Ezg41i7ofzSXSGAmbUxs1YFNrUn+i1jC1Attq06sBXYZGYZwK+KvM3ZBf77ccEd7r4Z+NbMzoydz8zsmNK9ivCLfVP5wcx6AZhZbaA/MCPW5OzY9hOJdhFtSkigUqyKUNUdHPu6W4lof/AzwD2xfQ8CD8Uquxzgol03qIgm4d7uvs3MpgONYtvkF4cCD8S+AucAS4h2X5wLvG1mK929p5l9ASwk+o/ch0Xeo5aZfUX0G8e5ezjH74j+Gf2d6J/hOODLMrmacLsAGG1mu/5u3+Lu38TuNf8c+zOoBFySqACleHpSTySJmdlUYKi7ZyY6FileheqyEBEJMlXIIiIBoQpZRCQglJBFRAJCCVlEJCCUkEVEAkIJWUQkIJSQRUQC4v8BvTJQJ8HquMAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    \n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "ax=sns.heatmap(cm, annot=True, xticklabels=['Down','Stable','Up'], yticklabels=['Down','Stable','Up'], cmap='Blues')\n",
    "ax.set_ylim(3.0, 0)\n",
    "plt.savefig('image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.63      0.50     61142\n",
      "          1       0.90      0.69      0.78    350499\n",
      "          2       0.36      0.71      0.48     53759\n",
      "\n",
      "avg / total       0.77      0.69      0.71    465400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Bid Price, Moving Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network modelling p(Y = y1 |Y >= y1, X=x)\n",
    "\n",
    "There can be zero levels both in the spread as well as in the bid and ask sides. Furthermore, many changes are happening within our 100ms snapshot window. I thus see two ways by which to calculate the price level change:\n",
    "\n",
    "#### 1.\n",
    "As the price is to 0.01 accuracy one can simply take the difference in the best bid price and multiply by 100 to get it in the terms of how many $ \\$ 0.01$ levels it has increased by.\n",
    "$\n",
    "#### 2.\n",
    "Or one can approximate the price level change by taking that which is closest to the current non-zero levels present.\n",
    " e.g. if the bid price moves up in the next step to 5.20 and at the current time step there are ask price levels at 5.15, 5.18, 5.22, ... then there will be a price level increase of 2 levels. This seems somewhat more arbitrary and heavily dependent on the current state of the orderbook.\n",
    " \n",
    "$\\textbf{This is one of the things I am not sure about but I have assumed the first method}$\n",
    "$\\textbf{of defining price level change.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file \"df_snapshot_100_ms_bid_up.csv\" uses the first approach of seeing levels as the $\\$0.01$ differences. It includes only the snapshots for which a bid price increase was observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bq1</th>\n",
       "      <th>bq2</th>\n",
       "      <th>bq3</th>\n",
       "      <th>bq4</th>\n",
       "      <th>bq5</th>\n",
       "      <th>bq6</th>\n",
       "      <th>bq7</th>\n",
       "      <th>bq8</th>\n",
       "      <th>bq9</th>\n",
       "      <th>bq10</th>\n",
       "      <th>...</th>\n",
       "      <th>aq42</th>\n",
       "      <th>aq43</th>\n",
       "      <th>aq44</th>\n",
       "      <th>aq45</th>\n",
       "      <th>aq46</th>\n",
       "      <th>aq47</th>\n",
       "      <th>aq48</th>\n",
       "      <th>aq49</th>\n",
       "      <th>aq50</th>\n",
       "      <th>bid_change_n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:10.300</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.093829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>2.859000</td>\n",
       "      <td>1.083058</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>2.45536</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>0.933419</td>\n",
       "      <td>2.297440</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:19.300</th>\n",
       "      <td>5.898437</td>\n",
       "      <td>0.103284</td>\n",
       "      <td>2.862000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>2.06466</td>\n",
       "      <td>...</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>1.236624</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:19.400</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.881936</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.658088</td>\n",
       "      <td>2.862000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.200</td>\n",
       "      <td>2.203000</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.236624</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:19.500</th>\n",
       "      <td>1.901425</td>\n",
       "      <td>2.286003</td>\n",
       "      <td>2.120276</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.658088</td>\n",
       "      <td>2.862000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.103284</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>4.10000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.203</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.236624</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:19.600</th>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>0.120276</td>\n",
       "      <td>2.658088</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.103284</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>4.10000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.203</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.236624</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              bq1       bq2       bq3       bq4       bq5  \\\n",
       "timestamp                                                                   \n",
       "2019-11-12 00:00:10.300  0.020000  0.093829  1.000000  0.023100  2.859000   \n",
       "2019-11-12 00:00:19.300  5.898437  0.103284  2.862000  1.000000  0.023100   \n",
       "2019-11-12 00:00:19.400  2.000000  0.881936  2.000000  4.658088  2.862000   \n",
       "2019-11-12 00:00:19.500  1.901425  2.286003  2.120276  2.000000  2.658088   \n",
       "2019-11-12 00:00:19.600  2.200000  2.000000  2.000000  2.860000  0.120276   \n",
       "\n",
       "                              bq6     bq7       bq8     bq9     bq10  ...  \\\n",
       "timestamp                                                             ...   \n",
       "2019-11-12 00:00:10.300  1.083058  0.0600  1.000000  0.1000  2.45536  ...   \n",
       "2019-11-12 00:00:19.300  4.100000  1.0000  0.100000  0.0600  2.06466  ...   \n",
       "2019-11-12 00:00:19.400  1.000000  0.0231  4.100000  1.0000  0.10000  ...   \n",
       "2019-11-12 00:00:19.500  2.862000  1.0000  0.103284  0.0231  4.10000  ...   \n",
       "2019-11-12 00:00:19.600  2.658088  1.0000  0.103284  0.0231  4.10000  ...   \n",
       "\n",
       "                          aq42      aq43   aq44      aq45      aq46      aq47  \\\n",
       "timestamp                                                                       \n",
       "2019-11-12 00:00:10.300  2.500  0.896321  0.001  0.766000  0.001737  1.820000   \n",
       "2019-11-12 00:00:19.300  2.600  0.005000  2.500  1.236624  0.010000  0.001000   \n",
       "2019-11-12 00:00:19.400  8.200  2.203000  2.600  0.005000  2.500000  1.236624   \n",
       "2019-11-12 00:00:19.500  2.203  2.600000  0.005  2.500000  1.236624  0.010000   \n",
       "2019-11-12 00:00:19.600  2.203  2.600000  0.005  2.500000  1.236624  0.010000   \n",
       "\n",
       "                             aq48      aq49      aq50  bid_change_n  \n",
       "timestamp                                                            \n",
       "2019-11-12 00:00:10.300  0.933419  2.297440  0.052000           1.0  \n",
       "2019-11-12 00:00:19.300  0.766000  0.001737  1.820000           4.0  \n",
       "2019-11-12 00:00:19.400  0.010000  0.001000  0.766000           3.0  \n",
       "2019-11-12 00:00:19.500  0.001000  0.766000  0.001737           3.0  \n",
       "2019-11-12 00:00:19.600  0.001000  0.766000  0.001737           4.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bid_up = pd.read_csv('df_snapshot_100ms_bid_up.csv', index_col='timestamp')\n",
    "df_bid_up.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453877"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_bid_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make sure to use values.astype(int) and round as otherwise 0.99 goes to 0 and many are approximately 1. Although for bins it doens't matter.\n",
    "value_counts = np.unique(np.round(df_bid_up['bid_change_n'].values).astype(int), return_counts=True)\n",
    "plt.hist(df_bid_up['bid_change_n'], bins=100, range=(0,100))\n",
    "plt.xlabel('Increase in price levels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0,100)\n",
    "plt.title('Histogram of bid price jumps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the neural network models conditional probabilities, the conditional increase $y_1>=1$ is also an input to the neural network $f_\\theta^{1,-}(x,y_1)$. This means for every row, n duplicates can be made with $y_1$ increasing from 1 to the amount of levels it actually moves. As can be seen in the histogram above, although in most snapshots the price level change is only around 5-10, there are some snapshots where there are increases of 100 or more (max price level change is 2733 (see value_counts)). Duplicating that many rows seems somewhat bad so I could simply duplicate the rows of those snapshots that only increase by say max 20 price levels. This would however have a big effect on the accuracy of the model in the tails of the distribution. As this is of particular importance in risk modelling, this isn't a great way to do it I think. Also there wouldn't be very many datapoints to predict the probabilities given it has increased by a large amount. Although I guess this is also less important.\n",
    "\n",
    "$\\textbf{This is the second thing I'm not really sure about}.$\n",
    "\n",
    "Sirignano's paper argues the following:\n",
    "\n",
    "$p(Y_1 = y_m | X=x) = p(Y_1 = y_m | Y_1 \\geq y_m, X=x)p(Y_1 \\geq y_m |X=x)$\n",
    "\n",
    "Instead I will implement the following for cases where $y_m \\geq 20$:\n",
    "\n",
    "$p(Y_1 = y_m | X=x) = p(Y_1 = y_m | Y_1 \\geq 20, X=x)p(Y_1 \\geq 20 |X=x)$\n",
    "\n",
    "Importantly, this means that the input $y_1$ will not exceed 20 for any case.\n",
    "\n",
    "For various reasons will also get rid of all datapoints which jump by more than 100 levels. This represents around 0.8% of data but a massive proportion of the number of classes.\n",
    "\n",
    "For now actually get rid of datapoints which jump by more than 20 levels. This keeps 60% of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to advance however, I will cap the duplication of the rows of snapshots to 20.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the timestamp as this is not important\n",
    "df_bid_up.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Round the bid_change_n to the nearest integer than convert type to int\n",
    "df_bid_up['bid_change_n'] = np.round(df_bid_up['bid_change_n'].values).astype(int)\n",
    "df_bid_up = df_bid_up[df_bid_up['bid_change_n'] <= 20]\n",
    "\n",
    "# Cap the duplication to 20 rows\n",
    "reps = np.clip(df_bid_up['bid_change_n'].values,a_min=1, a_max=20)\n",
    "\n",
    "# List of indices, if want to repeat twice will appear twice but max 20x.\n",
    "df_bid_up_reps = df_bid_up.loc[np.repeat(df_bid_up.index.values, reps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forming y1_cond from the bid change_n, add to dataframe\n",
    "y1_cond = [ind for val in df_bid_up['bid_change_n'].values for ind in list(range(1,min(20,val)+1))]\n",
    "df_bid_up_reps['y1_cond'] = y1_cond\n",
    "\n",
    "#Reset index\n",
    "df_bid_up_reps.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now the full dataframe in theory (I think) with the bid_change_n being the y variable and the rest the X dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1182916, 101) (1182916,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bq1</th>\n",
       "      <th>bq2</th>\n",
       "      <th>bq3</th>\n",
       "      <th>bq4</th>\n",
       "      <th>bq5</th>\n",
       "      <th>bq6</th>\n",
       "      <th>bq7</th>\n",
       "      <th>bq8</th>\n",
       "      <th>bq9</th>\n",
       "      <th>bq10</th>\n",
       "      <th>...</th>\n",
       "      <th>aq42</th>\n",
       "      <th>aq43</th>\n",
       "      <th>aq44</th>\n",
       "      <th>aq45</th>\n",
       "      <th>aq46</th>\n",
       "      <th>aq47</th>\n",
       "      <th>aq48</th>\n",
       "      <th>aq49</th>\n",
       "      <th>aq50</th>\n",
       "      <th>y1_cond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.093829</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>2.8590</td>\n",
       "      <td>1.083058</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.45536</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820</td>\n",
       "      <td>0.933419</td>\n",
       "      <td>2.297440</td>\n",
       "      <td>0.052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.898437</td>\n",
       "      <td>0.103284</td>\n",
       "      <td>2.862</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.06466</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>1.236624</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.898437</td>\n",
       "      <td>0.103284</td>\n",
       "      <td>2.862</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.06466</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>1.236624</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.898437</td>\n",
       "      <td>0.103284</td>\n",
       "      <td>2.862</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.06466</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>1.236624</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.898437</td>\n",
       "      <td>0.103284</td>\n",
       "      <td>2.862</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.06466</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>1.236624</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bq1       bq2    bq3     bq4     bq5       bq6   bq7  bq8   bq9  \\\n",
       "0  0.020000  0.093829  1.000  0.0231  2.8590  1.083058  0.06  1.0  0.10   \n",
       "1  5.898437  0.103284  2.862  1.0000  0.0231  4.100000  1.00  0.1  0.06   \n",
       "2  5.898437  0.103284  2.862  1.0000  0.0231  4.100000  1.00  0.1  0.06   \n",
       "3  5.898437  0.103284  2.862  1.0000  0.0231  4.100000  1.00  0.1  0.06   \n",
       "4  5.898437  0.103284  2.862  1.0000  0.0231  4.100000  1.00  0.1  0.06   \n",
       "\n",
       "      bq10  ...  aq42      aq43   aq44      aq45      aq46   aq47      aq48  \\\n",
       "0  2.45536  ...   2.5  0.896321  0.001  0.766000  0.001737  1.820  0.933419   \n",
       "1  2.06466  ...   2.6  0.005000  2.500  1.236624  0.010000  0.001  0.766000   \n",
       "2  2.06466  ...   2.6  0.005000  2.500  1.236624  0.010000  0.001  0.766000   \n",
       "3  2.06466  ...   2.6  0.005000  2.500  1.236624  0.010000  0.001  0.766000   \n",
       "4  2.06466  ...   2.6  0.005000  2.500  1.236624  0.010000  0.001  0.766000   \n",
       "\n",
       "       aq49   aq50  y1_cond  \n",
       "0  2.297440  0.052        1  \n",
       "1  0.001737  1.820        1  \n",
       "2  0.001737  1.820        2  \n",
       "3  0.001737  1.820        3  \n",
       "4  0.001737  1.820        4  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_bid_up_reps.drop('bid_change_n', axis=1)\n",
    "y = df_bid_up_reps['bid_change_n']\n",
    "print(X.shape, y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20]),\n",
       " array([105912, 212206, 277236, 278924,  65740,  52536,  25900,  15016,\n",
       "         13437,  17450,  16280,  13956,  13650,  11396,  10965,  10176,\n",
       "          9775,   9756,  10545,  12060], dtype=int64))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = np.unique(y.values, return_counts=True)\n",
    "a = {unique[0][i] : unique[1][i] for i in range(0,len(unique[0]))}\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1182916, 20)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to_categorical converts class vector into matrix from 0 to num_classes hence minus 1\n",
    "y_cat = to_categorical(y.values-1)\n",
    "np.shape(y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y_cat,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model specifications in paper:\n",
    "\n",
    "4 layers\n",
    "hidden units as tanh function\n",
    "50 neurons per hidden layer\n",
    "trained for 75 epochs\n",
    "\n",
    "batch normalisation\n",
    "RMSProp algorithm for training\n",
    "adaptive learning rate\n",
    "early stopping\n",
    "$l^2$ penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(101,), activation='tanh'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "\n",
    "model.compile(RMSprop(lr=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 851698 samples, validate on 94634 samples\n",
      "Epoch 1/5\n",
      "851698/851698 [==============================] - 137s 160us/step - loss: 7.4569 - accuracy: 0.0831 - val_loss: 7.2825 - val_accuracy: 0.0861\n",
      "Epoch 2/5\n",
      "851698/851698 [==============================] - 109s 128us/step - loss: 7.1858 - accuracy: 0.0719 - val_loss: 7.1211 - val_accuracy: 0.0824\n",
      "Epoch 3/5\n",
      "851698/851698 [==============================] - 124s 146us/step - loss: 7.1340 - accuracy: 0.0691 - val_loss: 7.5712 - val_accuracy: 0.1317\n",
      "Epoch 4/5\n",
      "851698/851698 [==============================] - 104s 122us/step - loss: 7.1346 - accuracy: 0.0608 - val_loss: 7.0681 - val_accuracy: 0.0815\n",
      "Epoch 5/5\n",
      "851698/851698 [==============================] - 101s 119us/step - loss: 7.1651 - accuracy: 0.0867 - val_loss: 7.5499 - val_accuracy: 0.0857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2cb0f714c88>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mattijs\\anaconda3\\envs\\globedx\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     21306\n",
      "           1       0.00      0.00      0.00     42247\n",
      "           2       0.00      0.00      0.00     55419\n",
      "           3       0.16      1.00      0.28     55896\n",
      "           4       0.00      0.00      0.00     13118\n",
      "           5       0.00      0.00      0.00     10579\n",
      "           6       0.00      0.00      0.00      5198\n",
      "           7       0.00      0.00      0.00      3057\n",
      "           8       0.00      0.00      0.00      2736\n",
      "           9       0.00      0.00      0.00      3490\n",
      "          10       0.00      0.00      0.00      3274\n",
      "          11       0.00      0.00      0.00      2766\n",
      "          12       0.00      0.00      0.00      2678\n",
      "          13       0.00      0.00      0.00      2375\n",
      "          14       0.00      0.00      0.00      2187\n",
      "          15       0.00      0.00      0.00      2084\n",
      "          16       0.00      0.00      0.00      1938\n",
      "          17       0.00      0.00      0.00      1946\n",
      "          18       0.00      0.00      0.00      2140\n",
      "          19       0.00      0.00      0.00      2438\n",
      "          20       0.00      0.00      0.00      2065\n",
      "          21       0.00      0.00      0.00      1854\n",
      "          22       0.00      0.00      0.00      1782\n",
      "          23       0.00      0.00      0.00      1838\n",
      "          24       0.00      0.00      0.00      1829\n",
      "          25       0.00      0.00      0.00      1825\n",
      "          26       0.00      0.00      0.00      1820\n",
      "          27       0.00      0.00      0.00      1624\n",
      "          28       0.00      0.00      0.00      1641\n",
      "          29       0.00      0.00      0.00      1524\n",
      "          30       0.00      0.00      0.00      1460\n",
      "          31       0.00      0.00      0.00      1607\n",
      "          32       0.00      0.00      0.00      1456\n",
      "          33       0.00      0.00      0.00      1402\n",
      "          34       0.00      0.00      0.00      1508\n",
      "          35       0.00      0.00      0.00      1456\n",
      "          36       0.00      0.00      0.00      1420\n",
      "          37       0.00      0.00      0.00      1446\n",
      "          38       0.00      0.00      0.00      1494\n",
      "          39       0.00      0.00      0.00      1555\n",
      "          40       0.00      0.00      0.00      1348\n",
      "          41       0.00      0.00      0.00      1288\n",
      "          42       0.00      0.00      0.00      1480\n",
      "          43       0.00      0.00      0.00      1343\n",
      "          44       0.00      0.00      0.00      1499\n",
      "          45       0.00      0.00      0.00      1429\n",
      "          46       0.00      0.00      0.00      1529\n",
      "          47       0.00      0.00      0.00      1439\n",
      "          48       0.00      0.00      0.00      1706\n",
      "          49       0.00      0.00      0.00      2235\n",
      "          50       0.00      0.00      0.00      1901\n",
      "          51       0.00      0.00      0.00      1454\n",
      "          52       0.00      0.00      0.00      1147\n",
      "          53       0.00      0.00      0.00      1243\n",
      "          54       0.00      0.00      0.00      1122\n",
      "          55       0.00      0.00      0.00      1228\n",
      "          56       0.00      0.00      0.00      1232\n",
      "          57       0.00      0.00      0.00      1222\n",
      "          58       0.00      0.00      0.00      1135\n",
      "          59       0.00      0.00      0.00      1213\n",
      "          60       0.00      0.00      0.00      1375\n",
      "          61       0.00      0.00      0.00      1006\n",
      "          62       0.00      0.00      0.00      1111\n",
      "          63       0.00      0.00      0.00      1113\n",
      "          64       0.00      0.00      0.00      1161\n",
      "          65       0.00      0.00      0.00       967\n",
      "          66       0.00      0.00      0.00      1113\n",
      "          67       0.00      0.00      0.00       971\n",
      "          68       0.00      0.00      0.00      1097\n",
      "          69       0.00      0.00      0.00      1012\n",
      "          70       0.00      0.00      0.00      1082\n",
      "          71       0.00      0.00      0.00      1109\n",
      "          72       0.00      0.00      0.00       994\n",
      "          73       0.00      0.00      0.00      1047\n",
      "          74       0.00      0.00      0.00       915\n",
      "          75       0.00      0.00      0.00      1028\n",
      "          76       0.00      0.00      0.00      1484\n",
      "          77       0.00      0.00      0.00      1756\n",
      "          78       0.00      0.00      0.00      1376\n",
      "          79       0.00      0.00      0.00      1174\n",
      "          80       0.00      0.00      0.00       951\n",
      "          81       0.00      0.00      0.00      1000\n",
      "          82       0.00      0.00      0.00       991\n",
      "          83       0.00      0.00      0.00       919\n",
      "          84       0.00      0.00      0.00       985\n",
      "          85       0.00      0.00      0.00      1039\n",
      "          86       0.00      0.00      0.00      1036\n",
      "          87       0.00      0.00      0.00      1120\n",
      "          88       0.00      0.00      0.00      1183\n",
      "          89       0.00      0.00      0.00      1200\n",
      "          90       0.00      0.00      0.00      1243\n",
      "          91       0.00      0.00      0.00      1284\n",
      "          92       0.00      0.00      0.00      1355\n",
      "          93       0.00      0.00      0.00      1288\n",
      "          94       0.00      0.00      0.00      1195\n",
      "          95       0.00      0.00      0.00      1474\n",
      "          96       0.00      0.00      0.00      1648\n",
      "          97       0.00      0.00      0.00      1998\n",
      "          98       0.00      0.00      0.00      2527\n",
      "          99       0.00      0.00      0.00      4914\n",
      "\n",
      "    accuracy                           0.16    349912\n",
      "   macro avg       0.00      0.01      0.00    349912\n",
      "weighted avg       0.03      0.16      0.04    349912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_class, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(0,100),softmax(y_pred[0,:]))\n",
    "plt.ylabel('Output of tanh function')\n",
    "plt.xlabel('Classes')\n",
    "plt.title('Example prediction probabilities ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bq1</th>\n",
       "      <th>bq2</th>\n",
       "      <th>bq3</th>\n",
       "      <th>bq4</th>\n",
       "      <th>bq5</th>\n",
       "      <th>bq6</th>\n",
       "      <th>bq7</th>\n",
       "      <th>bq8</th>\n",
       "      <th>bq9</th>\n",
       "      <th>bq10</th>\n",
       "      <th>...</th>\n",
       "      <th>aq42</th>\n",
       "      <th>aq43</th>\n",
       "      <th>aq44</th>\n",
       "      <th>aq45</th>\n",
       "      <th>aq46</th>\n",
       "      <th>aq47</th>\n",
       "      <th>aq48</th>\n",
       "      <th>aq49</th>\n",
       "      <th>aq50</th>\n",
       "      <th>y1_cond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.183577</td>\n",
       "      <td>1.507875</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.918</td>\n",
       "      <td>0.184587</td>\n",
       "      <td>0.608861</td>\n",
       "      <td>0.533285</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.011079</td>\n",
       "      <td>1.066000</td>\n",
       "      <td>0.077672</td>\n",
       "      <td>0.098656</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.366582</td>\n",
       "      <td>14.316389</td>\n",
       "      <td>0.186582</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.562034</td>\n",
       "      <td>4.500</td>\n",
       "      <td>0.077994</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.1574</td>\n",
       "      <td>0.158085</td>\n",
       "      <td>3.200</td>\n",
       "      <td>0.835094</td>\n",
       "      <td>0.731420</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.782604</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085818</td>\n",
       "      <td>0.138147</td>\n",
       "      <td>0.461688</td>\n",
       "      <td>0.398700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.196465</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.904599</td>\n",
       "      <td>2.200</td>\n",
       "      <td>0.302393</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.420795</td>\n",
       "      <td>1.011000</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.090432</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>0.184793</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.022260</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.073678</td>\n",
       "      <td>0.038619</td>\n",
       "      <td>...</td>\n",
       "      <td>2.380</td>\n",
       "      <td>1.4210</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>3.120000</td>\n",
       "      <td>4.990908</td>\n",
       "      <td>2.283413</td>\n",
       "      <td>0.056589</td>\n",
       "      <td>0.836083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.747182</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.082602</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.990832</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>2.371745</td>\n",
       "      <td>8.200</td>\n",
       "      <td>2.640000</td>\n",
       "      <td>1.066535</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.686080</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bq1        bq2       bq3       bq4       bq5    bq6       bq7  \\\n",
       "0  0.183577   1.507875  0.500000  2.100000  2.000000  2.918  0.184587   \n",
       "1  0.366582  14.316389  0.186582  2.000000  0.562034  4.500  0.077994   \n",
       "2  0.085818   0.138147  0.461688  0.398700  1.000000  0.080  0.196465   \n",
       "3  0.500000   2.090432  2.000000  0.364793  0.184793  0.200  0.022260   \n",
       "4  0.747182   2.200000  2.000000  2.000000  0.082602  0.068  0.120000   \n",
       "\n",
       "        bq8       bq9      bq10  ...   aq42    aq43      aq44   aq45  \\\n",
       "0  0.608861  0.533285  0.040000  ...  0.100  0.0500  0.010000  0.001   \n",
       "1  0.300000  7.400000  0.040000  ...  5.000  0.1574  0.158085  3.200   \n",
       "2  0.800000  0.040000  1.000000  ...  0.004  0.2500  0.904599  2.200   \n",
       "3  1.000000  0.073678  0.038619  ...  2.380  1.4210  0.764000  0.600   \n",
       "4  0.990832  0.040000  0.005000  ...  2.000  0.2335  2.371745  8.200   \n",
       "\n",
       "       aq46      aq47      aq48      aq49      aq50  y1_cond  \n",
       "0  0.011079  1.066000  0.077672  0.098656  0.100000      4.0  \n",
       "1  0.835094  0.731420  0.101000  0.782604  0.200000      6.0  \n",
       "2  0.302393  0.600000  0.420795  1.011000  0.007469      2.0  \n",
       "3  3.120000  4.990908  2.283413  0.056589  0.836083      7.0  \n",
       "4  2.640000  1.066535  2.700000  3.000000  0.686080      2.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_test = pd.DataFrame(data=X_test, columns=X.columns)\n",
    "df_X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9896088 , -0.999951  ,  0.99978125, ...,  0.98836726,\n",
       "         0.969835  ,  0.95229125],\n",
       "       [ 0.9900903 , -0.99995446,  0.99979013, ...,  0.9883347 ,\n",
       "         0.9696214 ,  0.95103836],\n",
       "       [ 0.9902758 , -0.9999451 ,  0.9997718 , ...,  0.98649234,\n",
       "         0.966923  ,  0.947864  ],\n",
       "       ...,\n",
       "       [ 0.98972607, -0.99995255,  0.9997757 , ...,  0.9873505 ,\n",
       "         0.9711123 ,  0.9523374 ],\n",
       "       [ 0.9898974 , -0.9999502 ,  0.9997563 , ...,  0.98807716,\n",
       "         0.9694349 ,  0.9537922 ],\n",
       "       [ 0.99084747, -0.99994683,  0.99977446, ...,  0.98676234,\n",
       "         0.9674972 ,  0.9520482 ]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

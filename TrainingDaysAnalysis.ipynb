{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tcn in /opt/conda/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: keras==2.3.1 in /opt/conda/lib/python3.7/site-packages (from keras-tcn) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /opt/conda/lib/python3.7/site-packages (from keras-tcn) (1.18.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1->keras-tcn) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1->keras-tcn) (1.4.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1->keras-tcn) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1->keras-tcn) (1.1.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1->keras-tcn) (5.3.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1->keras-tcn) (1.0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = './content/coinbase_btc_usd/coinbase/btc_usd/l2_snapshots/100ms/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_data(base_path):\n",
    "    \"\"\"Concatenate all the files in basepath keeping only the\n",
    "    columns specified by features.\n",
    "    \"\"\"\n",
    "    l2_snapshot = pd.DataFrame()\n",
    "    for i, x in enumerate(tqdm(sorted(os.listdir(base_path)))):\n",
    "        if base_path is None:\n",
    "            path = x\n",
    "        else:\n",
    "            path = base_path + x\n",
    "        df_hour = pd.read_parquet(path)\n",
    "        l2_snapshot = pd.concat([l2_snapshot, df_hour.dropna()])\n",
    "        \n",
    "    return l2_snapshot\n",
    "\n",
    "def extend_matrix(A, n):\n",
    "    \"\"\"Extend a matrix A by duplicating rows as specified by the list n.\"\"\"\n",
    "    n = n[1:]  # Do not duplicate rows for the first day\n",
    "    A = A[:-1]  # Do not duplicate the last day's row\n",
    "    A = np.repeat(A, repeats=n, axis=0)\n",
    "    return A\n",
    "\n",
    "def normalise_data_per_day(df):\n",
    "    df_mean = df.resample('D').mean()\n",
    "    df_var = df.resample('D').var()\n",
    "    \n",
    "    timestamps_per_day = np.unique(df.index.date, return_counts=True)[1]\n",
    "    mean_array = extend_matrix(df_mean.to_numpy(), timestamps_per_day)\n",
    "    var_array = extend_matrix(df_var.to_numpy(), timestamps_per_day)\n",
    "    \n",
    "    # Drop the rows of the first day\n",
    "    df = df[df.index.date != df.index[0].date()]\n",
    "    \n",
    "    df = (df - mean_array) / np.sqrt(var_array)\n",
    "\n",
    "    return df\n",
    "\n",
    "def balance_classes(y):\n",
    "    unique = np.unique(y, return_counts=True)\n",
    "\n",
    "    # Take smallest number as class size\n",
    "    class_size = np.min(unique[1])\n",
    "    class_size_index = np.argmin(unique[1])\n",
    "    timestamps = np.array([], dtype=int)\n",
    "    for i, category in enumerate(unique[0]):\n",
    "        if i == class_size_index:\n",
    "            continue\n",
    "        index = np.argwhere(y==category)\n",
    "        index = index.reshape(len(index))\n",
    "        random_timestamps = np.random.choice(index, (unique[1][i] - class_size), replace=False)\n",
    "        timestamps = np.concatenate((timestamps, random_timestamps), axis=None)\n",
    "        \n",
    "    return timestamps\n",
    "\n",
    "def generate_y(df_snapshot, T=100, D=40, best_ask='a1', best_bid='b1', k=20, alpha=10e-5):\n",
    "    \"\"\"Return X, y from the snapshot dataframe and the best ask/bid columns.\"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    df['mid_price'] = (df_snapshot[best_ask].to_numpy()+df_snapshot[best_bid].to_numpy())/2\n",
    "\n",
    "    # Create columns delayed by -k to k-1\n",
    "    for i in range(-k, k):\n",
    "        df[i] = df['mid_price'].shift(periods=i)\n",
    "\n",
    "    # Drop first k-1 rows and last k rows\n",
    "    df.drop(range(0,20), axis=0, inplace=True)\n",
    "    df.drop(range(len(df_snapshot)-20,len(df_snapshot)), axis=0, inplace=True)\n",
    "    \n",
    "    # Compute mean of previous k and next k\n",
    "    df['m_b'] = df[range(0,20)].mean(axis=1)\n",
    "    df['m_a'] = df[range(-20,0)].mean(axis=1)\n",
    "    \n",
    "    # Compute label of increasing or decreasing\n",
    "    y_increase = np.where(df['m_b'] > df['m_a'] * (1+alpha), 1, 0)\n",
    "    y_decrease = np.where(df['m_b'] < df['m_a'] * (1-alpha), -1, 0)\n",
    "    y = y_increase + y_decrease\n",
    "\n",
    "    # 100 most recent limit orders used so ignore first 100 timesteps\n",
    "    y = y[T:]\n",
    "    y += 1\n",
    "\n",
    "    return y\n",
    "\n",
    "def generate_preX(df_snapshot):\n",
    "    preX = df_snapshot.to_numpy()[20:-20]\n",
    "\n",
    "    return preX\n",
    "\n",
    "def generate_X(preX, T=100, D=40):\n",
    "    # For each timestep create matrix of 100 most recent limit orders\n",
    "    X = np.array([preX[t:t+T] for t in range(len(preX)-T)], dtype='float32')\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [07:45<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# l2_snap = pd.read_csv('total.csv', index_col=0, infer_datetime_format=True)\n",
    "l2_snap = concat_data(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>...</th>\n",
       "      <th>aq41</th>\n",
       "      <th>aq42</th>\n",
       "      <th>aq43</th>\n",
       "      <th>aq44</th>\n",
       "      <th>aq45</th>\n",
       "      <th>aq46</th>\n",
       "      <th>aq47</th>\n",
       "      <th>aq48</th>\n",
       "      <th>aq49</th>\n",
       "      <th>aq50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.000</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.55</td>\n",
       "      <td>8719.50</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8717.56</td>\n",
       "      <td>8716.06</td>\n",
       "      <td>...</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>2.203</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>0.933419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.100</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.55</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8717.56</td>\n",
       "      <td>8716.06</td>\n",
       "      <td>...</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>2.203</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>0.933419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.200</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.61</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8716.06</td>\n",
       "      <td>8716.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>8.200</td>\n",
       "      <td>2.203</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.300</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.61</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8718.00</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>8716.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>8.200</td>\n",
       "      <td>2.203</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00.400</th>\n",
       "      <td>8721.53</td>\n",
       "      <td>8720.59</td>\n",
       "      <td>8719.61</td>\n",
       "      <td>8719.56</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>8718.99</td>\n",
       "      <td>8718.02</td>\n",
       "      <td>8718.00</td>\n",
       "      <td>8717.87</td>\n",
       "      <td>8717.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>8.200</td>\n",
       "      <td>2.203</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>1.820000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              b1       b2       b3       b4      b5       b6  \\\n",
       "timestamp                                                                      \n",
       "2019-11-12 00:00:00.000  8721.53  8720.59  8719.55  8719.50  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.100  8721.53  8720.59  8719.56  8719.55  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.200  8721.53  8720.59  8719.61  8719.56  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.300  8721.53  8720.59  8719.61  8719.56  8719.0  8718.02   \n",
       "2019-11-12 00:00:00.400  8721.53  8720.59  8719.61  8719.56  8719.0  8718.99   \n",
       "\n",
       "                              b7       b8       b9      b10  ...      aq41  \\\n",
       "timestamp                                                    ...             \n",
       "2019-11-12 00:00:00.000  8717.87  8717.85  8717.56  8716.06  ...  8.200000   \n",
       "2019-11-12 00:00:00.100  8717.87  8717.85  8717.56  8716.06  ...  8.200000   \n",
       "2019-11-12 00:00:00.200  8717.87  8717.85  8716.06  8716.00  ...  0.009135   \n",
       "2019-11-12 00:00:00.300  8718.00  8717.87  8717.85  8716.60  ...  0.009135   \n",
       "2019-11-12 00:00:00.400  8718.02  8718.00  8717.87  8717.85  ...  0.009135   \n",
       "\n",
       "                          aq42   aq43   aq44   aq45      aq46      aq47  \\\n",
       "timestamp                                                                 \n",
       "2019-11-12 00:00:00.000  2.203  2.600  0.005  2.500  0.896321  0.766000   \n",
       "2019-11-12 00:00:00.100  2.203  2.600  0.005  2.500  0.896321  0.766000   \n",
       "2019-11-12 00:00:00.200  8.200  2.203  2.600  0.005  2.500000  0.896321   \n",
       "2019-11-12 00:00:00.300  8.200  2.203  2.600  0.005  2.500000  0.896321   \n",
       "2019-11-12 00:00:00.400  8.200  2.203  2.600  0.005  2.500000  0.896321   \n",
       "\n",
       "                             aq48      aq49      aq50  \n",
       "timestamp                                              \n",
       "2019-11-12 00:00:00.000  0.001737  1.820000  0.933419  \n",
       "2019-11-12 00:00:00.100  0.001737  1.820000  0.933419  \n",
       "2019-11-12 00:00:00.200  0.766000  0.001737  1.820000  \n",
       "2019-11-12 00:00:00.300  0.766000  0.001737  1.820000  \n",
       "2019-11-12 00:00:00.400  0.766000  0.001737  1.820000  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_snap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>...</th>\n",
       "      <th>aq41</th>\n",
       "      <th>aq42</th>\n",
       "      <th>aq43</th>\n",
       "      <th>aq44</th>\n",
       "      <th>aq45</th>\n",
       "      <th>aq46</th>\n",
       "      <th>aq47</th>\n",
       "      <th>aq48</th>\n",
       "      <th>aq49</th>\n",
       "      <th>aq50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-20 23:59:57.900</th>\n",
       "      <td>8082.96</td>\n",
       "      <td>8082.23</td>\n",
       "      <td>8081.65</td>\n",
       "      <td>8080.17</td>\n",
       "      <td>8079.74</td>\n",
       "      <td>8079.69</td>\n",
       "      <td>8079.19</td>\n",
       "      <td>8077.75</td>\n",
       "      <td>8077.6</td>\n",
       "      <td>8076.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.151276</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>1.137</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.907671</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.74149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 23:59:58.400</th>\n",
       "      <td>8082.96</td>\n",
       "      <td>8082.23</td>\n",
       "      <td>8081.65</td>\n",
       "      <td>8080.17</td>\n",
       "      <td>8079.74</td>\n",
       "      <td>8079.69</td>\n",
       "      <td>8079.19</td>\n",
       "      <td>8077.75</td>\n",
       "      <td>8077.6</td>\n",
       "      <td>8076.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.151276</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>1.137</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.907671</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.74149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 23:59:58.500</th>\n",
       "      <td>8082.96</td>\n",
       "      <td>8082.23</td>\n",
       "      <td>8081.65</td>\n",
       "      <td>8080.17</td>\n",
       "      <td>8079.74</td>\n",
       "      <td>8079.69</td>\n",
       "      <td>8079.19</td>\n",
       "      <td>8077.75</td>\n",
       "      <td>8077.6</td>\n",
       "      <td>8076.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.151276</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>1.137</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.907671</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.74149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 23:59:58.800</th>\n",
       "      <td>8082.96</td>\n",
       "      <td>8082.23</td>\n",
       "      <td>8081.65</td>\n",
       "      <td>8080.17</td>\n",
       "      <td>8079.74</td>\n",
       "      <td>8079.69</td>\n",
       "      <td>8079.19</td>\n",
       "      <td>8077.75</td>\n",
       "      <td>8077.6</td>\n",
       "      <td>8076.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.151276</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>1.137</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.907671</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.74149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 23:59:59.600</th>\n",
       "      <td>8082.96</td>\n",
       "      <td>8082.23</td>\n",
       "      <td>8081.65</td>\n",
       "      <td>8080.17</td>\n",
       "      <td>8079.74</td>\n",
       "      <td>8079.69</td>\n",
       "      <td>8079.19</td>\n",
       "      <td>8077.75</td>\n",
       "      <td>8077.6</td>\n",
       "      <td>8076.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.151276</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>1.137</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.907671</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.74149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              b1       b2       b3       b4       b5       b6  \\\n",
       "timestamp                                                                       \n",
       "2019-11-20 23:59:57.900  8082.96  8082.23  8081.65  8080.17  8079.74  8079.69   \n",
       "2019-11-20 23:59:58.400  8082.96  8082.23  8081.65  8080.17  8079.74  8079.69   \n",
       "2019-11-20 23:59:58.500  8082.96  8082.23  8081.65  8080.17  8079.74  8079.69   \n",
       "2019-11-20 23:59:58.800  8082.96  8082.23  8081.65  8080.17  8079.74  8079.69   \n",
       "2019-11-20 23:59:59.600  8082.96  8082.23  8081.65  8080.17  8079.74  8079.69   \n",
       "\n",
       "                              b7       b8      b9      b10  ...   aq41  \\\n",
       "timestamp                                                   ...          \n",
       "2019-11-20 23:59:57.900  8079.19  8077.75  8077.6  8076.88  ...  0.005   \n",
       "2019-11-20 23:59:58.400  8079.19  8077.75  8077.6  8076.88  ...  0.005   \n",
       "2019-11-20 23:59:58.500  8079.19  8077.75  8077.6  8076.88  ...  0.005   \n",
       "2019-11-20 23:59:58.800  8079.19  8077.75  8077.6  8076.88  ...  0.005   \n",
       "2019-11-20 23:59:59.600  8079.19  8077.75  8077.6  8076.88  ...  0.005   \n",
       "\n",
       "                             aq42    aq43   aq44  aq45      aq46   aq47  \\\n",
       "timestamp                                                                 \n",
       "2019-11-20 23:59:57.900  0.151276  0.0058  1.137   0.6  0.907671  0.001   \n",
       "2019-11-20 23:59:58.400  0.151276  0.0058  1.137   0.6  0.907671  0.001   \n",
       "2019-11-20 23:59:58.500  0.151276  0.0058  1.137   0.6  0.907671  0.001   \n",
       "2019-11-20 23:59:58.800  0.151276  0.0058  1.137   0.6  0.907671  0.001   \n",
       "2019-11-20 23:59:59.600  0.151276  0.0058  1.137   0.6  0.907671  0.001   \n",
       "\n",
       "                          aq48  aq49     aq50  \n",
       "timestamp                                      \n",
       "2019-11-20 23:59:57.900  0.001   2.4  0.74149  \n",
       "2019-11-20 23:59:58.400  0.001   2.4  0.74149  \n",
       "2019-11-20 23:59:58.500  0.001   2.4  0.74149  \n",
       "2019-11-20 23:59:58.800  0.001   2.4  0.74149  \n",
       "2019-11-20 23:59:59.600  0.001   2.4  0.74149  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_snap.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Model and Depth Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input, Model\n",
    "from tcn import TCN, tcn_full_summary\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(depth):\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "\n",
    "        i = Input(batch_shape=(None, 100, depth))\n",
    "        o = TCN(return_sequences=False, use_skip_connections=True, dropout_rate=0.4, dilations=[1, 2, 4, 8, 16, 32, 64], use_batch_norm=True)(i)\n",
    "        o = Dense(3, activation='softmax')(o)\n",
    "        m = Model(inputs=[i], outputs=[o])\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "        m.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(l2_snap, depth, columns, days_training):\n",
    "    l2_snap.index = pd.to_datetime(l2_snap.index)\n",
    "    l2_snap_dep2 = l2_snap.loc[:,columns]\n",
    "    l2_norm = normalise_data_per_day(l2_snap_dep2)\n",
    "    T = 100\n",
    "    D = depth\n",
    "    y = generate_y(l2_norm, T=T, D=D, best_ask='a1', best_bid = 'b1', alpha=0.002)\n",
    "    preX = generate_preX(l2_norm)\n",
    "    print(\"preX Shape: \", preX.shape)\n",
    "    X = generate_X(preX)\n",
    "    print(\"X shape, y shape: \", X.shape, y.shape)\n",
    "    print(\"Unique y's: \", np.unique(y))\n",
    "\n",
    "    del preX\n",
    "    gc.collect()\n",
    "\n",
    "    # First and last 20 are removed to create labels and then last 100 as previous 100 is required for input matrix\n",
    "    X_index = l2_norm[20:-120].index\n",
    "\n",
    "    # Number of data points for the last day\n",
    "    num_test = np.unique(X_index.day, return_counts=True)[1][-1]\n",
    "\n",
    "    # Days back to\n",
    "    num_start = np.unique(X_index.day, return_counts=True)[1][-1 - days_training:].sum()\n",
    "\n",
    "    # Split the data into the first days and the last day\n",
    "    X_train_val = X[-num_start:-num_test]\n",
    "    y_train_val = y[-num_start:-num_test]\n",
    "    X_test = X[-num_test:]\n",
    "    y_test = y[-num_test:]\n",
    "    return X_train_val, y_train_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth:10\n",
    "\n",
    "\n",
    "#### Days 1, 2, 4, 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days Training now  2\n",
      "preX Shape:  (4220032, 40)\n",
      "X shape, y shape:  (4219932, 100, 40) (4219932,)\n",
      "Unique y's:  [0 1 2]\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/20\n",
      "INFO:tensorflow:batch_all_reduce: 60 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 60 all-reduces with algorithm = nccl, num_packs = 1\n",
      "8080/8082 [============================>.] - ETA: 0s - loss: 0.7682 - accuracy: 0.5284\n",
      "Epoch 00001: val_loss improved from inf to 1.03368, saving model to model_resnet_walkforward_tcn_depth10.h5\n",
      "8082/8082 [==============================] - 232s 29ms/step - loss: 0.7682 - accuracy: 0.5284 - val_loss: 1.0337 - val_accuracy: 0.4117 - lr: 0.0100\n",
      "Epoch 2/20\n",
      "8082/8082 [==============================] - ETA: 0s - loss: 0.6999 - accuracy: 0.6029\n",
      "Epoch 00002: val_loss did not improve from 1.03368\n",
      "8082/8082 [==============================] - 221s 27ms/step - loss: 0.6999 - accuracy: 0.6029 - val_loss: 1.6836 - val_accuracy: 0.3617 - lr: 0.0100\n",
      "Epoch 3/20\n",
      "5388/8082 [===================>..........] - ETA: 59s - loss: 0.6828 - accuracy: 0.6164"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-78b2b7fe47b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_class_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for days_training in [1,2,4,7]:\n",
    "for days_training in [2]:\n",
    "    print('Days Training now ', days_training)\n",
    "    X_train_val, y_train_val, X_test, y_test = generate_data(l2_snap, 40, columns = ['b1','b2','b3','b4','b5','b6','b7','b8', 'b9', 'b10', 'a1','a2','a3','a4','a5','a6','a7','a8', 'a9', 'a10', 'bq1','bq2','bq3','bq4','bq5','bq6','bq7','bq8', 'bq9', 'bq10', 'aq1','aq2','aq3','aq4','aq5','aq6','aq7','aq8', 'aq9', 'aq10'], days_training=days_training)\n",
    "    m = generate_model(40)\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    class_weights = compute_class_weight('balanced', np.unique(y_train_val), y_train_val)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    EPOCHS = 20\n",
    "    model_filename = \"model_resnet_walkforward_tcn_depth10.h5\"\n",
    "    hist_filename = \"hist_model_walkforward_tcn_depth10.csv\"\n",
    "    early_stop = keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=4)\n",
    "    model_save_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "                                filepath= model_filename,\n",
    "                                save_best_only=True,\n",
    "                                monitor='val_loss',\n",
    "                                verbose=1)\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor='val_loss',\n",
    "                    factor=0.5,\n",
    "                    patience=2,\n",
    "                    verbose=1,\n",
    "                    min_lr=0.0001)\n",
    "    callbacks = [reduce_lr, model_save_checkpoint, early_stop]\n",
    "    history = m.fit(\n",
    "                X_train_val, y_train_val,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=128,\n",
    "                callbacks=callbacks,\n",
    "                class_weight = d_class_weights,\n",
    "                validation_data = (X_test, y_test),\n",
    "    )\n",
    "\n",
    "    y_pred = m.predict(X_test).argmax(axis=1)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set()\n",
    "    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    ax=sns.heatmap(cm, annot=True, xticklabels=['Down','Stable','Up'], yticklabels=['Down','Stable','Up'], cmap='Blues')\n",
    "    ax.set_ylim(3.0, 0)\n",
    "    plt.savefig('image_depth_10_{}_days_training'.format(days_training))\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_true = y_test,y_pred = y_pred,  target_names=['Down', 'Stable', 'Up']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEQCAYAAABFtIg2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deVyU5fo/8M/MsIiyI8sgKmqmU27IYv5CScFQQ8cdwzQr0Y6ZtpjytRKXSrE8pWhaedI82slTauio6XFPKwW1RNEsBREZBtlkEQFn5vcHOjnJ6DPILAyf9+t1XocZnpnnusDm4rnv+7ofkVar1YKIiKgOYksHQERE1otFgoiIDGKRICIig1gkiIjIIBYJIiIyiEWCiIgMsjPXiTIzM5GQkICSkhK4u7sjKSkJgYGBesfMmjULv//+u+7x77//jpUrVyIyMtJcYRIR0V1E5uqTmDBhAkaOHAm5XI6UlBRs3rwZ69evN3j8+fPn8fzzz+PHH3+Eg4ODOUIkIqK/MctwU2FhITIyMhATEwMAiImJQUZGBoqKigy+5rvvvsOQIUNYIIiILMgsRUKpVMLX1xcSiQQAIJFI4OPjA6VSWefx1dXV2L59O0aOHGmO8IiIyACrnLjeu3cv/P39IZPJLB0KEVGTZpaJa6lUCpVKBbVaDYlEArVajfz8fEil0jqP37x5c72vIoqLK6DRGD/N4uXljMLC8nqd09owF+tjK3kAzMVa1TcXsVgED48WBr9vliLh5eUFmUwGhUIBuVwOhUIBmUwGT0/Pe47Ny8vDiRMnsHTp0nqdS6PR1qtI3HmtrWAu1sdW8gCYi7UyRS5mG26aN28eNmzYgOjoaGzYsAHz588HAMTHxyM9PV133NatW9GvXz+4u7ubKzQiIjLAbEtgzaWwsLxe1dTb2wXXrpWZICLzYy7Wx1byAJiLtapvLmKxCF5ezoa//zBBERGRbWORICIig1gkiIjIILPt3URERA1Ho9Uiv7gSWcpS5BdXYkTUoyY5D4sEEZGV02q1KLx+E5l5ZchSliIrrwxZeWWorLoFAHB0kCAitA3cHCUNfm4WCSIiK6LValFSXo1MZSmy8kqRpawtCOWVNQAAiViE1j7OeOIxXwT6uSBQ6gr/ls3h5+tmkpVaLBJERBZUWlGNrLxSZCr/ukq4XlENABCLRGjl3QJBHVuindQVgVIXtGrpDHs7800ns0gQEZlJeWUNLueV/VUU8kpRVFoFABABkLZsgcfbeSLQzwXtpK5o7eMMB/uGH0IyBosEEZEJVFbdul0QynTDRvkllbrv+3o4oWOAe+2QkZ8L2vi6wMnR+j6SrS8iIqJGpqpGjSuq8r/mEfLKkFd4A3f2fvBybYZAqQv69vBHoJ8L2vq5oEUze4vGLBSLBBGREWpuaZBzrRxZyr+GjK4WVODOBkfuzg4I9HOtnViWuqKtnwtcmzfem6exSBARGXBLrUFuQQWy8spqrxKUZci5Vg717f3hnJ3s0U7qiqCO3mh3uyB4uDhaOOqGxSJBRITabbaVhbUFIev2FUJ2fjlqbmkAAM0d7RAodUF0WBvdxLKnqyNEIpGFIzctFgkianI0Wi2uFVfi7JXrSL+QjyxlKS6rylFVowZQ25zW1tcF/Xu2QqBf7dJTH3cnmy8IdWGRICKbdqdbWTdk9LduZXs7Mdr4OqNPNykCpS4I9HOFn2dziMVNryDUhUWCiGzGnW7lLGWp3hYWf+9W7vWYL9r5uSDoMT84SQCJmHudGsIiQUSN1p1u5TtbV2QqS+vsVg6UuqJdHd3KtnTTIVNhkSCiRqHiZo1uQvnO/xfe1a3s59Vc160ceLtb2dHC3cq2gEWCiKxOZdUtZKvKdH0If+9W9vFwwiMB7oiy8m5lW8CfKhFZlK5bOa9UN4dgK93KtoBFgojMRq9b+fbEcl3dyr0e89UtPW3M3cq2gEWCiEzi7m7lO0UhJ7/ubuU7S09trVvZFpitSGRmZiIhIQElJSVwd3dHUlISAgMD7zlu586dWLVqFbRaLUQiEdauXYuWLVuaK0wiqgeNRgtl0Y3a4aI6upWdHO0Q6PdXt3Kg1AVers2aZHNaY2O2IpGYmIi4uDjI5XKkpKRg7ty5WL9+vd4x6enpWLFiBb766it4e3ujrKwMDg681CSyJhqNFqqiG7fnEMoMdiv3C2qlu1FOU+1WtgVmKRKFhYXIyMjA2rVrAQAxMTFYuHAhioqK4OnpqTtu3bp1ePHFF+Ht7Q0AcHFxMUd4RGSAXrfy7aKQrSpDxU39buXwblLdfkbsVrYtZikSSqUSvr6+kEhq1yxLJBL4+PhAqVTqFYmLFy8iICAA48aNw40bNzBgwAD84x//4F8gRGZSXFb116Ty7aLw927lvkEB8HVvhkA/F7TybsFuZRtnVRPXarUav//+O9auXYvq6mpMmjQJ/v7+GDZsmOD38PJyrvf5vb1t58qFuVgfa8ujpKwKf+aU4I8rJfjzSgn+zCnW3UpTLBahja8LeneVomNrdzzS2h2BUlfY29lec5q1/V4ehilyMUuRkEqlUKlUUKvVkEgkUKvVyM/Ph1Qq1TvO398fAwcOhIODAxwcHBAZGYnTp08bVSQKC8uh0WgffODf2FJ7PnOxPpbOo+JmjW6VkaFu5U6tPdBOarhbuaT4BgDL59KQmEvtHwT3++PaLEXCy8sLMpkMCoUCcrkcCoUCMplMb6gJqJ2rOHToEORyOW7duoVffvkF0dHR5giRyGYI6Vbu0MoNkcG1+xmxW5nux2z/MubNm4eEhAR8+umncHV1RVJSEgAgPj4e06dPR9euXfHMM8/gzJkzGDx4MMRiMcLDwzFq1ChzhUjU6Oh3K9cWhbq6lft0lyJQ6opAdiuTkURardb4sRkrxuEm5mKNGiKPe7uVy5BbUAHN7f+E3Zwd0O52l3KgX21BcG3R8EvIbeV3AjAXwEqGm4jIOEK6lQOlLre3wWa3MpkOiwSRhel1K98uCnV1Kz8d1lp3pcBuZTIXFgkiM9JqtcgvrrxrDqEMl1VlqKq+3a1sL0Fbv9pu5UBpbXOat7sTxCwIZCEsEgDKblQjPe0KHm/txk5RanBXCyqwK/UKzvxZUOe9lcO7SnU3ypGyW5msDIsEgExlGT759jd07+CFKfLH0cyBPxZ6OBqNFr9dLMDetBycu1wMiViEAB9n9JL56FYZ+bdsATsJu5XJugn6NDx//jw6d+5s6lgsplsHL/xjZDes3nIaizecxPRR3eDp2szSYVEjdONmDX48rcS+EzkouH4THi6OGBnRHsP7P4rqympLh0dkNEFFYuLEifDx8YFcLseQIUPg4+Nj6rjMbvD/awdHsQirUs7gvfVpmDGqO9r62U67PpnW1YIK7DuRg5/OKFFdo8GjAW4Y3e8RBHVsCTuJGG7OjrjGIkGNkKAiceTIERw8eBDbtm3DihUrEBQUBLlcjqeffhpOTk6mjtFsunXwwpzngvHJt79h8caTmCJ/HD0e4b0sqG53hpT2nchBRlYx7CRiPPGYLyKDA/gHBtkMo5vpysrK8MMPP2D9+vXIycnBgAEDEBsbi+DgYFPFaJSGaKYrLqvC8u9OIzu/DGMjO2JASOuGDtOk2CBkWnUNKfXv2Qp9u/vDxcCtNq0xj/piLtbJKprpKioqsHfvXuzYsQMqlQrPPPMMpFIp3nrrLURERCAxMdHoAK2Rh4sjEsb1xOfbz+I/e/9AfnElno3syFUnTdyDhpSIbJGgInHw4EGkpKTg8OHD6NmzJ0aPHo2oqCg4OtZ2eI4bNw79+vWzmSIB1N5d65XhXfHfA39iT+oVFJRUcuVTE6TRaHH6YiH2nrjCISVqkgR94i1duhRyuRz/93//V+ektbu7O+bMmdPgwVmaWCzC2MiO8PVwwob/XcDiDScxY3R3bn/QBBhapdSnuz9cDQwpEdkiQUVi+/btDzxm9OjRDx2MterXMwBebk53rXzqhja+/CvSFnFIiUifoH/106ZNQ1pamt5zaWlpmD59ukmCskbdOnjh/8b1BAAs2nASv/5ZYOGIqKFoNFr8+kcBPvrmFN5dcwxHTisR1tkXiRNDkfBcMEI7+7BAUJMl6EoiNTUVy5Yt03uuR48eeOWVV0wSlLVq4+uCdyaEYPl3p5G8+TSejeyIqEa28on+wiElogcTVCQcHBxQWVkJZ+e/lknduHEDdnZNbxL37pVPX+/9AyqufGp0/j6k1JFDSkQGCfqUDw8Px9y5c7FgwQI4OzujvLwcCxYsQJ8+fUwdn1XiyqfGh6uUiOpH0KdaQkIC3nrrLYSFhcHNzQ3Xr19H3759sWTJElPHZ7XurHzy8XDCxv9dwOKNJzFjFFc+WRsOKRE9HEFFws3NDZ9//jny8/ORl5cHqVQKb29vU8fWKPTvGYCWXPlkda4WVGD/iRwc5ZAS0UMxanzEx8cH3t7e0Gq10Ghq75olFvM/uDsrn5Z9dxqLNnDPJ0vhkBJRwxNUJFQqFRYsWIC0tDSUlpbqfe/cuXMmCayx4cony6lrSGlE3/bo24NDSkQPS1CRSExMRLNmzbBu3To899xz2LhxI5KTkxEREWHq+BqVOyufPttWu/Ipv7gSY7nyyWQ4pERkeoKKxKlTp3DgwAE0b94cIpEInTt3xvvvv4+xY8dizJgxgk6UmZmJhIQElJSUwN3dHUlJSQgMDNQ7Jjk5GV9//bVu64+ePXs2uv2gHB0kmDbir5VP17jyqUFxSInIvAR9conFYl1PhKurK4qKiuDs7AyVSiX4RImJiYiLi4NcLkdKSgrmzp2L9evX33PcsGHDMHv2bMHva4248qnh3bhZgyOnldh3MgfXSjikRGQugopE9+7dcejQIQwYMADh4eF47bXX0KxZM3Tp0kXQSQoLC5GRkYG1a9cCAGJiYrBw4UIUFRXB09Oz/tFbOa58enjZeaX4bu8F/HQmD1U1anQMcMOopzikRGQugorEkiVLdKuZ5syZgy+//BIVFRV4/vnnBZ1EqVTC19cXEokEACCRSODj4wOlUnlPkdixYweOHDkCb29vvPrqqwgKCjImH6vz95VPL8sfR3eufLovDikRWY8H3plOrVZjzpw5WLhwIRwc6ndZf+bMGcyePRs7duzQPTd48GB8+OGHePzxx3XPXbt2De7u7rC3t8fRo0cxc+ZM7Ny5Ex4eHvU6rzUpvF6JhV8eQ+bV64gf1hUx4e0tHZLVKa+swd7j2dhx9BLyCm/Ay60ZBv+/doh+oi3cnDlUR2QJD7ySkEgkOHr0KESi+q/QkUqlUKlUUKvVkEgkUKvVyM/Ph1Qq1Tvu7ga9J598ElKpFH/88QfCwsIEn6shbl9qKjPH9MBn287is63puJhdbLKVT43tloy5ur2U/hpSGj6sC4I6toTUzw3XrpXhWmW1pcN8KI3td3I/zMU6WfT2pc8//zySk5Px6quvwt7e3uggvLy8IJPJoFAoIJfLoVAoIJPJ7hlqUqlU8PX1BVDbf3H16lW0a9fO6PNZK658+sudIaV9J67g7O0hpV6P+SAquDWHlIisyAOHmwAgIiICBQUFEIvF8PT01LuqOHjwoKATXbx4EQkJCSgtLYWrqyuSkpLQvn17xMfHY/r06ejatStmz56Ns2fPQiwWw97eHtOnTze6F8OaryTutv9kDjb+7wJa+zg3+Mona/7rqK5VSv2CWhlcpWTNuRjDVvIAmIu1MtWVhKAicfz4cYPfM2YoyBwaS5EAgNMXC7Aq5SyaO9o16Mona/yHX9eQUlRI6weuUrLGXOrDVvIAmIu1suhwk7UVAlvRrUNLm175xCElosZPUJH4+13p7jZjxowGC6YpunvPp+WbTyMu6lFEBgdYOqyHwsY3ItshqEjk5eXpPb527RpSU1MRFRVlkqCamrv3fNr4vwtQFd1olHs+1TWkNDKiA3o+6s3GN6JGSlCRWLRo0T3PHT58WK/vgR7OnZVPm/b/if+lXUHB9ZuYPPQxq1/5xCElIttW70+g8PBwvP766w0ZS5MnFovwbFTtnk9f77XuPZ84pETUNAgqEleuXNF7XFlZCYVCcU8zHDWMyOAAeLs3w6qUs1a351NuQQX2nczBT+m1Q0qPcEiJyKYJKhIDBgyASCTCndWyTk5OkMlkWLx4sUmDa8qsaeWTRqPF6UuF2JfGISWipkZQkTh//ryp46A63Fn5tOy73yyy8olDSkQkqEicO3cO7u7uesNLSqUS169fR+fOnU0WHP218unzbRm1K5+Kb2Bsf9OufOKQEhHdIahIvPXWW1i1apXeczU1NXjrrbewfft2kwRGf2nmYKe/8qmk4Vc+abS3VynphpRE6PWYL4eUiJo4QZ8yubm5aN26td5zbdq0wdWrV00SFN3LVCuf7gwp7T95FfkllfBwccTwvu0R0d0fri04pETU1AkqEn5+fjh79qzevR/Onj2ruxc1mU9DrXyqa0hpRER7DikRkR5BRWLixImYOnUqJk2ahDZt2iA7OxtffvklXn75ZVPHR3XQW/m08ST+IX8c3To8eOUTh5SIyFiCisSYMWPg4uKC7777Dnl5efDz88Ps2bMxcOBAU8dHBty98mnZd/df+cQhJSKqL8Ezn4MGDcKgQYNMGQsZydDKpzs4pERED0tQkXjvvfcwePBg9OzZU/fcyZMnsWvXLrz99tsmC44e7M7Kp2/2/4G9aTkoKLmJweHtkXLwDw4pEdFDE3TToSeeeAKHDx+Gg8NfQxPV1dWIiIjAzz//bNIAjdWYbjrU0PadyMHXey9Aq629yngqqFWjH1Kyhd8LYDt5AMzFWln0pkN3b8lxh1qthkajMTogMp3I4AAEeLeAyN4O7X1acEiJiB6aoE+RkJAQfPLJJ7qioNFokJycjJCQEJMGR8br1MYDT3bzZ4EgogYh6Eri7bffxpQpUxAeHg5/f38olUp4e3tj9erVpo6PiIgsSHAz3datW/Hbb78hLy8PUqkU3bp1g1jMv1aJiGyZ4CWwYrEYQUFBpoyFiIisjKAiUV5ejuTkZKSmpqK4uFhvEvvgwYOCTpSZmYmEhASUlJTA3d0dSUlJCAwMrPPYS5cuYfjw4YiLi8Ps2bMFvT8RETU8QeNF8+bNQ0ZGBqZOnYqSkhK88847kEqlmDhxouATJSYmIi4uDrt370ZcXBzmzp1b53FqtRqJiYmIiooS/N5ERGQagorE0aNHsXz5ckRFRUEikSAqKgqffPIJUlJSBJ2ksLAQGRkZiImJAQDExMQgIyMDRUVF9xz7+eef46mnnjJ4lUFEROYjqEhoNBq4uNR26zZv3hylpaXw9vbG5cuXBZ1EqVTC19cXEokEACCRSODj4wOlUql33Pnz53HkyBGjrlCIiMh0BM1JdO7cGampqejduzdCQkIwf/58tGjRokH/2q+pqcG7776LRYsW6YpJfdyvc/BBvL1tZ9sK5mJ9bCUPgLlYK1PkInjvpjuT1e+88w6WLl2K0tJSLFmyRNBJpFIpVCoV1Go1JBIJ1Go18vPz9W6Heu3aNWRnZ2Py5MkAgNLSUmi1WpSXl2PhwoWCE2rK23LcwVysj63kATAXa2XRbTnuviudp6cn3n//faOC8PLygkwmg0KhgFwuh0KhgEwmg6enp+4Yf39/HDt2TPc4OTkZN27c4OomIiILMls33Lx587BhwwZER0djw4YNmD9/PgAgPj4e6enp5gqDiIiMIGgX2MaEw03MxRrZSh4Ac7FWphpu4r4aRERkEIsEEREZZHDietmyZYLeYMaMGQ0WDBERWReDRSIvL0/3dVVVFfbs2YMuXbqgVatWyM3NRXp6Op5++mmzBElERJZhsEgsWrRI9/Xrr7+OpUuXIjo6Wvfcnj178MMPP5g2OiIisihBcxKHDx++Z8O9yMhIHDp0yCRBERGRdRBUJNq2bYuNGzfqPff111+jTZs2JgmKiIisg6CO6/fffx+vvPIK1qxZA19fX6hUKtjZ2SE5OdnU8RERkQU9sEhoNBqUlJRg27ZtOH/+PPLz8+Ht7Y0ePXrA3t7eHDESEZGFPLBIiMViTJ06FadOnUJISIg5YiIiIishaE4iNDQUv/76q6ljISIiKyNoTsLf3x/x8fGIjIyEn58fRCKR7ntspiMisl2CikRVVZVuCaxKpTJpQEREZD0EFYm7G+uIiKjpEFQk7igvL0dxcbHec3ffkIiIiGyLoCLx559/YubMmTh//jxEIhG0Wq1uXuLcuXMmDZCIiCxH0Oqm+fPno1evXjh+/DicnZ2RmpqK2NhYLF682NTxERGRBQkqEufPn8fMmTPh6uoKrVYLFxcXzJo1S/B24kRE1DgJKhKOjo64desWAMDDwwO5ubm6TmwiIrJdguYkgoODsWvXLowYMQLR0dGIj4+Hg4MDnnjiCVPHR0REFiSoSNw9rPTGG2+gY8eOqKiowLBhw0wWGBERWZ6gIlFWVgYXFxcAtXs5yeVykwZFRETWQVCRePLJJ9G+fXuEhoYiLCwMISEh8PDwMOpEmZmZSEhIQElJCdzd3ZGUlITAwEC9YzZv3ox169ZBLBZDo9Fg9OjRmDBhglHnISKihiPSarXaBx1UVVWFkydPIi0tDcePH8eZM2cQEBCA0NBQzJ07V9CJJkyYgJEjR0IulyMlJQWbN2/G+vXr9Y4pLy9HixYtIBKJUF5ejiFDhmDVqlXo3Lmz4IQKC8uh0TwwpXt4e7vg2rUyo19njZiL9bGVPADmYq3qm4tYLIKXl7Ph7wt5E0dHR/Tu3RuTJk3ClClTEBsbi9zcXOzevVtQEIWFhcjIyEBMTAwAICYmBhkZGSgqKtI7ztnZWdekd/PmTdTU1OhtJkhEROYlaLjpo48+QmpqKlQqFYKCghASEoJNmzbhkUceEXQSpVIJX19fSCQSAIBEIoGPjw+USiU8PT31jt23bx/++c9/Ijs7G2+++SY6depkZEpERNRQBBWJjRs3omXLlnj22WcRFhaGrl27ws7OqG2fBIuMjERkZCRyc3PxyiuvoG/fvmjfvr3g19/vsulBvL1d6v1aa8NcrI+t5AEwF2tlilwEfdKnpqYiPT0dqampWLVqFc6dO4dHHnkEoaGhmDp16gNfL5VKoVKpoFarIZFIoFarkZ+fD6lUavA1/v7+6Nq1Kw4ePGhUkeCcBHOxRraSB8BcrJVF5yTs7OwQFBSE2NhYjB49Gk8//TROnz6NTz/9VFAQXl5ekMlkUCgUAACFQgGZTHbPUNPFixd1XxcVFeHYsWN49NFHBZ2DiIganqAriffeew/Hjx/H5cuX0aVLF4SEhGD58uUICgoSfKJ58+YhISEBn376KVxdXZGUlAQAiI+Px/Tp09G1a1ds2rQJR48ehZ2dHbRaLZ577jmEh4fXLzMiInpogpbAJicnIzQ0FEFBQXB0dDRHXPXG4SbmYo1sJQ+AuVgriw03qdVqpKSkoGfPnlZfIIiIqGE9sEhIJBJIJBJUVVWZIx4iIrIiguYkJkyYgNdeew1TpkyBn5+fXoMbb19KRGS7BBWJhQsXAgCOHj2q97xIJOLtS4mIbJigInH+/HlTx0FERFbIqLbp3NxcqFQq+Pn53bcRjoiIbIOgIpGfn4833ngDv/76K9zd3VFSUoLu3bvjn//8J3x9fU0dIxERWYigjut58+ahc+fOOH78OI4cOYLjx49DJpMhMTHR1PEREZEFCbqSOHHiBJYtWwZ7e3sAQPPmzTFr1iz06dPHpMEREZFlCbqScHNz09tXCQAuXboEV1dXkwRFRETWQdCVxKRJkzBx4kSMGjUK/v7+yM3NxZYtWzBjxgxTx0dERBYkqEiMGTMGrVu3hkKhwO+//w4fHx8sXboUvXv3NnV8RERkQQaLxJgxY/Df//4XALBixQpMmzaNRYGIqIkxOCeRlZWl26/pyy+/NFtARERkPQxeSURGRiI6OhqtWrVCVVUVxo0bV+dxGzduNFlwRERkWQaLxKJFi5CWloarV68iPT0do0aNMmdcRERkBe47cR0SEoKQkBDU1NRg+PDh5oqJiIishKA+ibuvIiZPnmyyYIiIyLoIKhJ3S0tLM0UcRERkhYwuEgJuiU1ERDbC6CKxYMECU8RBRERWSFCR2Llzp+7rIUOG6L5evnx5w0dERERWQ1CRWLp0KQ4dOnTPc/v37zdJUEREZB0EFYnPP/8c8+bNQ2pqKoDaHoqjR4/iq6++EnyizMxMxMbGIjo6GrGxscjKyrrnmJUrV+KZZ57B0KFDMWLECPz444+C35+IiBqeoA3+OnTogBUrVmDq1Kno2bMnlEol1q9fD2dnZ8EnSkxMRFxcHORyOVJSUjB37lysX79e75hu3brhxRdfhJOTE86fP4/nnnsOR44cQbNmzYzLioiIGoTBK4mff/5Z73+lpaUYNWoUUlNTMWnSJKSnp+Pnn38WdJLCwkJkZGQgJiYGABATE4OMjAwUFRXpHdenTx84OTkBADp16gStVouSkpL65kZERA/J4JXE22+/XefzDg4O+OCDDwAAIpEI+/bte+BJlEolfH19IZFIAAASiQQ+Pj5QKpXw9PSs8zXff/892rRpAz8/vwe+/928vIRf3fydt7dLvV9rbZiL9bGVPADmYq1MkYvBImHJSenjx49j2bJl9dp9trCwHBqN8b0c3t4uuHatzOjXWSPmYn1sJQ+AuVir+uYiFovu+8e10X0S9SGVSqFSqaBWqwEAarUa+fn5kEql9xx76tQpvPXWW1i5ciXat29vjvCIiMgAg1cSEREREIlED3yDgwcPPvAYLy8vyGQyKBQKyOVyKBQKyGSye4aaTp8+jddffx3Lly/H448//uDoiYjIpAwWiQ8//LBBTzRv3jwkJCTg008/haurK5KSkgAA8fHxmD59Orp27Yr58+fj5s2bmDt3ru51S5YsQadOnRo0FiIiEkaktbHNmDgnwVyska3kATAXa2WqOQlBfRIAcO7cOaSlpaG4uFhvk78ZM2YYHRQRETUOgiauN23ahGeffRa//PILvvjiC1y4cAFr165Fdna2qeMjIiILElQk1qxZgzVr1mDlypVo1qwZVq5ciWXLlsHOTvCFCBERNUKCikRhYSFCQkJqXyAWQ6PRICIiAmgtEg4AABIGSURBVAcOHDBpcEREZFmCLgX8/PyQk5ODgIAABAYGYt++ffDw8IC9vb2p4yMiIgsSVCQmTZqEixcvIiAgAFOnTsWMGTNQU1NjcOsOIiKyDfctEjt37kRoaChGjBihey4iIgLHjx9HTU0NWrRoYfIAiYjIcu5bJJYtW4bs7Gy0adMGISEhCA0NRWhoKFq1agUHBwdzxUhERBZy3yKxe/duFBQUIDU1FWlpaVi7di3mzJkDX19fhISEICwsDKNHjzZXrEREZGYPnJNo2bIlBg0ahEGDBgEASktLsWnTJqxbtw4KhYJFgojIhj2wSGi1Wpw7d053NXHq1Cn4+Phg0KBBCA4ONkeMRERkIfctElOmTMHZs2fRrl07BAcHY8yYMVi0aJFRty0lIqLG677NdJmZmXBwcEBAQADatGmDtm3bskAQETUh972S2LNnj97E9VdffYXi4mL07NkTISEhCA4OhkwmM1esRERkZvWeuF61ahWKiopw7tw5kwdJRESWYfTE9YkTJ1BaWoouXbpg5MiR5oiRiIgs5L5FYvLkyTh16hRqamrQrVs3hIWFYdy4cQgKCoKjo6O5YiQiIgu5b5EICQnByy+/jK5du3IzPyKiJuiBVxJERNR0CbqfBBERNU0sEkREZBCLBBERGWS2IpGZmYnY2FhER0cjNjYWWVlZ9xxz5MgRjBgxAl26dEFSUpK5QiMiIgPMViQSExMRFxeH3bt3Iy4uDnPnzr3nmNatW+O9997DSy+9ZK6wiIjoPsxSJAoLC5GRkYGYmBgAQExMDDIyMlBUVKR3XNu2bfHYY4/Bzk7QXVWJiMjEzPJprFQq4evrC4lEAgCQSCTw8fGBUqmEp6dng57Ly6v+GxB6e7s0YCSWxVysj63kATAXa2WKXGzuT/bCwnJoNFqjX+ft7YJr18pMEJH5MRfrYyt5AMzFWtU3F7FYdN8/rs0y3CSVSqFSqaBWqwEAarUa+fn5kEql5jg9ERHVk1mKhJeXF2QyGRQKBQBAoVBAJpM1+FATERE1LLOtbpo3bx42bNiA6OhobNiwAfPnzwcAxMfHIz09HQCQlpaGvn37Yu3atfjmm2/Qt29f/Pjjj+YKkYiI/kak1WqNH8C3YpyTYC7WyFbyAJiLtWrUcxJERNQ4sUgQEZFBLBJERGQQiwQRERnEIkFERAaxSBARkUEsEkREZBCLBBERGcQiQUREBrFIEBGRQSwSRERkEIsEEREZxCJBREQGsUgQEZFBLBJERGQQiwQRERnEIkFERAaxSBARkUEsEkREZBCLBBERGcQiQUREBrFIEBGRQWYrEpmZmYiNjUV0dDRiY2ORlZV1zzFqtRrz589HVFQUBgwYgG+//dZc4RERUR3MViQSExMRFxeH3bt3Iy4uDnPnzr3nmO3btyM7Oxt79uzBpk2bkJycjJycHHOFSEREf2NnjpMUFhYiIyMDa9euBQDExMRg4cKFKCoqgqenp+64nTt3YvTo0RCLxfD09ERUVBR++OEHTJo0SfC5xGJRveN8mNdaG+ZifWwlD4C5WKv65PKg15ilSCiVSvj6+kIikQAAJBIJfHx8oFQq9YqEUqmEv7+/7rFUKkVeXp5R5/LwaFHvOL28nOv9WmvDXKyPreQBMBdrZYpcOHFNREQGmaVISKVSqFQqqNVqALUT1Pn5+ZBKpfccl5ubq3usVCrh5+dnjhCJiKgOZikSXl5ekMlkUCgUAACFQgGZTKY31AQAAwcOxLfffguNRoOioiLs3bsX0dHR5giRiIjqINJqtVpznOjixYtISEhAaWkpXF1dkZSUhPbt2yM+Ph7Tp09H165doVarsWDBAhw9ehQAEB8fj9jYWHOER0REdTBbkSAiosaHE9dERGQQiwQRERnEIkFERAaxSBARkUFm6bi2ZklJSdi9ezeuXr2K7du349FHH7V0SPVSXFyMWbNmITs7Gw4ODmjbti0WLFhwzzLjxmLq1KnIycmBWCxG8+bN8e6770Imk1k6rHpbsWIFkpOTG/W/MQDo378/HBwc4OjoCACYOXMm+vTpY+GojFdVVYUPPvgAP//8MxwdHdGjRw8sXLjQ0mEZLScnB6+88orucVlZGcrLy3H8+PEGO0eTLxKRkZGYMGECxo0bZ+lQHopIJMKkSZPQq1cvALXF76OPPsIHH3xg4cjqJykpCS4uLgCAvXv3Ys6cOdi6dauFo6qfs2fP4tdff9XbcqYxW758eaMudADw4YcfwtHREbt374ZIJEJBQYGlQ6qXgIAApKSk6B6///77uqblhtLkh5tCQkLu6fxujNzd3XUFAgB69Oih173e2NwpEABQXl4OkahxbsJWXV2NBQsWIDExsdHmYGsqKirw/fffY8aMGbrfScuWLS0c1cOrrq7G9u3bMXLkyAZ93yZ/JWGLNBoN/vOf/6B///6WDuWhvP322zh69Ci0Wi3WrFlj6XDqZdmyZRg6dChat25t6VAazMyZM6HVahEcHIw33ngDrq6ulg7JKFeuXIG7uztWrFiBY8eOoUWLFpgxYwZCQkIsHdpD2b9/P3x9ffH444836Ps2+SsJW7Rw4UI0b94czz33nKVDeSjvv/8+Dh48iNdffx1LliyxdDhGO3XqFNLT0xEXF2fpUBrMxo0bsW3bNmzevBlarRYLFiywdEhGu3XrFq5cuYLHHnsMW7ZswcyZM/Hqq6+ivLzc0qE9lM2bNzf4VQTAImFzkpKScPnyZXzyyScQi23j1zts2DAcO3YMxcXFlg7FKKmpqbh06RIiIyPRv39/5OXl4aWXXsKRI0csHVq93RmadXBwQFxcHE6ePGnhiIzn7+8POzs7xMTEAAC6d+8ODw8PZGZmWjiy+lOpVEhNTcWQIUMa/L1t41OEAAAff/wxzpw5g5UrV8LBwcHS4dRbRUUFlEql7vH+/fvh5uYGd3d3C0ZlvMmTJ+PIkSPYv38/9u/fDz8/P/zrX/9CeHi4pUOrlxs3bqCsrAwAoNVqsXPnzka54szT0xO9evXS7RGXmZmJwsJCtG3b1sKR1d/WrVsREREBDw+PBn/vJj8n8d5772HPnj0oKCjACy+8AHd3d+zYscPSYRntjz/+wOrVqxEYGIixY8cCqF35sHLlSgtHZrzKykrMmDEDlZWVEIvFcHNzw+rVqznxa2GFhYV49dVXoVarodFo0KFDByQmJlo6rHqZP38+5syZg6SkJNjZ2WHJkiWNbm7lblu3bsXbb79tkvfmBn9ERGQQh5uIiMggFgkiIjKIRYKIiAxikSAiIoNYJIiIyCAWCaIGkpOTg06dOuHWrVt1fv/SpUsYNmwYgoKCsH79ejNHV7e0tDRER0c3+LFkO7gElkyqf//+KCgogEQigUQiwSOPPAK5XI7Y2Fib6Qi/IycnB5GRkTh79izs7O5tQZozZw6cnZ0xZ86cBjlfcnIyLl++jI8++qhB3o+oLrb1XylZpdWrV+PUqVM4cOAA4uPj8cUXX5is8cea5ebmomPHjvV6raGrk/vRarXQaDT1Oh/RHSwSZDYuLi6IjIzEJ598gq1bt+LChQsAgIMHD2LYsGHo2bMnIiIikJycrHvN5MmT8e9//1vvfYYMGYK9e/dCq9Xigw8+QO/evREcHIwhQ4bo3vPv+vfvj59++kn3ODk5GTNnzgRQewOamTNnolevXggJCcHIkSN19xcoKyvDnDlzEB4ejj59+uDjjz/W7devVquRlJSEXr16ITIyEocOHTKY+4QJE3Ds2DEsWLAAQUFByMzMRFlZGWbNmoUnnngC/fr1w6effqr7UN+yZQvGjh2LDz74AGFhYXo/EwA4fPgwPvvsM+zatQtBQUEYOnQoAGD8+PH4+OOPMXbsWHTv3h1XrlzB5s2bMWjQIAQFBSEyMhLffPON7n2OHTuGvn376v2c/vWvf2HIkCEIDg7Ga6+9hqqqKqOPBYAvvvgC4eHhCA8Px7fffotOnTrh8uXLBn9GZJ2a/LYcZH7dunWDn58f0tLS8Oijj8LJyQlJSUno2LEjLly4gBdffBEymQxRUVEYNmwY1q5di/HjxwMAzp8/j/z8fPTt2xdHjhxBWloadu/eDRcXF1y6dEnvPhRCbd26FeXl5Th48CAcHBxw7tw5NGvWDAAwe/ZstGzZEnv27EFlZSWmTJkCqVSKsWPH4r///S8OHDiA77//Hk5OTnj11VcNnmP9+vUYP348hg4ditGjRwMAZs2ahbKyMuzduxclJSV46aWX4O3trfv+6dOn8cwzz+Cnn36650qib9++mDJlSp3DTSkpKfjiiy/Qrl07aLVaeHl54bPPPkPr1q2RmpqK+Ph4dO3a1eCW0rt27cKaNWvg6OiIZ599Flu2bMGzzz5r1LGHDx/GunXrsG7dOgQEBGDu3LnCfhlkdXglQRbh4+OD69evAwB69eqFTp06QSwWo3PnznjmmWd0t1+MiorC5cuXkZWVBaD2A3DQoEFwcHCAnZ0dKioqcOnSJWi1WnTo0AE+Pj5Gx2JnZ4eSkhJcvnwZEokEXbp0gbOzMwoKCnD48GHMmTMHzZs3h5eXFyZOnKjb22vXrl14/vnnIZVK4e7ujilTpgg+p1qtxs6dO/Hmm2/C2dkZAQEBeOGFF7Bt2za9n9H48eNhZ2enK1pCDB8+HB07doSdnR3s7e3x1FNPoU2bNhCJRAgLC8OTTz6JtLQ0g68fP348fH194e7ujn79+uHcuXNGH7tr1y6MGDECHTt2hJOTE6ZNmyY4frIuvJIgi1CpVHBzcwMA/Pbbb/joo4/wxx9/oKamBtXV1Rg4cCCA2i2pBw4ciG3btmHatGlQKBRYvnw5AKB3794YN24cFixYgNzcXAwYMACzZ8+Gs7OzUbHI5XLk5eXhjTfeQGlpKYYOHYrXX38dubm5uHXrlt6urRqNRrdddn5+vt5dDY25PWlxcTFqamr0XuPv7w+VSqV77OfnZ1Qed/z9TouHDh3CypUrkZWVBY1Gg5s3b9739qPe3t66r52cnJCfn2/0sfn5+ejSpYvBmKjx4JUEmd3p06ehUqkQHBwMAHjzzTd1Y/onTpzA2LFjcfeiu+HDh2P79u34+eef4eTkhKCgIN33JkyYgC1btmDHjh3IysoyeAc7JycnVFZW6h5fu3ZN97W9vT2mTZuGnTt34ptvvsHBgwfx/fffw8/PDw4ODvjll1+QlpaGtLQ0nDx5Uncl4e3trbel+d1fP4iHhwfs7e31bjGrVCrh6+ure/ygXW8Nff/u56urqzF9+nS8+OKLOHr0KNLS0tC3b1+YelGjj4+PXsEz5mdD1oVFgsymvLwcBw4cwBtvvIGhQ4eiU6dOAGrvH+Hm5gZHR0ecPn0aCoVC73VBQUEQi8VYvHixboIWqC02v/32G2pqauDk5AQHBwdIJJI6z925c2fs3LkTNTU1SE9Px+7du3Xf++WXX/D7779DrVbD2dkZdnZ2kEgk8PHxwZNPPonFixejvLwcGo0G2dnZuqGwQYMG4d///jfy8vJw/fp1fP7554J/FhKJBAMHDsTHH3+M8vJyXL16FWvXrtXL70G8vLxw9erV+65gqq6uRnV1NTw9PWFnZ4dDhw7p7qNgSgMHDsSWLVtw8eJFVFZWNsot66kWiwSZ3Msvv4ygoCBERERg9erVeOGFF7Bo0SLd9xMTE7F8+XIEBQVh5cqVGDRo0D3vIZfLceHCBcjlct1zFRUVeOeddxAWFoZ+/frB3d0dL774Yp0xvPbaa8jOztatFLr7Dl4FBQWYPn06goODMXjwYISFhek+rJcsWYKamhoMHjwYoaGhmD59uu4qZMyYMQgPD4dcLsfw4cPx9NNPG/Vzeffdd+Hk5ISoqCjExcUhJibGqNtP3hmS69WrF4YPH17nMc7OznjnnXfw2muvITQ0FAqFwiz3Po+IiMD48eMxYcIEDBgwAD169ACARn0zrKaKzXTUKHz//ffYtGkT/vOf/1g6FKqHixcvIiYmBunp6XU2GpL14pUEWb3Kykp8/fXXiI2NtXQoZIT//e9/qK6uxvXr1/Hhhx+iX79+LBCNEIsEWbUff/wRvXv3hpeXl+7G9dQ4fPPNN+jduzcGDBgAiUSCefPmWTokqgcONxERkUG8kiAiIoNYJIiIyCAWCSIiMohFgoiIDGKRICIig1gkiIjIoP8PB4cmY/otLBkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([1,2,4,7], [0.57, 0.43, 0.57, 0.67])\n",
    "plt.ylabel('Walk-forward accuracy')\n",
    "plt.xlabel('Days used for training')\n",
    "plt.ylim([0, 0.7])\n",
    "plt.savefig('walkforward_days_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1,2,4,7], [0.5656, 0.4336])\n",
    "plt.ylabel('Walk-forward accuracy')\n",
    "plt.xlabel('Days used for training')\n",
    "plt.ylim([0, 0.7])\n",
    "plt.savefig('walkforward_days_training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_val, y_train_val, X_test, y_test = generate_data(l2_snap, 20, columns = ['b1','b2','b3','b4','b5', 'a1','a2','a3','a4','a5', 'bq1','bq2','bq3','bq4','bq5', 'aq1','aq2','aq3','aq4','aq5'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = generate_model(20)\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# class_weights = compute_class_weight('balanced', np.unique(y_train_val), y_train_val)\n",
    "# d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 20\n",
    "# model_filename = \"model_resnet_walkforward_tcn_depth5.h5\"\n",
    "# hist_filename = \"hist_model_walkforward_tcn_depth5.csv\"\n",
    "# early_stop = keras.callbacks.EarlyStopping(\n",
    "#                 monitor='val_loss',\n",
    "#                 patience=4)\n",
    "# model_save_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "#                             filepath= model_filename,\n",
    "#                             save_best_only=True,\n",
    "#                             monitor='val_loss',\n",
    "#                             verbose=1)\n",
    "# reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "#                 monitor='val_loss',\n",
    "#                 factor=0.5,\n",
    "#                 patience=2,\n",
    "#                 verbose=1,\n",
    "#                 min_lr=0.0001)\n",
    "# callbacks = [reduce_lr, model_save_checkpoint, early_stop]\n",
    "# history = m.fit(\n",
    "#             X_train_val, y_train_val,\n",
    "#             epochs=EPOCHS,\n",
    "#             batch_size=128,\n",
    "#             callbacks=callbacks,\n",
    "#             class_weight = d_class_weights,\n",
    "#             validation_data = (X_test, y_test),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = m.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set()\n",
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    \n",
    "# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# ax=sns.heatmap(cm, annot=True, xticklabels=['Down','Stable','Up'], yticklabels=['Down','Stable','Up'], cmap='Blues')\n",
    "# ax.set_ylim(3.0, 0)\n",
    "# plt.savefig('image_depth_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_true = y_test,y_pred = y_pred,  target_names=['Down', 'Stable', 'Up']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEPTH 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_val, y_train_val, X_test, y_test = generate_data(l2_snap, 4, columns=['b1','a1','bq1','aq1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = generate_model(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# class_weights = compute_class_weight('balanced', np.unique(y_train_val), y_train_val)\n",
    "# d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 20\n",
    "# model_filename = \"model_resnet_walkforward_tcn.h5\"\n",
    "# hist_filename = \"hist_model_walkforward_tcn.csv\"\n",
    "# early_stop = keras.callbacks.EarlyStopping(\n",
    "#                 monitor='val_loss',\n",
    "#                 patience=4)\n",
    "# model_save_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "#                             filepath= model_filename,\n",
    "#                             save_best_only=True,\n",
    "#                             monitor='val_loss',\n",
    "#                             verbose=1)\n",
    "# reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "#                 monitor='val_loss',\n",
    "#                 factor=0.5,\n",
    "#                 patience=2,\n",
    "#                 verbose=1,\n",
    "#                 min_lr=0.0001)\n",
    "# callbacks = [reduce_lr, model_save_checkpoint, early_stop]\n",
    "# history = m.fit(\n",
    "#             X_train_val, y_train_val,\n",
    "#             epochs=EPOCHS,\n",
    "#             batch_size=128,\n",
    "#             callbacks=callbacks,\n",
    "#             class_weight = d_class_weights,\n",
    "#             validation_data = (X_test, y_test),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = m.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set()\n",
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    \n",
    "# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# ax=sns.heatmap(cm, annot=True, xticklabels=['Down','Stable','Up'], yticklabels=['Down','Stable','Up'], cmap='Blues')\n",
    "# ax.set_ylim(3.0, 0)\n",
    "# plt.savefig('image_depth_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_true = y_test,y_pred = y_pred,  target_names=['Down', 'Stable', 'Up']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
